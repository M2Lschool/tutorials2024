# [[M2L2024](https://www.m2lschool.org/home)] Tutorial 1: Natural Language Processing

**Authors:** [Georgios Peikos](https://www.linkedin.com/in/peikosgeorgios/), [Luca Herranz-Celotti](https://lucehe.github.io/)

--- 

This is the tutorial of the 2024 Mediterranean Machine Learning Summer School on Natural 
Language Processing!

This tutorial will explore the fundamental aspects of Natural Language Processing (NLP). 
Basic Python programming skills are expected. Prior knowledge of standard NLP techniques 
(e.g. text tokenization and classification with ML) is beneficial but optional when working 
through the notebooks as they assume minimal prior knowledge.

This tutorial combines detailed analysis and development of essential NLP concepts via 
custom (i.e. from scratch) implementations. Other necessary NLP components will be developed 
using PyTorch's NLP library implementations. As a result, the tutorial offers deep 
understanding and facilitates easy usage in future applications.

### Outline

* Part I: Introduction to Text Tokenization and Classification
  *  Text Classification: Simple Classifier
  *  Text Classification: Encoder-only Transformer

* Part II: Introduction to Decoder-only Transformer and Sparse Mixture of Experts Architecture
  *  Text Generation: Decoder-only Transformer
  *  Text Generation: Decoder-only Transformer + MoE

* Part III: Introduction to Parameter Efficient Fine-tuning
  *  Fine-tuning the full Pre-trained Models
  *  Fine-tuning using Low-Rank Adaptation of Large Language Models (LoRA)

### Notebooks

#### Part I: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_I_text_classification/Transformer_Encoder_Classification.ipynb)

Solution: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_I_text_classification/Transformer_Encoder_Classification_solved.ipynb)

#### Part II: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_II_text_generation/Transformer_Decoder_MoE.ipynb)

Solution: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_II_text_generation/Transformer_Decoder_MoE_solved.ipynb)

#### Part III: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_III_llm_finetuning/LoRA.ipynb)

Solution: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/1_nlp/part_III_llm_finetuning/LoRA_solved.ipynb)

---
