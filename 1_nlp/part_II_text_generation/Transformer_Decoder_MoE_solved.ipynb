{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd460906c5434436bb0ad4b122cb8616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37a8f46704f14945bef2635440aa0bc9",
              "IPY_MODEL_ce5253855acb4be4b0026ca55c1aaf23",
              "IPY_MODEL_5b18da8645e14bc9bf817d19d9ac4bf7"
            ],
            "layout": "IPY_MODEL_8c8a82d674674682b00aba4cd2e87dba"
          }
        },
        "37a8f46704f14945bef2635440aa0bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_844e303a4d7a4cfb9934bcab6746c945",
            "placeholder": "​",
            "style": "IPY_MODEL_84c0bb59ed724811a5ef0473a40d867c",
            "value": "Downloading builder script: 100%"
          }
        },
        "ce5253855acb4be4b0026ca55c1aaf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d070ad3703a6435b9188cd7a17e9f1b9",
            "max": 3731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_128acced85c148fd89c6530bfbf49ae1",
            "value": 3731
          }
        },
        "5b18da8645e14bc9bf817d19d9ac4bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad45f16aa83d49a3bdf0a67aa9ad0f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_6970f7710c074c9baed65efed2c6a2e3",
            "value": " 3.73k/3.73k [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "8c8a82d674674682b00aba4cd2e87dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844e303a4d7a4cfb9934bcab6746c945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c0bb59ed724811a5ef0473a40d867c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d070ad3703a6435b9188cd7a17e9f1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128acced85c148fd89c6530bfbf49ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad45f16aa83d49a3bdf0a67aa9ad0f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6970f7710c074c9baed65efed2c6a2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2816d1668fd042aca827a5685f815b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc3d8de5049e48928fb68f5f18ef916c",
              "IPY_MODEL_d966ec1f281a4f5aa5c140e3054eade4",
              "IPY_MODEL_ed23753e83234294b11b9e8d84272580"
            ],
            "layout": "IPY_MODEL_3b1c60ce0a0a4369a1fe277fbbff77f3"
          }
        },
        "cc3d8de5049e48928fb68f5f18ef916c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_410881f61a7941ee98e0fea1bed948be",
            "placeholder": "​",
            "style": "IPY_MODEL_7676a6a0a1b84595a13887308cb55ee6",
            "value": "Downloading readme: 100%"
          }
        },
        "d966ec1f281a4f5aa5c140e3054eade4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1eea7a6fbc472bb5ecd071d50f172e",
            "max": 6101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a483b76dede460784011ad5bc056fc2",
            "value": 6101
          }
        },
        "ed23753e83234294b11b9e8d84272580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_053d38cfbef2404485346b5cda96f523",
            "placeholder": "​",
            "style": "IPY_MODEL_92944b62080e4770aa332bd2703a2f1d",
            "value": " 6.10k/6.10k [00:00&lt;00:00, 28.6kB/s]"
          }
        },
        "3b1c60ce0a0a4369a1fe277fbbff77f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410881f61a7941ee98e0fea1bed948be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7676a6a0a1b84595a13887308cb55ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1eea7a6fbc472bb5ecd071d50f172e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a483b76dede460784011ad5bc056fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "053d38cfbef2404485346b5cda96f523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92944b62080e4770aa332bd2703a2f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42c0d4c00f0345b79f0a7c4b293fd6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_204df83e2d60442281b00e07ad6725c3",
              "IPY_MODEL_34619982bbde403cb4603ab126433b64",
              "IPY_MODEL_f3bd58ecf11b41b48c260ea630e2a94a"
            ],
            "layout": "IPY_MODEL_19511f6ed8bc4d9294ef28f3d20f46ca"
          }
        },
        "204df83e2d60442281b00e07ad6725c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71bf45b35e76439b94063e47de734d01",
            "placeholder": "​",
            "style": "IPY_MODEL_eb8e20d8825945029a38848fb92b0bc6",
            "value": "Downloading data: "
          }
        },
        "34619982bbde403cb4603ab126433b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c90df872f4449ea9cfb78b2ed59c10",
            "max": 435071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb86d1cfa7274329b718eec570d135d5",
            "value": 435071
          }
        },
        "f3bd58ecf11b41b48c260ea630e2a94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70325a36fbc342ff9c54359eed0147fd",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f96202911143b1bf27eea07077ac44",
            "value": " 1.12M/? [00:00&lt;00:00, 15.7MB/s]"
          }
        },
        "19511f6ed8bc4d9294ef28f3d20f46ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71bf45b35e76439b94063e47de734d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8e20d8825945029a38848fb92b0bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c90df872f4449ea9cfb78b2ed59c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb86d1cfa7274329b718eec570d135d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70325a36fbc342ff9c54359eed0147fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f96202911143b1bf27eea07077ac44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779594a3ce134ad186ea5fe72abf7aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d57bec07df304798810a71d8efed2afe",
              "IPY_MODEL_d00f8829eda2428ba2b97553d34f7e85",
              "IPY_MODEL_e2f6b5d1e88542d888abd70ae75047f1"
            ],
            "layout": "IPY_MODEL_87863c8478f74a469eabd86f859feb7b"
          }
        },
        "d57bec07df304798810a71d8efed2afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9af869d0164bfea5160adafdac963b",
            "placeholder": "​",
            "style": "IPY_MODEL_65f2b49d83ab4e2287044377945f42d4",
            "value": "Generating train split: 100%"
          }
        },
        "d00f8829eda2428ba2b97553d34f7e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf60e6b38ac4f87b38083d431f89df4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c7aac4d3a08459ea4081a552f5c6e95",
            "value": 1
          }
        },
        "e2f6b5d1e88542d888abd70ae75047f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf2166e9786415b93b432cc440fe62c",
            "placeholder": "​",
            "style": "IPY_MODEL_0b6706206abb4abeacf4d741dc5b4ca6",
            "value": " 1/1 [00:00&lt;00:00, 34.21 examples/s]"
          }
        },
        "87863c8478f74a469eabd86f859feb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9af869d0164bfea5160adafdac963b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f2b49d83ab4e2287044377945f42d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf60e6b38ac4f87b38083d431f89df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7aac4d3a08459ea4081a552f5c6e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbf2166e9786415b93b432cc440fe62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6706206abb4abeacf4d741dc5b4ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a0f3fe566a54d3a8f19bf797ff4345b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a21df6419419451da7696d4945a9bcda",
              "IPY_MODEL_b11878e97c984ca88790d5b031d82e65",
              "IPY_MODEL_b8bea541198344b2af7bba9e34ad7ec2"
            ],
            "layout": "IPY_MODEL_2e998e1fb7274e3589de073a1aa883d2"
          }
        },
        "a21df6419419451da7696d4945a9bcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1773bb38f14c4c9eb9702cbdf2321a",
            "placeholder": "​",
            "style": "IPY_MODEL_71e9e801c3c4409b8d8ccbe1d53dc0ff",
            "value": "Generating validation split: 100%"
          }
        },
        "b11878e97c984ca88790d5b031d82e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e57f719ec2c4ebe9c870a6cb61eac11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2e8c74722c49b69bd091d7df8f6bba",
            "value": 1
          }
        },
        "b8bea541198344b2af7bba9e34ad7ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4dc868fe6d46cb9038b9c7830eb1da",
            "placeholder": "​",
            "style": "IPY_MODEL_557c543998dc49f587103be30ef618f5",
            "value": " 1/1 [00:00&lt;00:00, 51.36 examples/s]"
          }
        },
        "2e998e1fb7274e3589de073a1aa883d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1773bb38f14c4c9eb9702cbdf2321a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e9e801c3c4409b8d8ccbe1d53dc0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e57f719ec2c4ebe9c870a6cb61eac11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2e8c74722c49b69bd091d7df8f6bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be4dc868fe6d46cb9038b9c7830eb1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557c543998dc49f587103be30ef618f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d29503173f04d8998f9d3f91ba86a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbe5aee32254f40a79ba6688a1d989a",
              "IPY_MODEL_dd71a5de19ee40d9867aa4a5e719064a",
              "IPY_MODEL_2fd83fc3e84749a7a053c4ba247fbf11"
            ],
            "layout": "IPY_MODEL_d262a7075b8744be9012728db17bc75e"
          }
        },
        "7bbe5aee32254f40a79ba6688a1d989a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1975fd2c6daf4b20a4da0dfa2ccfcbaa",
            "placeholder": "​",
            "style": "IPY_MODEL_4e218252bc0343f4ac39e12e04c6f2e5",
            "value": "Generating test split: 100%"
          }
        },
        "dd71a5de19ee40d9867aa4a5e719064a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01feab2fa8fa4d14a226bfae192401c9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43abfe39db0a4fee8976cd60e3688dde",
            "value": 1
          }
        },
        "2fd83fc3e84749a7a053c4ba247fbf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b165bdfb7d4e8a85c491658251ab94",
            "placeholder": "​",
            "style": "IPY_MODEL_7e4219bb0ad24fa3959264e546970dc6",
            "value": " 1/1 [00:00&lt;00:00, 56.78 examples/s]"
          }
        },
        "d262a7075b8744be9012728db17bc75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1975fd2c6daf4b20a4da0dfa2ccfcbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e218252bc0343f4ac39e12e04c6f2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01feab2fa8fa4d14a226bfae192401c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43abfe39db0a4fee8976cd60e3688dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1b165bdfb7d4e8a85c491658251ab94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4219bb0ad24fa3959264e546970dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing Tutorial\n",
        "======\n",
        "\n",
        "This is the tutorial of the 2024 [Mediterranean Machine Learning Summer School](https://www.m2lschool.org/) on Natural Language Processing!\n",
        "\n",
        "This tutorial will explore the fundamental aspects of Natural Language Processing (NLP). Basic Python programming skills are expected.\n",
        "Prior knowledge of standard NLP techniques (e.g. text tokenization and classification with ML) is beneficial but optional when working through the notebooks as they assume minimal prior knowledge.\n",
        "\n",
        "This tutorial combines detailed analysis and development of essential NLP concepts via custom (i.e. from scratch) implementations. Other necessary NLP components will be developed using PyTorch's NLP library implementations. As a result, the tutorial offers deep understanding and facilitates easy usage in future applications.\n",
        "\n",
        "## Outline\n",
        "\n",
        "* Part I: Introduction to Text Tokenization and Classification\n",
        "  *  Text Classification: Simple Classifier\n",
        "  *  Text Classification: Encoder-only Transformer\n",
        "\n",
        "* Part II: Introduction to Decoder-only Transformer and Sparse Mixture of Experts Architecture\n",
        "  *  Text Generation: Decoder-only Transformer\n",
        "  *  Text Generation: Decoder-only Transformer + MoE\n",
        "\n",
        "* Part III: Introduction to Parameter Efficient Fine-tuning\n",
        "  *  Fine-tuning the full Pre-trained Models\n",
        "  *  Fine-tuning using Low-Rank Adaptation of Large Language Models (LoRA)\n",
        "\n",
        "## Notation\n",
        "\n",
        "* Sections marked as [📝] contain cells with missing code that you should complete.\n",
        "* Sections marked with [📚] contain cells that you should read and modify to understand how your changes alter the obtained results.\n",
        "* External resources are mentioned with [✨]. These provide valuable supplementary information for this tutorial and offer opportunities for further in-depth exploration of the topics covered.\n",
        "* Sections that contain code that test the functionality of other sections are marked with [✍]. You are more that welcome to modify these sections so that you can understand code functionality.\n",
        "\n",
        "\n",
        "## Libraries\n",
        "\n",
        "This tutorial leverages [PyTorch](https://pytorch.org/) for neural network implementation and training, complemented by standard Python libraries for data processing and the [Hugging Face](https://huggingface.co/) datasets library for accessing NLP resources.\n",
        "\n",
        "GPU access is recommended for optimal performance, particularly for model training and text generation. While all code can run on CPU, a CUDA-enabled environment will significantly speed up these processes.\n",
        "\n",
        "## Credits\n",
        "\n",
        "The tutorial is created by:\n",
        "\n",
        "* [Georgios Peikos](https://www.linkedin.com/in/peikosgeorgios/)\n",
        "* [Luca Herranz-Celotti](http://LuCeHe.github.io)\n",
        "\n",
        "It is inspired by and synthesizes various online resources, which are cited throughout for reference and further reading.\n",
        "\n",
        "## Note for Colab users\n",
        "\n",
        "To grab a GPU (if available), make sure you go to `Edit -> Notebook settings` and choose a GPU under `Hardware accelerator`\n",
        "\n"
      ],
      "metadata": {
        "id": "KBrDjSR61FHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nhQDxGSyOQh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: Introduction to the decoder-only Transformers architecture and Sparse Mixture of Expert\n",
        "\n",
        "We create a decoder-only Transformer architecture from the bottom up, including a custom text tokenizer and an efficient dataset handler. We will explore all essential components of this architecture, train the model, and show its capabilities in text generation.\n",
        "\n",
        "Then, we will enhance our base model by incorporating a gating function and implementing a sparse mixture of experts."
      ],
      "metadata": {
        "id": "cCNKdaEAOFeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7wFJ2UqTOcpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder-only Transformer Architecture\n",
        "\n",
        "The decoder-only transformer architecture consists of multiple identical blocks stacked sequentially. Each block is composed of two main elements:\n",
        "- A masked multi-head self-attention mechanism.\n",
        "- A feed-forward neural network.\n",
        "\n",
        "These components are typically encapsulated within residual connections and layer normalization. In this section, we will explore the internal structure of these blocks in greater depth and provide a practical PyTorch implementation."
      ],
      "metadata": {
        "id": "bI8usToL1SAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Decoder Only Architecture](https://drive.google.com/uc?id=1ksROxQxf3b7dlBUoIQggzyLeBaPO-AQn)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JleDmRBgvle7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "cSQDU10O6YUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "\n",
        "import math\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Union\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "E532K_c76aIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5ec262-82d8-41ce-fb38-b51f87893707"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Text Tokenization from Scratch\n",
        "\n",
        "Tokenization is a fundamental step in NLP that converts raw text into a format that systems can understand and process. It enables the transformation of variable-length text sequences into fixed-size numerical representations, which is crucial for input to neural network models.\n",
        "\n",
        "Here, we create a simple text tokenizer for basic word-level tokenization tasks.\n",
        "The tokenizer can be improved so that:\n",
        "\n",
        "1.   Methods for handling very large vocabularies (e.g., frequency thresholding)\n",
        "2.   Support for n-grams or phrase detection\n",
        "3.   Handle punctuation. For instance now, tokens like \"word.\" and \"word\" are being treated differently.\n",
        "\n",
        "Also, we create a testing function to showcase the codes behavior.\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   Overview of hugging Face tokenizers [Link-huggingface](https://huggingface.co/docs/transformers/en/tokenizer_summary)"
      ],
      "metadata": {
        "id": "HNcnHkLd6Vab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the tokenizer with special tokens and prepare vocabulary structures.\"\"\"\n",
        "        # Special tokens are used for various purposes in NLP tasks:\n",
        "        # <PAD>: Used for padding sequences to a fixed length\n",
        "        # <UNK>: Represents unknown words not in the vocabulary\n",
        "        # <SOS>: Marks the start of a sequence\n",
        "        # <EOS>: Marks the end of a sequence\n",
        "        self.special_tokens = [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]\n",
        "\n",
        "        # word_to_idx: Maps words to unique integer indices\n",
        "        # This is crucial for converting text into a format that neural networks can process\n",
        "        self.word_to_idx = {token: idx for idx, token in enumerate(self.special_tokens)}\n",
        "\n",
        "        # idx_to_word: The reverse mapping of word_to_idx\n",
        "        # This is used for converting model outputs back into readable text\n",
        "        self.idx_to_word = {idx: token for idx, token in enumerate(self.special_tokens)}\n",
        "\n",
        "        # Counter object to keep track of word frequencies in the corpus\n",
        "        self.word_count = Counter()\n",
        "\n",
        "    def fit(self, texts: List[str]) -> None:\n",
        "        \"\"\"Build the vocabulary from a list of texts.\"\"\"\n",
        "        # Count the frequency of each word in the entire corpus\n",
        "        for text in texts:\n",
        "            self.word_count.update(text.split())\n",
        "\n",
        "        # Add each unique word to the vocabulary\n",
        "        # We assign a unique index to each word, which the model will use to represent words\n",
        "        for word in self.word_count:\n",
        "            if word not in self.word_to_idx:\n",
        "                idx = len(self.word_to_idx)\n",
        "                self.word_to_idx[word] = idx\n",
        "                self.idx_to_word[idx] = word\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "        \"\"\"Convert a text string to a list of indices.\"\"\"\n",
        "        # This method is used to prepare input for the model\n",
        "        # It converts each word to its corresponding index\n",
        "        # If a word is not in the vocabulary, it uses the <UNK> token\n",
        "        return [self.word_to_idx.get(word, self.word_to_idx[\"<UNK>\"]) for word in text.split()]\n",
        "\n",
        "    def decode(self, indices: List[int]) -> str:\n",
        "        \"\"\"Convert a list of indices back to a text string.\"\"\"\n",
        "        # This method is used to convert model output back into readable text\n",
        "        # It maps each index back to its corresponding word\n",
        "        return \" \".join([self.idx_to_word.get(idx, \"<UNK>\") for idx in indices])\n",
        "\n",
        "    def encode_batch(self, texts: List[str]) -> List[List[int]]:\n",
        "        \"\"\"Convert a batch of text strings to lists of indices.\"\"\"\n",
        "        return [self.encode(text) for text in texts]\n",
        "\n",
        "    def decode_batch(self, batch_indices: List[List[int]]) -> List[str]:\n",
        "        \"\"\"Convert a batch of lists of indices back to text strings.\"\"\"\n",
        "        return [self.decode(indices) for indices in batch_indices]\n",
        "\n",
        "    def show_vocab(self):\n",
        "        \"\"\"Display the vocabulary.\"\"\"\n",
        "        # Useful for debugging and understanding the tokenizer's state\n",
        "        print(\"Vocabulary:\")\n",
        "        for word, idx in self.word_to_idx.items():\n",
        "            print(f\"{word}: {idx}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the size of the vocabulary.\"\"\"\n",
        "        # The vocabulary size is an important parameter for the model\n",
        "        # It determines the dimensionality of the model's output layer\n",
        "        return len(self.word_to_idx)"
      ],
      "metadata": {
        "id": "mZ6q24hC1Q2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Tokenizer\n",
        "\n",
        "This testing function shows examples of text tokenization presenting also extreme use cases."
      ],
      "metadata": {
        "id": "V8FKgjcjZyj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_tokenizer():\n",
        "    print(\"\\nTesting SimpleTokenizer\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    # Sample texts\n",
        "    texts = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"Pack my box with five dozen liquor jugs!\",\n",
        "        \"How vexingly quick daft zebras jump!\",\n",
        "        \"This is a sentence with some punctuation, including commas.\",\n",
        "        \"This text contains an unknown word: monkey\",\n",
        "        \"\"  # Empty string to test edge case\n",
        "    ]\n",
        "\n",
        "    # Initialize and fit the tokenizer\n",
        "    tokenizer = SimpleTokenizer()\n",
        "    tokenizer.fit(texts)\n",
        "\n",
        "    # Display vocabulary\n",
        "    tokenizer.show_vocab()\n",
        "    print(f\"\\nVocabulary size: {len(tokenizer)}\")\n",
        "\n",
        "    # Test encoding and decoding\n",
        "    print(\"\\nEncoding and Decoding Test:\")\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode(text)\n",
        "        decoded = tokenizer.decode(encoded)\n",
        "        print(f\"\\nOriginal: {text}\")\n",
        "        print(f\"Encoded : {encoded}\")\n",
        "        print(f\"Decoded : {decoded}\")\n",
        "        print(f\"Match   : {'✓' if text.strip().lower() == decoded.strip().lower() else '✗'}\")\n",
        "\n",
        "    # Test unknown word handling\n",
        "    print(\"\\nUnknown Word Handling Test:\")\n",
        "    unknown_text = \"This text contains an unknown word: xylophone\"\n",
        "    encoded_unknown = tokenizer.encode(unknown_text)\n",
        "    decoded_unknown = tokenizer.decode(encoded_unknown)\n",
        "    print(f\"Original: {unknown_text}\")\n",
        "    print(f\"Encoded : {encoded_unknown}\")\n",
        "    print(f\"Decoded : {decoded_unknown}\")\n",
        "\n",
        "    # Test special tokens\n",
        "    print(\"\\nSpecial Tokens Test:\")\n",
        "    special_text = \"< SOS > This is a test sentence <EOS>\"\n",
        "    encoded_special = tokenizer.encode(special_text)\n",
        "    decoded_special = tokenizer.decode(encoded_special)\n",
        "    print(f\"Original: {special_text}\")\n",
        "    print(f\"Encoded : {encoded_special}\")\n",
        "    print(f\"Decoded : {decoded_special}\")\n",
        "\n",
        "    # Test case sensitivity\n",
        "    print(\"\\nCase Sensitivity Test:\")\n",
        "    case_text = \"The Quick Brown Fox\"\n",
        "    encoded_case = tokenizer.encode(case_text)\n",
        "    decoded_case = tokenizer.decode(encoded_case)\n",
        "    print(f\"Original: {case_text}\")\n",
        "    print(f\"Encoded : {encoded_case}\")\n",
        "    print(f\"Decoded : {decoded_case}\")\n",
        "\n",
        "print(\"\\nChecking the tokenizer's outputs\")\n",
        "test_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tc3YteacXJOs",
        "outputId": "14568ef2-d306-4ada-ce5f-54cde1dfaec3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking the tokenizer's outputs\n",
            "\n",
            "Testing SimpleTokenizer\n",
            "==============================\n",
            "Vocabulary:\n",
            "<PAD>: 0\n",
            "<UNK>: 1\n",
            "<SOS>: 2\n",
            "<EOS>: 3\n",
            "The: 4\n",
            "quick: 5\n",
            "brown: 6\n",
            "fox: 7\n",
            "jumps: 8\n",
            "over: 9\n",
            "the: 10\n",
            "lazy: 11\n",
            "dog.: 12\n",
            "Pack: 13\n",
            "my: 14\n",
            "box: 15\n",
            "with: 16\n",
            "five: 17\n",
            "dozen: 18\n",
            "liquor: 19\n",
            "jugs!: 20\n",
            "How: 21\n",
            "vexingly: 22\n",
            "daft: 23\n",
            "zebras: 24\n",
            "jump!: 25\n",
            "This: 26\n",
            "is: 27\n",
            "a: 28\n",
            "sentence: 29\n",
            "some: 30\n",
            "punctuation,: 31\n",
            "including: 32\n",
            "commas.: 33\n",
            "text: 34\n",
            "contains: 35\n",
            "an: 36\n",
            "unknown: 37\n",
            "word:: 38\n",
            "monkey: 39\n",
            "\n",
            "Vocabulary size: 40\n",
            "\n",
            "Encoding and Decoding Test:\n",
            "\n",
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "Encoded : [4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "Decoded : The quick brown fox jumps over the lazy dog.\n",
            "Match   : ✓\n",
            "\n",
            "Original: Pack my box with five dozen liquor jugs!\n",
            "Encoded : [13, 14, 15, 16, 17, 18, 19, 20]\n",
            "Decoded : Pack my box with five dozen liquor jugs!\n",
            "Match   : ✓\n",
            "\n",
            "Original: How vexingly quick daft zebras jump!\n",
            "Encoded : [21, 22, 5, 23, 24, 25]\n",
            "Decoded : How vexingly quick daft zebras jump!\n",
            "Match   : ✓\n",
            "\n",
            "Original: This is a sentence with some punctuation, including commas.\n",
            "Encoded : [26, 27, 28, 29, 16, 30, 31, 32, 33]\n",
            "Decoded : This is a sentence with some punctuation, including commas.\n",
            "Match   : ✓\n",
            "\n",
            "Original: This text contains an unknown word: monkey\n",
            "Encoded : [26, 34, 35, 36, 37, 38, 39]\n",
            "Decoded : This text contains an unknown word: monkey\n",
            "Match   : ✓\n",
            "\n",
            "Original: \n",
            "Encoded : []\n",
            "Decoded : \n",
            "Match   : ✓\n",
            "\n",
            "Unknown Word Handling Test:\n",
            "Original: This text contains an unknown word: xylophone\n",
            "Encoded : [26, 34, 35, 36, 37, 38, 1]\n",
            "Decoded : This text contains an unknown word: <UNK>\n",
            "\n",
            "Special Tokens Test:\n",
            "Original: < SOS > This is a test sentence <EOS>\n",
            "Encoded : [1, 1, 1, 26, 27, 28, 1, 29, 3]\n",
            "Decoded : <UNK> <UNK> <UNK> This is a <UNK> sentence <EOS>\n",
            "\n",
            "Case Sensitivity Test:\n",
            "Original: The Quick Brown Fox\n",
            "Encoded : [4, 1, 1, 1]\n",
            "Decoded : The <UNK> <UNK> <UNK>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📚 TextDataset: Efficient Text Processing\n",
        "\n",
        "The TextDataset class is a crucial component in preparing text data for deep learning models, implementing a sliding window approach that allows processing of variable-length texts while maintaining context.\n",
        "\n",
        "This class bridges the gap between raw text data and the input requirements of neural networks, handling tasks such as tokenization, padding, and attention mask generation, which are essential for training effective sequence models like Transformers.\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   Padding and truncation [Link-huggingface](https://huggingface.co/docs/transformers/en/pad_truncation)\n"
      ],
      "metadata": {
        "id": "JS3le4cC6do5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts: List[str], tokenizer: SimpleTokenizer, max_length: int, overlap: int = 50):\n",
        "        \"\"\"\n",
        "        Initialize the TextDataset with sliding window functionality.\n",
        "\n",
        "        Args:\n",
        "            texts (List[str]): List of input texts.\n",
        "            tokenizer (SimpleTokenizer): Tokenizer object for encoding texts.\n",
        "            max_length (int): Maximum length of encoded sequences.\n",
        "            overlap (int): Number of overlapping tokens between windows.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.overlap = overlap\n",
        "        self.data = []\n",
        "        self.attention_masks = []\n",
        "        self.document_map = []  # Maps each window to its original document\n",
        "        self.original_texts = texts  # Store original texts\n",
        "\n",
        "        for doc_idx, text in enumerate(texts):\n",
        "            tokens = self.tokenizer.encode(text)\n",
        "            windows = self.create_sliding_windows(tokens)\n",
        "\n",
        "            for window in windows:\n",
        "                attention_mask = [1] * len(window)  # 1 for real tokens\n",
        "\n",
        "                # Pad if necessary\n",
        "                if len(window) < max_length:\n",
        "                    padding_length = max_length - len(window)\n",
        "                    window = window + [self.tokenizer.word_to_idx[\"<PAD>\"]] * padding_length\n",
        "                    attention_mask = attention_mask + [0] * padding_length  # 0 for padding in attention mask\n",
        "\n",
        "                self.data.append(window)\n",
        "                self.attention_masks.append(attention_mask)\n",
        "                self.document_map.append(doc_idx)\n",
        "\n",
        "    def create_sliding_windows(self, tokens: List[int]) -> List[List[int]]:\n",
        "        \"\"\"\n",
        "        Create sliding windows from a list of tokens.\n",
        "\n",
        "        Args:\n",
        "            tokens (List[int]): List of token ids.\n",
        "\n",
        "        Returns:\n",
        "            List[List[int]]: List of token windows.\n",
        "        \"\"\"\n",
        "        windows = []\n",
        "        # Calculate stride: how many tokens to move for each new window\n",
        "        # -1 accounts for the added <SOS> token at the start of each window\n",
        "        stride = self.max_length - self.overlap - 1\n",
        "\n",
        "        for start in range(0, len(tokens), stride):\n",
        "            # Create a window starting with <SOS> token\n",
        "            window = [self.tokenizer.word_to_idx[\"<SOS>\"]] + tokens[start:start + self.max_length - 1]\n",
        "            if len(window) < self.max_length:\n",
        "                # This is the last window, add <EOS> token\n",
        "                window.append(self.tokenizer.word_to_idx[\"<EOS>\"])\n",
        "            windows.append(window)\n",
        "\n",
        "        return windows\n",
        "\n",
        "    def get_original_document(self, doc_idx: int) -> str:\n",
        "        \"\"\"Retrieve the original document text.\"\"\"\n",
        "        if 0 <= doc_idx < len(self.original_texts):\n",
        "            return self.original_texts[doc_idx]\n",
        "        else:\n",
        "            raise IndexError(f\"Document index {doc_idx} is out of range.\")\n",
        "\n",
        "    def get_document_length(self, doc_idx: int) -> int:\n",
        "        \"\"\"Get the number of tokens in the original document.\"\"\"\n",
        "        if 0 <= doc_idx < len(self.original_texts):\n",
        "            return len(self.tokenizer.encode(self.original_texts[doc_idx]))\n",
        "        else:\n",
        "            raise IndexError(f\"Document index {doc_idx} is out of range.\")\n",
        "\n",
        "    def window_to_document_position(self, window_idx: int, token_idx: int) -> Tuple[int, int]:\n",
        "        \"\"\"Map a position in a window back to its position in the original document.\"\"\"\n",
        "        if 0 <= window_idx < len(self.data):\n",
        "            doc_idx = self.document_map[window_idx]\n",
        "            doc_windows = self.get_document_windows(doc_idx)\n",
        "            # Find which window of the document this is\n",
        "            relative_window_idx = doc_windows.index(window_idx)\n",
        "            # Calculate the start position of this window in the document\n",
        "            window_start = relative_window_idx * (self.max_length - self.overlap - 1)\n",
        "            # -1 to account for <SOS> token at the start of each window\n",
        "            return doc_idx, window_start + token_idx - 1\n",
        "        else:\n",
        "            raise IndexError(f\"Window index {window_idx} is out of range.\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Get the number of windows in the dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "        \"\"\"\n",
        "        Get a sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "                A tuple containing (token_ids, attention_mask, document_index).\n",
        "        \"\"\"\n",
        "        if 0 <= idx < len(self.data):\n",
        "            # Add an extra dimension to make it batch-first (batch_size=1)\n",
        "            return (torch.tensor(self.data[idx]).unsqueeze(0),\n",
        "                    torch.tensor(self.attention_masks[idx]).unsqueeze(0),\n",
        "                    self.document_map[idx])\n",
        "        else:\n",
        "            raise IndexError(f\"Index {idx} is out of range.\")\n",
        "\n",
        "\n",
        "    def get_document_windows(self, doc_idx: int) -> List[int]:\n",
        "        \"\"\"\n",
        "        Get all window indices for a specific document.\n",
        "\n",
        "        Args:\n",
        "            doc_idx (int): Index of the document.\n",
        "\n",
        "        Returns:\n",
        "            List[int]: List of window indices belonging to the document.\n",
        "        \"\"\"\n",
        "        return [i for i, doc in enumerate(self.document_map) if doc == doc_idx]"
      ],
      "metadata": {
        "id": "CeBCUMY16jms"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Dataset Processing\n",
        "\n",
        "This testing function shows how the TextDataset and SimpleTokenizer classes work together."
      ],
      "metadata": {
        "id": "QMa3_yaQgAYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sliding_window_dataset():\n",
        "    print(\"\\n--- Testing Sliding Window Dataset ---\\n\")\n",
        "\n",
        "    texts = [\n",
        "        \"This is a short sentence.\",\n",
        "        \"This is a much longer sentence that will be split into multiple windows to demonstrate the sliding window approach. It contains enough tokens to create at least two or three windows depending on the chosen maximum length and overlap.\",\n",
        "        \"Another sentence of medium length that might create two windows.\",\n",
        "        \"\",  # Empty text to test edge case\n",
        "        \"Short.\"  # Very short text to test edge case\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        tokenizer = SimpleTokenizer()\n",
        "        tokenizer.fit(texts)\n",
        "\n",
        "        max_length = 16\n",
        "        overlap = 5\n",
        "        dataset = TextDataset(texts, tokenizer, max_length, overlap)\n",
        "\n",
        "        print(f\"Dataset configuration:\")\n",
        "        print(f\"  Max length: {max_length}\")\n",
        "        print(f\"  Overlap: {overlap}\")\n",
        "        print(f\"  Total windows: {len(dataset)}\")\n",
        "        print(f\"  Vocabulary size: {len(tokenizer)}\\n\")\n",
        "\n",
        "        for doc_idx, text in enumerate(texts):\n",
        "            print(f\"Document {doc_idx}:\")\n",
        "            print(f\"  Original text: '{text}'\")\n",
        "            print(f\"  Original length: {len(text.split())}\")\n",
        "\n",
        "            window_indices = dataset.get_document_windows(doc_idx)\n",
        "            print(f\"  Number of windows: {len(window_indices)}\")\n",
        "\n",
        "            for i, window_idx in enumerate(window_indices):\n",
        "                tokens, attention_mask, _ = dataset[window_idx]\n",
        "                # Remove the batch dimension for decoding\n",
        "                decoded = tokenizer.decode(tokens.squeeze(0).tolist())\n",
        "                print(f\"\\n    Window {i}:\")\n",
        "                print(f\"    Tokens shape: {tokens.shape}\")\n",
        "                print(f\"    Tokens: {tokens.squeeze(0).tolist()}\")\n",
        "                print(f\"    Attention mask shape: {attention_mask.shape}\")\n",
        "                print(f\"    Attention mask: {attention_mask.squeeze(0).tolist()}\")\n",
        "                print(f\"    Decoded: '{decoded}'\")\n",
        "                print(f\"    Window length: {tokens.size(1)}\")  # Use size(1) for sequence length\n",
        "\n",
        "            print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "        tokenizer.show_vocab()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    print(\"\\n--- End of Test ---\")\n",
        "\n",
        "# Run the test\n",
        "test_sliding_window_dataset()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AwEtTxasgHC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922f645a-6fc9-417e-d2d0-976791a9e3df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Sliding Window Dataset ---\n",
            "\n",
            "Dataset configuration:\n",
            "  Max length: 16\n",
            "  Overlap: 5\n",
            "  Total windows: 7\n",
            "  Vocabulary size: 48\n",
            "\n",
            "Document 0:\n",
            "  Original text: 'This is a short sentence.'\n",
            "  Original length: 5\n",
            "  Number of windows: 1\n",
            "\n",
            "    Window 0:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 4, 5, 6, 7, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    Decoded: '<SOS> This is a short sentence. <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "    Window length: 16\n",
            "\n",
            "--------------------------------------------------\n",
            "Document 1:\n",
            "  Original text: 'This is a much longer sentence that will be split into multiple windows to demonstrate the sliding window approach. It contains enough tokens to create at least two or three windows depending on the chosen maximum length and overlap.'\n",
            "  Original length: 39\n",
            "  Number of windows: 4\n",
            "\n",
            "    Window 0:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "    Decoded: '<SOS> This is a much longer sentence that will be split into multiple windows to demonstrate'\n",
            "    Window length: 16\n",
            "\n",
            "    Window 1:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 19, 29]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "    Decoded: '<SOS> into multiple windows to demonstrate the sliding window approach. It contains enough tokens to create'\n",
            "    Window length: 16\n",
            "\n",
            "    Window 2:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 26, 27, 28, 19, 29, 30, 31, 32, 33, 34, 18, 35, 36, 21, 37]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "    Decoded: '<SOS> contains enough tokens to create at least two or three windows depending on the chosen'\n",
            "    Window length: 16\n",
            "\n",
            "    Window 3:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 18, 35, 36, 21, 37, 38, 39, 40, 41, 3, 0, 0, 0, 0, 0]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "    Decoded: '<SOS> windows depending on the chosen maximum length and overlap. <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "    Window length: 16\n",
            "\n",
            "--------------------------------------------------\n",
            "Document 2:\n",
            "  Original text: 'Another sentence of medium length that might create two windows.'\n",
            "  Original length: 10\n",
            "  Number of windows: 1\n",
            "\n",
            "    Window 0:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 42, 11, 43, 44, 39, 12, 45, 29, 32, 46, 3, 0, 0, 0, 0]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "    Decoded: '<SOS> Another sentence of medium length that might create two windows. <EOS> <PAD> <PAD> <PAD> <PAD>'\n",
            "    Window length: 16\n",
            "\n",
            "--------------------------------------------------\n",
            "Document 3:\n",
            "  Original text: ''\n",
            "  Original length: 0\n",
            "  Number of windows: 0\n",
            "\n",
            "--------------------------------------------------\n",
            "Document 4:\n",
            "  Original text: 'Short.'\n",
            "  Original length: 1\n",
            "  Number of windows: 1\n",
            "\n",
            "    Window 0:\n",
            "    Tokens shape: torch.Size([1, 16])\n",
            "    Tokens: [2, 47, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    Attention mask shape: torch.Size([1, 16])\n",
            "    Attention mask: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    Decoded: '<SOS> Short. <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "    Window length: 16\n",
            "\n",
            "--------------------------------------------------\n",
            "Vocabulary:\n",
            "<PAD>: 0\n",
            "<UNK>: 1\n",
            "<SOS>: 2\n",
            "<EOS>: 3\n",
            "This: 4\n",
            "is: 5\n",
            "a: 6\n",
            "short: 7\n",
            "sentence.: 8\n",
            "much: 9\n",
            "longer: 10\n",
            "sentence: 11\n",
            "that: 12\n",
            "will: 13\n",
            "be: 14\n",
            "split: 15\n",
            "into: 16\n",
            "multiple: 17\n",
            "windows: 18\n",
            "to: 19\n",
            "demonstrate: 20\n",
            "the: 21\n",
            "sliding: 22\n",
            "window: 23\n",
            "approach.: 24\n",
            "It: 25\n",
            "contains: 26\n",
            "enough: 27\n",
            "tokens: 28\n",
            "create: 29\n",
            "at: 30\n",
            "least: 31\n",
            "two: 32\n",
            "or: 33\n",
            "three: 34\n",
            "depending: 35\n",
            "on: 36\n",
            "chosen: 37\n",
            "maximum: 38\n",
            "length: 39\n",
            "and: 40\n",
            "overlap.: 41\n",
            "Another: 42\n",
            "of: 43\n",
            "medium: 44\n",
            "might: 45\n",
            "windows.: 46\n",
            "Short.: 47\n",
            "\n",
            "--- End of Test ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Positional Encoding\n",
        "\n",
        "Positional Encoding adds information about the position of each token in the sequence. This is necessary because the self-attention mechanism in Transformers doesn't inherently have a notion of token order.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   Transformer Architecture: The Positional Encoding [Link-kazemnejad](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)\n",
        "\n",
        "*   Positional Encoding in Transformers [Link-geeksforgeeks](https://www.geeksforgeeks.org/positional-encoding-in-transformers/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BHKvbddC6lpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
        "        # Used for tensors that need to be on the same device as the module.\n",
        "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "70Yf8eWK_EvY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Positional Encoding for Text"
      ],
      "metadata": {
        "id": "vcOi9vZdmc1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_positional_encoding_with_dataset():\n",
        "    print(\"\\n--- Testing Positional Encoding with Dataset ---\\n\")\n",
        "\n",
        "    # Set a fixed seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Sample texts\n",
        "    texts = [\n",
        "        \"This is a short sentence.\",\n",
        "        \"This is a much longer sentence that will be split into multiple windows. Observe the term overlapping?\",\n",
        "        \"Another sentence of medium length.\"\n",
        "    ]\n",
        "\n",
        "    # Initialize tokenizer and fit it to the texts\n",
        "    tokenizer = SimpleTokenizer()\n",
        "    tokenizer.fit(texts)\n",
        "\n",
        "    # Create dataset\n",
        "    max_length = 10\n",
        "    overlap = 2\n",
        "    dataset = TextDataset(texts, tokenizer, max_length, overlap)\n",
        "\n",
        "    # Initialize positional encoding\n",
        "    d_model = 16  # Small dimension for demonstration\n",
        "    pos_encoder = PositionalEncoding(d_model, max_length)\n",
        "\n",
        "    print(f\"Dataset configuration:\")\n",
        "    print(f\"  Max length: {max_length}\")\n",
        "    print(f\"  Overlap: {overlap}\")\n",
        "    print(f\"  Total windows: {len(dataset)}\")\n",
        "    print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
        "    print(f\"  Embedding dimension: {d_model}\\n\")\n",
        "\n",
        "    # Process each window through the positional encoding\n",
        "    for i in range(len(dataset)):\n",
        "        tokens, attention_mask, doc_idx = dataset[i]\n",
        "\n",
        "        # Convert tokens to \"embeddings\" (just for demonstration)\n",
        "        pseudo_embeddings = torch.rand(1, tokens.size(1), d_model)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Apply positional encoding\n",
        "        encoded = pos_encoder(pseudo_embeddings)\n",
        "\n",
        "        print(f\"Window {i} (from document {doc_idx}):\")\n",
        "        print(f\"  Original tokens: {tokens.squeeze(0).tolist()}\")\n",
        "        print(f\"  Attention mask: {attention_mask.squeeze(0).tolist()}\")\n",
        "        print(f\"  Decoded: '{tokenizer.decode(tokens.squeeze(0).tolist())}'\")\n",
        "        print(f\"  Shape after positional encoding: {encoded.shape}\")\n",
        "\n",
        "        # Display the positional encoding effect for all tokens\n",
        "        print(f\"  Positional encoding effect:\")\n",
        "        for j in range(tokens.size(1)):\n",
        "            if attention_mask[0, j] == 1:  # Only show for non-padding tokens\n",
        "                print(f\"    Token {j}:\")\n",
        "                print(f\"      Before: {pseudo_embeddings[0, j, :].tolist()}\")\n",
        "                print(f\"      After:  {encoded[0, j, :].tolist()}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(\"--- End of Test ---\")\n",
        "\n",
        "# Run the test\n",
        "test_positional_encoding_with_dataset()"
      ],
      "metadata": {
        "id": "jOzH22PBmfyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ff1dfa-27db-4348-fe10-c8756759afd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Positional Encoding with Dataset ---\n",
            "\n",
            "Dataset configuration:\n",
            "  Max length: 10\n",
            "  Overlap: 2\n",
            "  Total windows: 5\n",
            "  Vocabulary size: 27\n",
            "  Embedding dimension: 16\n",
            "\n",
            "Window 0 (from document 0):\n",
            "  Original tokens: [2, 4, 5, 6, 7, 8, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> This is a short sentence. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Positional encoding effect:\n",
            "    Token 0:\n",
            "      Before: [0.8822692632675171, 0.9150039553642273, 0.38286375999450684, 0.9593056440353394, 0.3904482126235962, 0.600895345211029, 0.2565724849700928, 0.7936413288116455, 0.9407714605331421, 0.13318592309951782, 0.9345980882644653, 0.5935796499252319, 0.8694044351577759, 0.5677152872085571, 0.7410940527915955, 0.42940449714660645]\n",
            "      After:  [0.8822692632675171, 1.915004014968872, 0.38286375999450684, 1.9593056440353394, 0.3904482126235962, 1.6008954048156738, 0.2565724849700928, 1.7936413288116455, 0.9407714605331421, 1.133185863494873, 0.9345980882644653, 1.593579649925232, 0.8694044351577759, 1.5677152872085571, 0.7410940527915955, 1.4294044971466064]\n",
            "    Token 1:\n",
            "      Before: [0.8854429125785828, 0.5739044547080994, 0.2665800452232361, 0.6274491548538208, 0.26963168382644653, 0.4413635730743408, 0.2969208359718323, 0.831685483455658, 0.10531491041183472, 0.26949483156204224, 0.3588126301765442, 0.19936376810073853, 0.5471915602684021, 0.006160438060760498, 0.951554536819458, 0.07526588439941406]\n",
            "      After:  [1.7269139289855957, 1.1142067909240723, 0.5775636434555054, 1.577864408493042, 0.3694651126861572, 1.4363677501678467, 0.32853832840919495, 1.8311855792999268, 0.11531474441289902, 1.2694448232650757, 0.36197489500045776, 1.1993587017059326, 0.5481915473937988, 1.006160020828247, 0.9518707394599915, 1.075265884399414]\n",
            "    Token 2:\n",
            "      Before: [0.8860136866569519, 0.5832095742225647, 0.3376477360725403, 0.8089749813079834, 0.5779253840446472, 0.9039816856384277, 0.5546598434448242, 0.34231340885162354, 0.634341835975647, 0.36441028118133545, 0.710428774356842, 0.9464110732078552, 0.7890297770500183, 0.281413733959198, 0.788632333278656, 0.5894631147384644]\n",
            "      After:  [1.7953110933303833, 0.16706272959709167, 0.9287748336791992, 1.615553379058838, 0.7765946984291077, 1.8840482234954834, 0.6178632378578186, 1.3403141498565674, 0.6543405055999756, 1.3642103672027588, 0.7167533040046692, 1.9463911056518555, 0.7910297513008118, 1.2814117670059204, 0.7892647981643677, 1.5894629955291748]\n",
            "    Token 3:\n",
            "      Before: [0.7539175152778625, 0.19524747133255005, 0.005045771598815918, 0.30681973695755005, 0.11648857593536377, 0.9102694392204285, 0.6440156698226929, 0.7071067690849304, 0.6581305861473083, 0.4913020133972168, 0.8913041353225708, 0.1447432041168213, 0.5314818620681763, 0.1587299108505249, 0.6541759967803955, 0.32780885696411133]\n",
            "      After:  [0.8950375318527222, -0.7947450280189514, 0.8176946640014648, 0.8895733952522278, 0.41200876235961914, 1.8656059503555298, 0.7387417554855347, 1.7026101350784302, 0.6881260871887207, 1.4908521175384521, 0.900790810585022, 1.144698143005371, 0.5344818830490112, 1.1587255001068115, 0.6551246643066406, 1.3278083801269531]\n",
            "    Token 4:\n",
            "      Before: [0.6532081365585327, 0.3958292603492737, 0.9146959185600281, 0.20364904403686523, 0.20180100202560425, 0.20178300142288208, 0.9497213959693909, 0.6666255593299866, 0.9811253547668457, 0.08736187219619751, 0.00406193733215332, 0.10881811380386353, 0.16365545988082886, 0.7025200724601746, 0.6790379285812378, 0.9154621958732605]\n",
            "      After:  [-0.10359436273574829, -0.25781434774398804, 1.868276596069336, 0.504786491394043, 0.5912193059921265, 1.1228439807891846, 1.0758755207061768, 1.658636212348938, 1.021114706993103, 1.086561918258667, 0.016710706055164337, 1.1087381839752197, 0.16765545308589935, 1.7025120258331299, 0.6803028583526611, 1.9154614210128784]\n",
            "    Token 5:\n",
            "      Before: [0.24178731441497803, 0.1591441035270691, 0.7652890682220459, 0.2978977560997009, 0.8034619092941284, 0.38134968280792236, 0.786022961139679, 0.11151599884033203, 0.2476751208305359, 0.652438223361969, 0.6057037711143494, 0.3725206255912781, 0.7980347275733948, 0.8399046063423157, 0.13741332292556763, 0.2330659031867981]\n",
            "      After:  [-0.7171369791030884, 0.44280630350112915, 1.7652356624603271, 0.28755542635917664, 1.2828874588012695, 1.2589322328567505, 0.9434788227081299, 1.0990419387817383, 0.29765427112579346, 1.6511884927749634, 0.6215144991874695, 1.372395634651184, 0.8030347228050232, 1.8398921489715576, 0.13899445533752441, 1.2330646514892578]\n",
            "    Token 6:\n",
            "      Before: [0.9578309655189514, 0.3312837481498718, 0.3227418065071106, 0.016202688217163086, 0.21366488933563232, 0.6249018311500549, 0.43400341272354126, 0.13705700635910034, 0.5117283463478088, 0.15845924615859985, 0.07580167055130005, 0.2246686816215515, 0.06239396333694458, 0.1816309690475464, 0.9998044371604919, 0.5944374799728394]\n",
            "      After:  [0.6784154772758484, 1.2914540767669678, 1.2698900699615479, -0.3045937120914459, 0.778307318687439, 1.450237512588501, 0.6226036548614502, 1.1191109418869019, 0.5716923475265503, 1.1566598415374756, 0.09477419406175613, 1.2244887351989746, 0.06839393079280853, 1.1816129684448242, 1.001701831817627, 1.594435691833496]\n",
            "\n",
            "Window 1 (from document 1):\n",
            "  Original tokens: [2, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> This is a much longer sentence that will be'\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Positional encoding effect:\n",
            "    Token 0:\n",
            "      Before: [0.9544757604598999, 0.6098752021789551, 0.5643200278282166, 0.05937260389328003, 0.7098942399024963, 0.4249897003173828, 0.27093786001205444, 0.9294732809066772, 0.6114743947982788, 0.2233617901802063, 0.2469305396080017, 0.4761221408843994, 0.779180645942688, 0.3722330927848816, 0.21471256017684937, 0.32877856492996216]\n",
            "      After:  [0.9544757604598999, 1.609875202178955, 0.5643200278282166, 1.0593726634979248, 0.7098942399024963, 1.4249897003173828, 0.27093786001205444, 1.9294732809066772, 0.6114743947982788, 1.2233617305755615, 0.2469305396080017, 1.4761221408843994, 0.779180645942688, 1.3722331523895264, 0.21471256017684937, 1.3287785053253174]\n",
            "    Token 1:\n",
            "      Before: [0.12646257877349854, 0.6783162355422974, 0.8870201110839844, 0.02927982807159424, 0.6161253452301025, 0.7582958936691284, 0.5906646847724915, 0.3219376802444458, 0.7609710693359375, 0.7627565860748291, 0.6869636178016663, 0.41213929653167725, 0.36759936809539795, 0.5534904599189758, 0.4116729497909546, 0.35099947452545166]\n",
            "      After:  [0.9679335355758667, 1.218618631362915, 1.1980037689208984, 0.9796951413154602, 0.7159587740898132, 1.7533000707626343, 0.6222822070121765, 1.3214377164840698, 0.77097088098526, 1.7627065181732178, 0.6901258826255798, 1.4121342897415161, 0.3685993552207947, 1.5534899234771729, 0.4119891822338104, 1.350999355316162]\n",
            "    Token 2:\n",
            "      Before: [0.819603443145752, 0.9296997785568237, 0.45050132274627686, 0.3880515694618225, 0.5072961449623108, 0.4701458811759949, 0.6202056407928467, 0.640116810798645, 0.045871615409851074, 0.31548112630844116, 0.9210647344589233, 0.6947774887084961, 0.47513121366500854, 0.1985471248626709, 0.19409745931625366, 0.052116572856903076]\n",
            "      After:  [1.7289009094238281, 0.5135529041290283, 1.041628360748291, 1.1946299076080322, 0.7059654593467712, 1.4502124786376953, 0.6834090352058411, 1.6381175518035889, 0.06587028503417969, 1.3152811527252197, 0.9273892641067505, 1.6947574615478516, 0.4771312177181244, 1.198545217514038, 0.19472990930080414, 1.0521163940429688]\n",
            "    Token 3:\n",
            "      Before: [0.33701878786087036, 0.6688520908355713, 0.8188108205795288, 0.7308486700057983, 0.05802798271179199, 0.1993187665939331, 0.4210916757583618, 0.9836747646331787, 0.5723287463188171, 0.3705146312713623, 0.7068576216697693, 0.3095592260360718, 0.17637217044830322, 0.8649436235427856, 0.2726491093635559, 0.39976662397384644]\n",
            "      After:  [0.47813880443573, -0.3211404085159302, 1.6314597129821777, 1.313602328300476, 0.35354816913604736, 1.1546552181243896, 0.5158177614212036, 1.9791781902313232, 0.6023242473602295, 1.3700647354125977, 0.7163442969322205, 1.3095142841339111, 0.1793721616268158, 1.8649392127990723, 0.2735978066921234, 1.399766206741333]\n",
            "    Token 4:\n",
            "      Before: [0.0025978684425354004, 0.834635317325592, 0.8788173198699951, 0.6822240948677063, 0.15136289596557617, 0.006530046463012695, 0.09391051530838013, 0.8728501200675964, 0.7400528788566589, 0.920752227306366, 0.7619349360466003, 0.6265460848808289, 0.495103657245636, 0.11974698305130005, 0.07161390781402588, 0.032325685024261475]\n",
            "      After:  [-0.7542046308517456, 0.18099170923233032, 1.8323980569839478, 0.9833616018295288, 0.5407812595367432, 0.9275910258293152, 0.22006458044052124, 1.8648607730865479, 0.7800422310829163, 1.919952392578125, 0.7745836973190308, 1.6264660358428955, 0.4991036355495453, 1.119739055633545, 0.07287881523370743, 1.0323249101638794]\n",
            "    Token 5:\n",
            "      Before: [0.7046809792518616, 0.25451600551605225, 0.39937371015548706, 0.21224737167358398, 0.40888822078704834, 0.14808255434036255, 0.1732921600341797, 0.6658554077148438, 0.35140180587768555, 0.8086715936660767, 0.33959561586380005, 0.13321638107299805, 0.41178053617477417, 0.2576262950897217, 0.3470292091369629, 0.02400219440460205]\n",
            "      After:  [-0.25424331426620483, 0.5381782054901123, 1.3993202447891235, 0.2019050270318985, 0.8883137702941895, 1.025665044784546, 0.3307480216026306, 1.65338134765625, 0.4013809561729431, 1.8074219226837158, 0.35540634393692017, 1.1330914497375488, 0.4167805016040802, 1.2576137781143188, 0.3486103415489197, 1.024000883102417]\n",
            "    Token 6:\n",
            "      Before: [0.7797454595565796, 0.15189772844314575, 0.7513088583946228, 0.7268921136856079, 0.8572163581848145, 0.1164739727973938, 0.8595983982086182, 0.2636241912841797, 0.6855345964431763, 0.9695573449134827, 0.4294840693473816, 0.4961332678794861, 0.38488471508026123, 0.08250772953033447, 0.7399514317512512, 0.003641068935394287]\n",
            "      After:  [0.5003299713134766, 1.1120679378509521, 1.6984570026397705, 0.4060957133769989, 1.421858787536621, 0.9418095946311951, 1.0481986999511719, 1.245678186416626, 0.7454985976219177, 1.9677579402923584, 0.4484565854072571, 1.4959533214569092, 0.390884667634964, 1.0824897289276123, 0.7418488264083862, 1.0036392211914062]\n",
            "    Token 7:\n",
            "      Before: [0.8103999495506287, 0.8741125464439392, 0.9728531837463379, 0.3820602297782898, 0.08917903900146484, 0.6124151349067688, 0.7762136459350586, 0.0023456215858459473, 0.38650816679000854, 0.20027226209640503, 0.4562681317329407, 0.25389325618743896, 0.2956162095069885, 0.3412705659866333, 0.024847984313964844, 0.9102537631988525]\n",
            "      After:  [1.4673864841461182, 1.6280148029327393, 1.7732747793197632, -0.21737724542617798, 0.7333966493606567, 1.3772573471069336, 0.995769739151001, 0.9779455065727234, 0.4564509987831116, 1.1978232860565186, 0.4784022569656372, 1.253648281097412, 0.302616149187088, 1.3412461280822754, 0.027061577886343002, 1.9102513790130615]\n",
            "    Token 8:\n",
            "      Before: [0.9191656112670898, 0.4215654730796814, 0.44305896759033203, 0.2959400415420532, 0.048468589782714844, 0.013427793979644775, 0.685829222202301, 0.2254769206047058, 0.1785615086555481, 0.4609884023666382, 0.3334944248199463, 0.3382396101951599, 0.5160655975341797, 0.39394378662109375, 0.3278437852859497, 0.2605970501899719]\n",
            "      After:  [1.9085237979888916, 0.2760654389858246, 1.0173767805099487, -0.5226923823356628, 0.7658246159553528, 0.7101345062255859, 0.9361215829849243, 1.1936471462249756, 0.258476197719574, 1.4577901363372803, 0.35878995060920715, 1.3379197120666504, 0.5240654945373535, 1.3939118385314941, 0.330373615026474, 1.2605938911437988]\n",
            "    Token 9:\n",
            "      Before: [0.09308630228042603, 0.9192535877227783, 0.2999064326286316, 0.6324897408485413, 0.3265170454978943, 0.5406306385993958, 0.9661502242088318, 0.7303613424301147, 0.06670016050338745, 0.6984513998031616, 0.9746214151382446, 0.6315416693687439, 0.8352123498916626, 0.9929437637329102, 0.42338550090789795, 0.6037772297859192]\n",
            "      After:  [0.5052047967910767, 0.008123338222503662, 0.5911656618118286, -0.32415443658828735, 1.1098439693450928, 1.1622406244277954, 1.2469285726547241, 1.690134048461914, 0.15657870471477509, 1.694404125213623, 1.0030781030654907, 1.6311366558074951, 0.8442122340202332, 1.992903232574463, 0.4262315332889557, 1.6037731170654297]\n",
            "\n",
            "Window 2 (from document 1):\n",
            "  Original tokens: [2, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> will be split into multiple windows. Observe the term'\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Positional encoding effect:\n",
            "    Token 0:\n",
            "      Before: [0.15248245000839233, 0.3969614505767822, 0.8702918887138367, 0.7563229203224182, 0.18360549211502075, 0.09905749559402466, 0.1583181619644165, 0.006561160087585449, 0.11418050527572632, 0.3763512969017029, 0.8374385833740234, 0.5836911201477051, 0.11969727277755737, 0.09888803958892822, 0.748737633228302, 0.128079354763031]\n",
            "      After:  [0.15248245000839233, 1.3969614505767822, 0.8702918887138367, 1.7563228607177734, 0.18360549211502075, 1.0990574359893799, 0.1583181619644165, 1.0065611600875854, 0.11418050527572632, 1.3763513565063477, 0.8374385833740234, 1.583691120147705, 0.11969727277755737, 1.0988880395889282, 0.748737633228302, 1.1280794143676758]\n",
            "    Token 1:\n",
            "      Before: [0.43843626976013184, 0.739853024482727, 0.268593966960907, 0.4454800486564636, 0.4564777612686157, 0.3817083239555359, 0.2464839220046997, 0.05428081750869751, 0.09582149982452393, 0.23226916790008545, 0.9829188585281372, 0.258492648601532, 0.16423600912094116, 0.6211971044540405, 0.637805163860321, 0.7739548683166504]\n",
            "      After:  [1.2799072265625, 1.2801554203033447, 0.5795775651931763, 1.3958953619003296, 0.5563111901283264, 1.3767125606536865, 0.2781014144420624, 1.0537807941436768, 0.10582133382558823, 1.2322192192077637, 0.9860811233520508, 1.2584877014160156, 0.16523601114749908, 1.6211966276168823, 0.6381213665008545, 1.7739548683166504]\n",
            "    Token 2:\n",
            "      Before: [0.8800601959228516, 0.778437077999115, 0.004249513149261475, 0.5443443059921265, 0.8028765320777893, 0.45378726720809937, 0.20536041259765625, 0.9766699075698853, 0.3129860758781433, 0.21532773971557617, 0.049222469329833984, 0.5223341584205627, 0.7215665578842163, 0.610681414604187, 0.5988748669624329, 0.12080627679824829]\n",
            "      After:  [1.7893576622009277, 0.36229023337364197, 0.5953766107559204, 1.350922703742981, 1.0015459060668945, 1.4338538646697998, 0.26856380701065063, 1.974670648574829, 0.3329847455024719, 1.21512770652771, 0.05554698035120964, 1.522314190864563, 0.7235665321350098, 1.6106793880462646, 0.5995073318481445, 1.120806097984314]\n",
            "    Token 3:\n",
            "      Before: [0.03305637836456299, 0.5088046789169312, 0.9559170603752136, 0.7884606719017029, 0.2088828682899475, 0.43509572744369507, 0.1314082145690918, 0.2587882876396179, 0.5905491709709167, 0.7722692489624023, 0.9141846299171448, 0.04094696044921875, 0.8343076109886169, 0.14735394716262817, 0.6872336268424988, 0.9231226444244385]\n",
            "      After:  [0.1741763800382614, -0.4811878204345703, 1.7685658931732178, 1.3712143898010254, 0.5044030547142029, 1.3904322385787964, 0.2261343002319336, 1.2542916536331177, 0.6205446720123291, 1.7718193531036377, 0.923671305179596, 1.0409018993377686, 0.8373076319694519, 1.14734947681427, 0.6881822943687439, 1.9231221675872803]\n",
            "    Token 4:\n",
            "      Before: [0.5070211887359619, 0.9549044966697693, 0.07397425174713135, 0.30902040004730225, 0.7916264533996582, 0.3910660743713379, 0.397649884223938, 0.2916041612625122, 0.8446530699729919, 0.7452515959739685, 0.6602250337600708, 0.21901816129684448, 0.09412521123886108, 0.5540803074836731, 0.6481394171714783, 0.26914405822753906]\n",
            "      After:  [-0.2497813105583191, 0.30126088857650757, 1.027554988861084, 0.61015784740448, 1.1810448169708252, 1.3121271133422852, 0.5238039493560791, 1.2836148738861084, 0.8846424221992493, 1.7444517612457275, 0.6728737950325012, 1.2189381122589111, 0.09812519699335098, 1.554072380065918, 0.6494043469429016, 1.2691433429718018]\n",
            "    Token 5:\n",
            "      Before: [0.3601011633872986, 0.8376838564872742, 0.5398298501968384, 0.5225591659545898, 0.3769497275352478, 0.04720515012741089, 0.02987128496170044, 0.26099246740341187, 0.24583929777145386, 0.6557767987251282, 0.35444462299346924, 0.30438894033432007, 0.9767149090766907, 0.674161434173584, 0.856451153755188, 0.25794363021850586]\n",
            "      After:  [-0.5988231301307678, 1.1213459968566895, 1.53977632522583, 0.5122168064117432, 0.8563752174377441, 0.924787700176239, 0.18732716143131256, 1.248518466949463, 0.2958184480667114, 1.6545270681381226, 0.37025535106658936, 1.304263949394226, 0.9817149043083191, 1.6741489171981812, 0.8580322861671448, 1.2579424381256104]\n",
            "    Token 6:\n",
            "      Before: [0.29576659202575684, 0.6837702393531799, 0.16686242818832397, 0.17314797639846802, 0.4758501648902893, 0.31711965799331665, 0.1251710057258606, 0.7965794801712036, 0.9020814299583435, 0.5811116695404053, 0.41294336318969727, 0.036863505840301514, 0.31788063049316406, 0.627292811870575, 0.7357654571533203, 0.43679124116897583]\n",
            "      After:  [0.01635110378265381, 1.6439404487609863, 1.1140105724334717, -0.147648423910141, 1.0404925346374512, 1.1424553394317627, 0.3137712776660919, 1.7786333560943604, 0.962045431137085, 1.5793122053146362, 0.43191587924957275, 1.0366835594177246, 0.3238805830478668, 1.627274751663208, 0.7376628518104553, 1.4367895126342773]\n",
            "    Token 7:\n",
            "      Before: [0.302323579788208, 0.7786130309104919, 0.10180014371871948, 0.816008985042572, 0.306022584438324, 0.5076526999473572, 0.4011920690536499, 0.5606194734573364, 0.34890079498291016, 0.8635634779930115, 0.4870014190673828, 0.8902997374534607, 0.9807402491569519, 0.2564045190811157, 0.1352454423904419, 0.9011510014533997]\n",
            "      After:  [0.9593101739883423, 1.532515287399292, 0.9022217392921448, 0.21657150983810425, 0.9502401947975159, 1.272494912147522, 0.6207481622695923, 1.5362193584442139, 0.4188436269760132, 1.861114501953125, 0.5091355443000793, 1.890054702758789, 0.9877402186393738, 1.2563800811767578, 0.13745903968811035, 1.9011485576629639]\n",
            "    Token 8:\n",
            "      Before: [0.891806960105896, 0.11822634935379028, 0.46134835481643677, 0.006936848163604736, 0.09070044755935669, 0.5965712666511536, 0.6330173015594482, 0.6059905290603638, 0.36391764879226685, 0.9612888693809509, 0.5714889764785767, 0.20495760440826416, 0.47169309854507446, 0.620072603225708, 0.675096333026886, 0.14645957946777344]\n",
            "      After:  [1.8811652660369873, -0.02727368474006653, 1.0356662273406982, -0.8116955757141113, 0.8080564737319946, 1.2932779788970947, 0.8833096027374268, 1.5741608142852783, 0.4438323378562927, 1.9580905437469482, 0.5967844724655151, 1.2046376466751099, 0.4796930253505707, 1.6200406551361084, 0.6776261329650879, 1.1464563608169556]\n",
            "    Token 9:\n",
            "      Before: [0.6873947978019714, 0.2445591688156128, 0.0845298171043396, 0.2268962860107422, 0.9822046756744385, 0.9274289011955261, 0.947742223739624, 0.7935056090354919, 0.8777247667312622, 0.4330751299858093, 0.22488605976104736, 0.7498282790184021, 0.24090862274169922, 0.16256707906723022, 0.3403329849243164, 0.6049296259880066]\n",
            "      After:  [1.099513292312622, -0.6665710806846619, 0.3757890462875366, -0.7297478914260864, 1.7655315399169922, 1.5490388870239258, 1.2285205125808716, 1.7532782554626465, 0.967603325843811, 1.429027795791626, 0.25334271788597107, 1.7494232654571533, 0.24990850687026978, 1.1625266075134277, 0.34317901730537415, 1.6049256324768066]\n",
            "\n",
            "Window 3 (from document 1):\n",
            "  Original tokens: [2, 20, 21, 22, 3, 0, 0, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Decoded: '<SOS> the term overlapping? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Positional encoding effect:\n",
            "    Token 0:\n",
            "      Before: [0.7573983073234558, 0.30579549074172974, 0.20571684837341309, 0.5674465298652649, 0.20528340339660645, 0.17446929216384888, 0.760625958442688, 0.4160076975822449, 0.9568924903869629, 0.9863913059234619, 0.6495527625083923, 0.6720788478851318, 0.6151418685913086, 0.5078304409980774, 0.46363377571105957, 0.5068720579147339]\n",
            "      After:  [0.7573983073234558, 1.305795431137085, 0.20571684837341309, 1.5674464702606201, 0.20528340339660645, 1.174469232559204, 0.760625958442688, 1.4160077571868896, 0.9568924903869629, 1.986391305923462, 0.6495527625083923, 1.6720788478851318, 0.6151418685913086, 1.5078303813934326, 0.46363377571105957, 1.5068720579147339]\n",
            "    Token 1:\n",
            "      Before: [0.686712384223938, 0.964885413646698, 0.3704204559326172, 0.28864210844039917, 0.3789175748825073, 0.2584378719329834, 0.5850193500518799, 0.8732241988182068, 0.8909887075424194, 0.7295627593994141, 0.13203424215316772, 0.23164761066436768, 0.3901442885398865, 0.4078379273414612, 0.5411238670349121, 0.041014254093170166]\n",
            "      After:  [1.5281833410263062, 1.505187749862671, 0.6814040541648865, 1.2390574216842651, 0.478751003742218, 1.2534420490264893, 0.6166368722915649, 1.8727242946624756, 0.9009885191917419, 1.7295126914978027, 0.1351965069770813, 1.2316426038742065, 0.3911442756652832, 1.4078373908996582, 0.5414400696754456, 1.0410141944885254]\n",
            "    Token 2:\n",
            "      Before: [0.6556223630905151, 0.1185639500617981, 0.1836276650428772, 0.08430874347686768, 0.9356598258018494, 0.026530086994171143, 0.8771833777427673, 0.4831915497779846, 0.44185060262680054, 0.8127392530441284, 0.4537861943244934, 0.8135770559310913, 0.8615074753761292, 0.0658949613571167, 0.6923919916152954, 0.5943894982337952]\n",
            "      After:  [1.5649197101593018, -0.2975828945636749, 0.7747547626495361, 0.8908871412277222, 1.134329080581665, 1.0065966844558716, 0.9403867721557617, 1.4811922311782837, 0.46184927225112915, 1.8125393390655518, 0.46011069416999817, 1.8135571479797363, 0.8635074496269226, 1.0658929347991943, 0.6930244565010071, 1.5943893194198608]\n",
            "    Token 3:\n",
            "      Before: [0.6075058579444885, 0.5729957222938538, 0.6367654800415039, 0.25946658849716187, 0.43602943420410156, 0.975059986114502, 0.8359247446060181, 0.48121577501296997, 0.029734551906585693, 0.5219138860702515, 0.15951323509216309, 0.906595766544342, 0.19645631313323975, 0.4638991951942444, 0.3890286684036255, 0.5889769196510315]\n",
            "      After:  [0.7486258745193481, -0.4169967770576477, 1.4494143724441528, 0.8422202467918396, 0.7315496206283569, 1.930396556854248, 0.9306508302688599, 1.4767191410064697, 0.05973005294799805, 1.5214638710021973, 0.16899992525577545, 1.9065507650375366, 0.19945630431175232, 1.4638947248458862, 0.389977365732193, 1.588976502418518]\n",
            "    Token 4:\n",
            "      Before: [0.9705138206481934, 0.5475096106529236, 0.7895820140838623, 0.8881108164787292, 0.9036555886268616, 0.3273242712020874, 0.3881716728210449, 0.7409688830375671, 0.36356616020202637, 0.7341319918632507, 0.3907661437988281, 0.16087383031845093, 0.7035216689109802, 0.5766590237617493, 0.7229241728782654, 0.9967430233955383]\n",
            "      After:  [0.21371132135391235, -0.10613399744033813, 1.743162751197815, 1.1892483234405518, 1.2930738925933838, 1.2483851909637451, 0.514325737953186, 1.7329795360565186, 0.4035554826259613, 1.7333321571350098, 0.40341490507125854, 1.1607937812805176, 0.7075216770172119, 1.5766510963439941, 0.7241891026496887, 1.9967422485351562]\n",
            "\n",
            "Window 4 (from document 2):\n",
            "  Original tokens: [2, 23, 11, 24, 25, 26, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> Another sentence of medium length. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Positional encoding effect:\n",
            "    Token 0:\n",
            "      Before: [0.6020277142524719, 0.03156214952468872, 0.9365567564964294, 0.8136954307556152, 0.010527074337005615, 0.261183500289917, 0.6630775928497314, 0.39727020263671875, 0.44551175832748413, 0.2742421627044678, 0.9016097784042358, 0.2205008864402771, 0.9146384000778198, 0.5322611331939697, 0.6005108952522278, 0.8900659084320068]\n",
            "      After:  [0.6020277142524719, 1.031562089920044, 0.9365567564964294, 1.8136954307556152, 0.010527074337005615, 1.261183500289917, 0.6630775928497314, 1.3972702026367188, 0.44551175832748413, 1.2742421627044678, 0.9016097784042358, 1.2205009460449219, 0.9146384000778198, 1.5322611331939697, 0.6005108952522278, 1.8900659084320068]\n",
            "    Token 1:\n",
            "      Before: [0.41761720180511475, 0.21532833576202393, 0.41913288831710815, 0.9055266976356506, 0.12900632619857788, 0.6134902238845825, 0.008604288101196289, 0.7621510624885559, 0.6847338676452637, 0.5211961269378662, 0.7145965695381165, 0.5005623698234558, 0.7766764163970947, 0.10418975353240967, 0.4265737533569336, 0.7218073010444641]\n",
            "      After:  [1.259088158607483, 0.7556306719779968, 0.7301164865493774, 1.8559420108795166, 0.22883974015712738, 1.6084944009780884, 0.040221791714429855, 1.7616510391235352, 0.6947336792945862, 1.5211460590362549, 0.71775883436203, 1.5005574226379395, 0.7776764035224915, 1.1041892766952515, 0.42688998579978943, 1.7218072414398193]\n",
            "    Token 2:\n",
            "      Before: [0.9979084134101868, 0.75469571352005, 0.13641279935836792, 0.8845484256744385, 0.3885008692741394, 0.3932427763938904, 0.04554516077041626, 0.42129284143447876, 0.8536633849143982, 0.5697224140167236, 0.20877301692962646, 0.6539060473442078, 0.3396778106689453, 0.9564970135688782, 0.06602269411087036, 0.34206223487854004]\n",
            "      After:  [1.9072058200836182, 0.338548868894577, 0.7275398969650269, 1.691126823425293, 0.5871701836585999, 1.3733093738555908, 0.10874855518341064, 1.4192935228347778, 0.8736620545387268, 1.5695223808288574, 0.21509753167629242, 1.653886079788208, 0.34167781472206116, 1.9564950466156006, 0.06665515154600143, 1.342061996459961]\n",
            "    Token 3:\n",
            "      Before: [0.01721322536468506, 0.3030849099159241, 0.657623827457428, 0.981307327747345, 0.5839731693267822, 0.9901792407035828, 0.5978260636329651, 0.7887679934501648, 0.9008311033248901, 0.9179616570472717, 0.22013813257217407, 0.9596949815750122, 0.802882730960846, 0.26621049642562866, 0.2613983154296875, 0.08062690496444702]\n",
            "      After:  [0.15833322703838348, -0.6869075894355774, 1.4702727794647217, 1.564060926437378, 0.8794933557510376, 1.945515751838684, 0.6925521492958069, 1.7842713594436646, 0.9308266043663025, 1.9175117015838623, 0.22962482273578644, 1.9596500396728516, 0.8058827519416809, 1.2662060260772705, 0.262347012758255, 1.0806264877319336]\n",
            "    Token 4:\n",
            "      Before: [0.6255686283111572, 0.09472537040710449, 0.7112123370170593, 0.6578988432884216, 0.06559890508651733, 0.6362504363059998, 0.45933473110198975, 0.7284088730812073, 0.7868947982788086, 0.0029274821281433105, 0.958549439907074, 0.9193210005760193, 0.6989418268203735, 0.04301947355270386, 0.3213896155357361, 0.3550955653190613]\n",
            "      After:  [-0.13123387098312378, -0.5589182376861572, 1.6647930145263672, 0.9590363502502441, 0.45501723885536194, 1.5573114156723022, 0.5854887962341309, 1.7204195261001587, 0.8268841505050659, 1.0021276473999023, 0.9711982011795044, 1.919240951538086, 0.7029418349266052, 1.0430114269256592, 0.32265451550483704, 1.3550947904586792]\n",
            "    Token 5:\n",
            "      Before: [0.37150102853775024, 0.7819615602493286, 0.6817852854728699, 0.8960895538330078, 0.31273841857910156, 0.6682698726654053, 0.677897572517395, 0.08370459079742432, 0.014990091323852539, 0.24055546522140503, 0.8422738313674927, 0.029270172119140625, 0.06478309631347656, 0.7801002860069275, 0.7697644829750061, 0.9111963510513306]\n",
            "      After:  [-0.5874232649803162, 1.0656237602233887, 1.6817318201065063, 0.8857471942901611, 0.7921639680862427, 1.5458524227142334, 0.835353434085846, 1.0712306499481201, 0.0649692565202713, 1.2393057346343994, 0.8580845594406128, 1.0291452407836914, 0.06978307664394379, 1.7800877094268799, 0.7713456153869629, 1.9111950397491455]\n",
            "    Token 6:\n",
            "      Before: [0.12253063917160034, 0.1340501308441162, 0.756493330001831, 0.9348151087760925, 0.7991694211959839, 0.5783260464668274, 0.6647873520851135, 0.9745633602142334, 0.17739784717559814, 0.27299410104751587, 0.8497334718704224, 0.15788018703460693, 0.22429370880126953, 0.864995539188385, 0.6577610373497009, 0.6615350246429443]\n",
            "      After:  [-0.15688484907150269, 1.0942203998565674, 1.7036415338516235, 0.6140186786651611, 1.3638118505477905, 1.4036617279052734, 0.8533875942230225, 1.9566173553466797, 0.2373618483543396, 1.2711946964263916, 0.8687059879302979, 1.1577001810073853, 0.23029367625713348, 1.8649775981903076, 0.6596584320068359, 1.661533236503601]\n",
            "\n",
            "--- End of Test ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Masked Multihead Attention Mechanism\n",
        "\n",
        "As you have implemented the Attention Mechanism in Part I, here you will have to use its ready implementation from Pytorch.\n",
        "\n",
        "Masked Attention mechanism allows the transformer model to focus on relevant parts of the input sequence while preventing information leakage from future tokens during sequential processing (i.e. we use the term Masked).\n",
        "\n",
        "Please, visit [Link-pytorch](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) for a detailed description of the MultiheadAttention function in PyTorch.\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   Multi-head Attention, deep dive [Link-towardsdatascience](https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853)\n",
        "* Attention Is All You Need (original Transformer paper) [Link-ArXiv](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "* A visual explanation of the attention mechanism [Link-youtube](https://www.youtube.com/watch?v=bCz4OMemCcA&t=1208s&ab_channel=UmarJamil)"
      ],
      "metadata": {
        "id": "i_d5KqeSAdiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, nhead: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        # The masked positions are filled with float('-inf'). Unmasked positions are filled with float(0.0). See: https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        seq_len = x.size(1)\n",
        "        attn_mask = self.generate_square_subsequent_mask(seq_len).to(x.device)\n",
        "        output, _ = self.multihead_attn(x, x, x, attn_mask=attn_mask)\n",
        "        return output, attn_mask"
      ],
      "metadata": {
        "id": "oDqt8XggAlFe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Multihead Attention"
      ],
      "metadata": {
        "id": "MAMRpHUKwGKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_expanded_transformer_components():\n",
        "    print(\"\\n--- Testing Expanded Transformer Components ---\\n\")\n",
        "\n",
        "    # Set a fixed seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Sample texts\n",
        "    texts = [\n",
        "        \"This is a short sentence.\",\n",
        "        \"This is a much longer sentence that will be split into multiple windows. Observe the term overlapping?\",\n",
        "        \"Another sentence of medium length.\"\n",
        "    ]\n",
        "\n",
        "    # Initialize tokenizer and fit it to the texts\n",
        "    tokenizer = SimpleTokenizer()\n",
        "    tokenizer.fit(texts)\n",
        "\n",
        "    # Create dataset\n",
        "    max_length = 10\n",
        "    overlap = 2\n",
        "    dataset = TextDataset(texts, tokenizer, max_length, overlap)\n",
        "\n",
        "    # Hyperparameters\n",
        "    d_model = 16  # Small dimension for demonstration\n",
        "    nhead = 2\n",
        "\n",
        "    # Initialize components\n",
        "    pos_encoder = PositionalEncoding(d_model, max_length)\n",
        "    masked_self_attn = MaskedAttention(d_model, nhead)\n",
        "\n",
        "    print(f\"Dataset configuration:\")\n",
        "    print(f\"  Max length: {max_length}\")\n",
        "    print(f\"  Overlap: {overlap}\")\n",
        "    print(f\"  Total windows: {len(dataset)}\")\n",
        "    print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
        "    print(f\"  Embedding dimension: {d_model}\")\n",
        "    print(f\"  Number of attention heads: {nhead}\\n\")\n",
        "\n",
        "    # Process each window\n",
        "    for i in range(len(dataset)):\n",
        "        tokens, attention_mask, doc_idx = dataset[i]\n",
        "\n",
        "        print(f\"Window {i} (from document {doc_idx}):\")\n",
        "        print(f\"  Original tokens: {tokens.squeeze(0).tolist()}\")\n",
        "        print(f\"  Attention mask: {attention_mask.squeeze(0).tolist()}\")\n",
        "        print(f\"  Decoded: '{tokenizer.decode(tokens.squeeze(0).tolist())}'\")\n",
        "\n",
        "        # Convert tokens to \"embeddings\" (just for demonstration)\n",
        "        pseudo_embeddings = torch.rand(1, tokens.size(1), d_model)  # (batch_size, seq_len, d_model)\n",
        "        print(f\"  Shape of pseudo embeddings: {pseudo_embeddings.shape}\")\n",
        "\n",
        "        # Apply positional encoding\n",
        "        pos_encoded = pos_encoder(pseudo_embeddings)\n",
        "        print(f\"  Shape after positional encoding: {pos_encoded.shape}\")\n",
        "\n",
        "        # Apply masked self-attention\n",
        "        attn_output, attn_mask = masked_self_attn(pos_encoded)\n",
        "        print(f\"  Shape after masked self-attention: {attn_output.shape}\")\n",
        "\n",
        "        # Display the effect of positional encoding and attention for all tokens\n",
        "        print(f\"  Transformer effect on tokens:\")\n",
        "        for j in range(tokens.size(1)):\n",
        "            if attention_mask[0, j] == 1:  # Only show for non-padding tokens\n",
        "                print(f\"    Token {j}:\")\n",
        "                print(f\"      Initial:   {pseudo_embeddings[0, j, :5].tolist()}\")\n",
        "                print(f\"      Positional:{pos_encoded[0, j, :5].tolist()}\")\n",
        "                print(f\"      Attention Mask: {attn_mask[j, :5].tolist()}\")  # Show first 5 values of attention mask\n",
        "                print(f\"      Attention: {attn_output[0, j, :5].tolist()}\")\n",
        "        print()\n",
        "\n",
        "    print(\"--- End of Expanded Test ---\")\n",
        "\n",
        "# Run the expanded test\n",
        "test_expanded_transformer_components()"
      ],
      "metadata": {
        "id": "e0UqHQVswJzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debf2132-9893-48b1-934f-60a5747aa439"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Expanded Transformer Components ---\n",
            "\n",
            "Dataset configuration:\n",
            "  Max length: 10\n",
            "  Overlap: 2\n",
            "  Total windows: 5\n",
            "  Vocabulary size: 27\n",
            "  Embedding dimension: 16\n",
            "  Number of attention heads: 2\n",
            "\n",
            "Window 0 (from document 0):\n",
            "  Original tokens: [2, 4, 5, 6, 7, 8, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> This is a short sentence. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.09746289253234863, 0.8920455574989319, 0.5080603361129761, 0.6052985191345215, 0.2980855107307434]\n",
            "      Positional:[0.09746289253234863, 1.892045497894287, 0.5080603361129761, 1.6052985191345215, 0.2980855107307434]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.30292782187461853, 0.058979008346796036, 0.34361016750335693, 0.13326211273670197, -0.00016203013365156949]\n",
            "    Token 1:\n",
            "      Initial:   [0.4321278929710388, 0.29191911220550537, 0.3689272999763489, 0.07888573408126831, 0.10265827178955078]\n",
            "      Positional:[1.2735989093780518, 0.8322214484214783, 0.6799108982086182, 1.0293010473251343, 0.20249168574810028]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.3692473769187927, 0.023512933403253555, 0.1952037215232849, 0.17413878440856934, 0.41070911288261414]\n",
            "    Token 2:\n",
            "      Initial:   [0.5097318291664124, 0.7297412157058716, 0.32111454010009766, 0.7177174091339111, 0.3392990231513977]\n",
            "      Positional:[1.4190292358398438, 0.31359437108039856, 0.9122416377067566, 1.5242958068847656, 0.5379683375358582]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.405964195728302, 0.011201255954802036, 0.0836726725101471, 0.1970246285200119, 0.5972457528114319]\n",
            "    Token 3:\n",
            "      Initial:   [0.24083131551742554, 0.005495131015777588, 0.6896569132804871, 0.7801569700241089, 0.07074397802352905]\n",
            "      Positional:[0.38195133209228516, -0.9844973683357239, 1.5023057460784912, 1.3629106283187866, 0.3662641644477844]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.603456437587738, -0.2551816701889038, -0.1215255931019783, 0.125038281083107, 0.6076415181159973]\n",
            "    Token 4:\n",
            "      Initial:   [0.2881501317024231, 0.8012835383415222, 0.6001207828521729, 0.6325052380561829, 0.42332249879837036]\n",
            "      Positional:[-0.4686523675918579, 0.1476399302482605, 1.5537015199661255, 0.9336427450180054, 0.8127408027648926]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.20292046666145325, 0.18137019872665405, 0.10705427825450897, 0.20969344675540924, 0.46637991070747375]\n",
            "    Token 5:\n",
            "      Initial:   [0.2444191575050354, 0.09143507480621338, 0.5188246965408325, 0.2066711187362671, 0.9110968708992004]\n",
            "      Positional:[-0.714505136013031, 0.37509727478027344, 1.5187711715698242, 0.1963287740945816, 1.3905223608016968]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.3654632270336151, 0.1086680069565773, 0.06271891295909882, 0.32703766226768494, 0.5651660561561584]\n",
            "    Token 6:\n",
            "      Initial:   [0.4646261930465698, 0.957639753818512, 0.15339964628219604, 0.1462550163269043, 0.5813086628913879]\n",
            "      Positional:[0.1852107048034668, 1.9178099632263184, 1.1005477905273438, -0.1745413839817047, 1.1459510326385498]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.3645380735397339, 0.08689384907484055, 0.029141269624233246, 0.3618967831134796, 0.622290849685669]\n",
            "\n",
            "Window 1 (from document 1):\n",
            "  Original tokens: [2, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> This is a much longer sentence that will be'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.34115320444107056, 0.31912773847579956, 0.990519106388092, 0.314685583114624, 0.14199954271316528]\n",
            "      Positional:[0.34115320444107056, 1.3191277980804443, 0.990519106388092, 1.314685583114624, 0.14199954271316528]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [0.43687835335731506, 0.4565636217594147, 0.3507387936115265, 0.2024543583393097, 0.008659991435706615]\n",
            "    Token 1:\n",
            "      Initial:   [0.5054755806922913, 0.7410762310028076, 0.3251892328262329, 0.06390810012817383, 0.6263900399208069]\n",
            "      Positional:[1.3469464778900146, 1.2813785076141357, 0.6361728310585022, 1.0143234729766846, 0.7262234687805176]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.7696546316146851, -0.30239981412887573, -0.17886075377464294, 0.15534347295761108, 0.6137670874595642]\n",
            "    Token 2:\n",
            "      Initial:   [0.6643266677856445, 0.8806777596473694, 0.28508204221725464, 0.3875274658203125, 0.6363529562950134]\n",
            "      Positional:[1.5736241340637207, 0.46453091502189636, 0.8762091398239136, 1.194105863571167, 0.8350222706794739]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.5785796046257019, -0.08263222128152847, -0.09736323356628418, 0.19611109793186188, 0.8050152659416199]\n",
            "    Token 3:\n",
            "      Initial:   [0.5485855937004089, 0.44189202785491943, 0.004032909870147705, 0.4088873267173767, 0.4521103501319885]\n",
            "      Positional:[0.6897056102752686, -0.548100471496582, 0.8166818022727966, 0.9916409850120544, 0.7476305365562439]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.5861164927482605, -0.1866563856601715, -0.173819437623024, 0.14461837708950043, 0.803645670413971]\n",
            "    Token 4:\n",
            "      Initial:   [0.9017549753189087, 0.22105300426483154, 0.8008725047111511, 0.4360339641571045, 0.007035315036773682]\n",
            "      Positional:[0.14495247602462769, -0.4325906038284302, 1.754453182220459, 0.7371714115142822, 0.3964536488056183]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.6188420653343201, -0.2170855551958084, -0.17996084690093994, 0.11934284120798111, 0.7741169333457947]\n",
            "    Token 5:\n",
            "      Initial:   [0.37506330013275146, 0.45226621627807617, 0.2217569351196289, 0.13068997859954834, 0.8363087773323059]\n",
            "      Positional:[-0.5838609933853149, 0.7359284162521362, 1.2217035293579102, 0.12034764140844345, 1.3157342672348022]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.432193785905838, 0.003275876399129629, -0.06913033872842789, 0.23924772441387177, 0.6527177095413208]\n",
            "    Token 6:\n",
            "      Initial:   [0.09864664077758789, 0.6012027263641357, 0.7730188965797424, 0.2515934705734253, 0.555067241191864]\n",
            "      Positional:[-0.18076884746551514, 1.561372995376587, 1.7201671600341797, -0.06920292973518372, 1.1197097301483154]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.49911564588546753, -0.08719375729560852, -0.07740342617034912, 0.27743786573410034, 0.6570183634757996]\n",
            "    Token 7:\n",
            "      Initial:   [0.38638901710510254, 0.9490664601325989, 0.3097335696220398, 0.3548141121864319, 0.5341376662254333]\n",
            "      Positional:[1.0433756113052368, 1.702968716621399, 1.1101551055908203, -0.2446233630180359, 1.1783552169799805]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.37389469146728516, 0.02373555116355419, -0.027100838720798492, 0.29781731963157654, 0.5392606258392334]\n",
            "    Token 8:\n",
            "      Initial:   [0.685197114944458, 0.13193923234939575, 0.5313456654548645, 0.9651788473129272, 0.8793095946311951]\n",
            "      Positional:[1.6745553016662598, -0.01356080174446106, 1.105663537979126, 0.14654642343521118, 1.596665620803833]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.5465435981750488, -0.08604010939598083, -0.10789158195257187, 0.2841069996356964, 0.6541135907173157]\n",
            "    Token 9:\n",
            "      Initial:   [0.2186814546585083, 0.27491676807403564, 0.6700762510299683, 0.06158679723739624, 0.4221327304840088]\n",
            "      Positional:[0.6307999491691589, -0.636213481426239, 0.9613354802131653, -0.8950573801994324, 1.2054595947265625]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.5348485708236694, -0.052214499562978745, -0.11903820931911469, 0.3285274803638458, 0.6465451717376709]\n",
            "\n",
            "Window 2 (from document 1):\n",
            "  Original tokens: [2, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> will be split into multiple windows. Observe the term'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.023123741149902344, 0.6316888928413391, 0.747222363948822, 0.061399757862091064, 0.17266380786895752]\n",
            "      Positional:[0.023123741149902344, 1.6316888332366943, 0.747222363948822, 1.0613996982574463, 0.17266380786895752]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.22530552744865417, 0.12471821159124374, 0.28732603788375854, 0.44889429211616516, 0.015198233537375927]\n",
            "    Token 1:\n",
            "      Initial:   [0.883198082447052, 0.8064818978309631, 0.8618844151496887, 0.003833949565887451, 0.9117289781570435]\n",
            "      Positional:[1.7246689796447754, 1.346784234046936, 1.172868013381958, 0.9542492628097534, 1.0115623474121094]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.54913729429245, -0.07064637541770935, -0.008004860952496529, 0.36822009086608887, 0.556068480014801]\n",
            "    Token 2:\n",
            "      Initial:   [0.7969839572906494, 0.5626142621040344, 0.516853928565979, 0.5956724882125854, 0.17186564207077026]\n",
            "      Positional:[1.7062814235687256, 0.1464674174785614, 1.1079809665679932, 1.40225088596344, 0.3705349564552307]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.5722422003746033, -0.12434389442205429, -0.0875592827796936, 0.3171077072620392, 0.5575131773948669]\n",
            "    Token 3:\n",
            "      Initial:   [0.4298197627067566, 0.6429978013038635, 0.5225837230682373, 0.2503151297569275, 0.327858030796051]\n",
            "      Positional:[0.5709397792816162, -0.34699469804763794, 1.3352326154708862, 0.8330687880516052, 0.6233782172203064]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.5179765224456787, -0.006169227883219719, -0.08306824415922165, 0.31707116961479187, 0.6917088627815247]\n",
            "    Token 4:\n",
            "      Initial:   [0.43127381801605225, 0.3380986452102661, 0.3102777600288391, 0.3150080442428589, 0.9594602584838867]\n",
            "      Positional:[-0.32552868127822876, -0.3155449628829956, 1.2638585567474365, 0.6161454916000366, 1.3488786220550537]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.5406835675239563, -0.008745926432311535, -0.08782916516065598, 0.33249732851982117, 0.6030360460281372]\n",
            "    Token 5:\n",
            "      Initial:   [0.39566487073898315, 0.08251774311065674, 0.023042798042297363, 0.171051025390625, 0.7268852591514587]\n",
            "      Positional:[-0.5632594227790833, 0.3661799430847168, 1.022989273071289, 0.16070868074893951, 1.206310749053955]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.29661670327186584, 0.1754787564277649, 0.013970313593745232, 0.32629692554473877, 0.5795361399650574]\n",
            "    Token 6:\n",
            "      Initial:   [0.895921528339386, 0.23396503925323486, 0.05204510688781738, 0.7196753025054932, 0.5311281681060791]\n",
            "      Positional:[0.616506040096283, 1.194135308265686, 0.9991933107376099, 0.39887890219688416, 1.0957705974578857]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4124150574207306, -0.049647558480501175, -0.0644126608967781, 0.28509798645973206, 0.4744986891746521]\n",
            "    Token 7:\n",
            "      Initial:   [0.04945605993270874, 0.6988415122032166, 0.41853559017181396, 0.7283081412315369, 0.4977729916572571]\n",
            "      Positional:[0.706442654132843, 1.4527437686920166, 1.2189571857452393, 0.1288706660270691, 1.1419906616210938]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.47094517946243286, 0.056072674691677094, -0.0569952018558979, 0.35383346676826477, 0.7070335745811462]\n",
            "    Token 8:\n",
            "      Initial:   [0.2910900115966797, 0.21942031383514404, 0.27615296840667725, 0.15551382303237915, 0.14953309297561646]\n",
            "      Positional:[1.2804481983184814, 0.07392027974128723, 0.850470781326294, -0.6631186008453369, 0.8668891191482544]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.33245617151260376, 0.12001398205757141, -0.013744396157562733, 0.2856137156486511, 0.5560255646705627]\n",
            "    Token 9:\n",
            "      Initial:   [0.7358364462852478, 0.5917077660560608, 0.6536521315574646, 0.6830741763114929, 0.27044761180877686]\n",
            "      Positional:[1.1479549407958984, -0.31942248344421387, 0.9449113607406616, -0.2735700011253357, 1.0537744760513306]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.46106135845184326, 0.031451527029275894, -0.08140801638364792, 0.31207719445228577, 0.6219484806060791]\n",
            "\n",
            "Window 3 (from document 1):\n",
            "  Original tokens: [2, 20, 21, 22, 3, 0, 0, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Decoded: '<SOS> the term overlapping? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.9869992733001709, 0.6132185459136963, 0.3144165277481079, 0.4502519369125366, 0.6407642364501953]\n",
            "      Positional:[0.9869992733001709, 1.6132185459136963, 0.3144165277481079, 1.4502519369125366, 0.6407642364501953]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.4033154547214508, 0.17907707393169403, 0.02819337323307991, 0.13209772109985352, 0.5030664205551147]\n",
            "    Token 1:\n",
            "      Initial:   [0.33922648429870605, 0.3217257261276245, 0.9783200025558472, 0.691785991191864, 0.9920566082000732]\n",
            "      Positional:[1.1806974411010742, 0.8620280623435974, 1.2893035411834717, 1.64220130443573, 1.0918899774551392]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.4171152710914612, 0.09039470553398132, -0.03324350714683533, 0.16534201800823212, 0.7680708765983582]\n",
            "    Token 2:\n",
            "      Initial:   [0.6017863750457764, 0.329353392124176, 0.12398684024810791, 0.1337946653366089, 0.2013312578201294]\n",
            "      Positional:[1.5110838413238525, -0.086793452501297, 0.7151139378547668, 0.9403730630874634, 0.40000057220458984]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.42419397830963135, 0.10575570911169052, -0.057195600122213364, 0.19642779231071472, 0.8563101887702942]\n",
            "    Token 3:\n",
            "      Initial:   [0.6862091422080994, 0.3482993245124817, 0.20185118913650513, 0.6179623007774353, 0.44079720973968506]\n",
            "      Positional:[0.827329158782959, -0.6416931748390198, 1.0145001411437988, 1.2007160186767578, 0.7363173961639404]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.40697184205055237, 0.12812064588069916, -0.06250517070293427, 0.221684530377388, 0.8432471752166748]\n",
            "    Token 4:\n",
            "      Initial:   [0.5399761199951172, 0.6362065076828003, 0.8804687857627869, 0.26372116804122925, 0.7985025644302368]\n",
            "      Positional:[-0.21682637929916382, -0.017437100410461426, 1.8340494632720947, 0.5648586750030518, 1.1879209280014038]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.37717047333717346, 0.10988402366638184, -0.02455931343138218, 0.27027469873428345, 0.7987484931945801]\n",
            "\n",
            "Window 4 (from document 2):\n",
            "  Original tokens: [2, 23, 11, 24, 25, 26, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> Another sentence of medium length. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.577206015586853, 0.7385759353637695, 0.03400152921676636, 0.5011811256408691, 0.05765819549560547]\n",
            "      Positional:[0.577206015586853, 1.7385759353637695, 0.03400152921676636, 1.5011811256408691, 0.05765819549560547]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.31409716606140137, 0.08221111446619034, 0.03178007900714874, 0.1580047905445099, 0.19956322014331818]\n",
            "    Token 1:\n",
            "      Initial:   [0.17157816886901855, 0.7134378552436829, 0.9898809194564819, 0.2579604387283325, 0.7358318567276001]\n",
            "      Positional:[1.0130491256713867, 1.2537401914596558, 1.3008644580841064, 1.2083756923675537, 0.8356652855873108]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.5564097762107849, -0.07554564625024796, -0.051238782703876495, 0.11123543232679367, 0.5578495264053345]\n",
            "    Token 2:\n",
            "      Initial:   [0.59932941198349, 0.38812363147735596, 0.8214121460914612, 0.2754364013671875, 0.5350692868232727]\n",
            "      Positional:[1.5086268186569214, -0.028023213148117065, 1.4125392436981201, 1.082014799118042, 0.7337386012077332]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.5830851197242737, -0.07982688397169113, -0.13428325951099396, 0.1874244511127472, 0.7925053238868713]\n",
            "    Token 3:\n",
            "      Initial:   [0.7415045499801636, 0.3632585406303406, 0.5736007690429688, 0.5968784689903259, 0.6171205043792725]\n",
            "      Positional:[0.8826245665550232, -0.6267339587211609, 1.3862496614456177, 1.1796321868896484, 0.9126406908035278]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.5673719644546509, -0.04151001572608948, -0.14706961810588837, 0.2036711573600769, 0.8324263095855713]\n",
            "    Token 4:\n",
            "      Initial:   [0.4989064931869507, 0.6064485311508179, 0.9750649333000183, 0.9859485030174255, 0.28888994455337524]\n",
            "      Positional:[-0.2578960061073303, -0.04719507694244385, 1.9286456108093262, 1.287086009979248, 0.6783082485198975]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.5160091519355774, -0.03773985058069229, -0.09358043223619461, 0.23858432471752167, 0.6968011260032654]\n",
            "    Token 5:\n",
            "      Initial:   [0.0458981990814209, 0.33253902196884155, 0.6517975926399231, 0.8534388542175293, 0.7785176038742065]\n",
            "      Positional:[-0.9130260944366455, 0.6162012219429016, 1.6517441272735596, 0.8430964946746826, 1.2579431533813477]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4902394413948059, -0.0010156218195334077, -0.0699649378657341, 0.2870899736881256, 0.6900935173034668]\n",
            "    Token 6:\n",
            "      Initial:   [0.9003341794013977, 0.41853517293930054, 0.05829566717147827, 0.5536373257637024, 0.5362840890884399]\n",
            "      Positional:[0.6209186911582947, 1.3787055015563965, 1.005443811416626, 0.23284092545509338, 1.1009265184402466]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.508764386177063, -0.014578032307326794, -0.08915726840496063, 0.27497199177742004, 0.6350379586219788]\n",
            "\n",
            "--- End of Expanded Test ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Feed Forward Netwrok\n",
        "\n",
        "A feed-forward network is a multi-layered structure in which information moves in a single direction, from the input layer to the output layer.\n",
        "\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   Transformer Feed-Forward Layers Are Key-Value Memories\n",
        " [Link-ArXiv](https://arxiv.org/abs/2012.14913)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AGmlNshUAmmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define feed-forward network using nn.Sequential\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),  # First linear layer\n",
        "            nn.ReLU(),                 # ReLU activation\n",
        "            nn.Dropout(dropout),       # Dropout for regularization\n",
        "            nn.Linear(d_ff, d_model)   # Second linear layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)  # Apply the feed-forward network"
      ],
      "metadata": {
        "id": "yH4rocZtFSY7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Feed Forward Layer"
      ],
      "metadata": {
        "id": "XxPG41aLFJz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_all_transformer_components():\n",
        "    print(\"\\n--- Testing Transformer Components ---\\n\")\n",
        "\n",
        "    # Set a fixed seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Sample texts\n",
        "    texts = [\n",
        "        \"This is a short sentence.\",\n",
        "        \"This is a much longer sentence that will be split into multiple windows. Observe the term overlapping?\",\n",
        "        \"Another sentence of medium length.\"\n",
        "    ]\n",
        "\n",
        "    # Initialize tokenizer and fit it to the texts\n",
        "    tokenizer = SimpleTokenizer()\n",
        "    tokenizer.fit(texts)\n",
        "\n",
        "    # Create dataset\n",
        "    max_length = 10\n",
        "    overlap = 2\n",
        "    dataset = TextDataset(texts, tokenizer, max_length, overlap)\n",
        "\n",
        "    # Hyperparameters\n",
        "    d_model = 16  # Small dimension for demonstration\n",
        "    nhead = 2\n",
        "    d_ff = d_model  # Feed-forward dimension\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Initialize components\n",
        "    pos_encoder = PositionalEncoding(d_model, max_length)\n",
        "    masked_self_attn = MaskedAttention(d_model, nhead)\n",
        "    feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "    print(f\"Dataset configuration:\")\n",
        "    print(f\"  Max length: {max_length}\")\n",
        "    print(f\"  Overlap: {overlap}\")\n",
        "    print(f\"  Total windows: {len(dataset)}\")\n",
        "    print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
        "    print(f\"  Embedding dimension: {d_model}\")\n",
        "    print(f\"  Number of attention heads: {nhead}\")\n",
        "    print(f\"  Feed-forward dimension: {d_ff}\\n\")\n",
        "\n",
        "    # Process each window\n",
        "    for i in range(len(dataset)):\n",
        "        tokens, attention_mask, doc_idx = dataset[i]\n",
        "\n",
        "        print(f\"Window {i} (from document {doc_idx}):\")\n",
        "        print(f\"  Original tokens: {tokens.squeeze(0).tolist()}\")\n",
        "        print(f\"  Attention mask: {attention_mask.squeeze(0).tolist()}\")\n",
        "        print(f\"  Decoded: '{tokenizer.decode(tokens.squeeze(0).tolist())}'\")\n",
        "\n",
        "        # Convert tokens to \"embeddings\" (just for demonstration)\n",
        "        pseudo_embeddings = torch.rand(1, tokens.size(1), d_model)  # (batch_size, seq_len, d_model)\n",
        "        print(f\"  Shape of pseudo embeddings: {pseudo_embeddings.shape}\")\n",
        "\n",
        "        # Apply positional encoding\n",
        "        pos_encoded = pos_encoder(pseudo_embeddings)\n",
        "        print(f\"  Shape after positional encoding: {pos_encoded.shape}\")\n",
        "\n",
        "        # Apply masked self-attention\n",
        "        attn_output, attn_mask = masked_self_attn(pos_encoded)\n",
        "        print(f\"  Shape after masked self-attention: {attn_output.shape}\")\n",
        "\n",
        "        # Apply feed-forward network\n",
        "        ff_output = feed_forward(attn_output)\n",
        "        print(f\"  Shape after feed-forward: {ff_output.shape}\")\n",
        "\n",
        "        # Display the effect of positional encoding, attention, and feed-forward for all tokens\n",
        "        print(f\"  Transformer effect on tokens:\")\n",
        "        for j in range(tokens.size(1)):\n",
        "            if attention_mask[0, j] == 1:  # Only show for non-padding tokens\n",
        "                print(f\"    Token {j}:\")\n",
        "                print(f\"      Initial:   {pseudo_embeddings[0, j, :5].tolist()}\")\n",
        "                print(f\"      Positional:{pos_encoded[0, j, :5].tolist()}\")\n",
        "                print(f\"      Attention Mask: {attn_mask[j, :5].tolist()}\")  # Show first 5 values\n",
        "                print(f\"      Attention: {attn_output[0, j, :5].tolist()}\")\n",
        "                print(f\"      Feed-Forward: {ff_output[0, j, :5].tolist()}\")\n",
        "        print()\n",
        "\n",
        "    print(\"--- End of Expanded Test ---\")\n",
        "\n",
        "# Run the expanded test\n",
        "test_all_transformer_components()"
      ],
      "metadata": {
        "id": "FyyrKkJZAuMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbfa001-619f-4134-c229-f5e11e6e84ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Transformer Components ---\n",
            "\n",
            "Dataset configuration:\n",
            "  Max length: 10\n",
            "  Overlap: 2\n",
            "  Total windows: 5\n",
            "  Vocabulary size: 27\n",
            "  Embedding dimension: 16\n",
            "  Number of attention heads: 2\n",
            "  Feed-forward dimension: 16\n",
            "\n",
            "Window 0 (from document 0):\n",
            "  Original tokens: [2, 4, 5, 6, 7, 8, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> This is a short sentence. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Shape after feed-forward: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.50750333070755, 0.8034182190895081, 0.532285213470459, 0.5399761199951172, 0.6362065076828003]\n",
            "      Positional:[0.50750333070755, 1.8034181594848633, 0.532285213470459, 1.5399761199951172, 0.6362065076828003]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.21086835861206055, 0.2382364124059677, 0.179763063788414, 0.3103293776512146, 0.5374228358268738]\n",
            "      Feed-Forward: [0.1308080106973648, 0.26601219177246094, 0.037419725209474564, 0.2835398316383362, -0.09917416423559189]\n",
            "    Token 1:\n",
            "      Initial:   [0.05308955907821655, 0.7500075101852417, 0.049994051456451416, 0.4391469955444336, 0.5298210978507996]\n",
            "      Positional:[0.8945605158805847, 1.2903099060058594, 0.3609776496887207, 1.3895623683929443, 0.6296545267105103]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.38097092509269714, 0.08109887689352036, 0.08833040297031403, 0.16683298349380493, 0.506827175617218]\n",
            "      Feed-Forward: [0.14191381633281708, 0.21208591759204865, 0.03267112746834755, 0.3128281831741333, -0.06387915462255478]\n",
            "    Token 2:\n",
            "      Initial:   [0.4148801565170288, 0.4395599365234375, 0.9889400601387024, 0.39194321632385254, 0.11934781074523926]\n",
            "      Positional:[1.3241775035858154, 0.023413091897964478, 1.5800671577453613, 1.198521614074707, 0.3180171251296997]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.12902353703975677, 0.27886924147605896, 0.1359003186225891, 0.24177782237529755, 0.41197124123573303]\n",
            "      Feed-Forward: [0.15140175819396973, 0.18726205825805664, 0.008778112009167671, 0.1262429654598236, -0.2146751582622528]\n",
            "    Token 3:\n",
            "      Initial:   [0.366510808467865, 0.6209648847579956, 0.14469265937805176, 0.10225951671600342, 0.018978595733642578]\n",
            "      Positional:[0.5076308250427246, -0.36902761459350586, 0.9573415517807007, 0.6850131750106812, 0.31449878215789795]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.4052215814590454, 0.05995522439479828, 0.035345081239938736, 0.20561710000038147, 0.5763307213783264]\n",
            "      Feed-Forward: [0.07088395208120346, 0.2753441631793976, 0.03175804018974304, 0.2271888703107834, -0.10397692024707794]\n",
            "    Token 4:\n",
            "      Initial:   [0.5732741355895996, 0.06064373254776001, 0.4830366373062134, 0.2778189778327942, 0.6645737290382385]\n",
            "      Positional:[-0.1835283637046814, -0.5929998755455017, 1.436617374420166, 0.5789564847946167, 1.0539920330047607]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.3018227219581604, 0.08831988275051117, 0.0452420637011528, 0.14754047989845276, 0.47987794876098633]\n",
            "      Feed-Forward: [0.06680063903331757, 0.2342202067375183, 0.03511245921254158, 0.21035164594650269, -0.10367506742477417]\n",
            "    Token 5:\n",
            "      Initial:   [0.05939781665802002, 0.5459702610969543, 0.15506881475448608, 0.8737807273864746, 0.582149863243103]\n",
            "      Positional:[-0.8995264768600464, 0.8296324610710144, 1.1550153493881226, 0.8634383678436279, 1.0615754127502441]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.27546727657318115, 0.12029422074556351, 0.08277468383312225, 0.26879939436912537, 0.36885523796081543]\n",
            "      Feed-Forward: [0.06323066353797913, 0.2156534194946289, 0.0442197360098362, 0.2134849727153778, -0.09953661262989044]\n",
            "    Token 6:\n",
            "      Initial:   [0.3521820902824402, 0.4462805390357971, 0.8655674457550049, 0.8844633102416992, 0.577206015586853]\n",
            "      Positional:[0.07276660203933716, 1.4064507484436035, 1.8127156496047974, 0.5636669397354126, 1.1418484449386597]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.22879639267921448, 0.1502773016691208, 0.08893775194883347, 0.24874907732009888, 0.4128985106945038]\n",
            "      Feed-Forward: [0.07272198051214218, 0.21219590306282043, 0.043738849461078644, 0.1988517940044403, -0.1046898365020752]\n",
            "\n",
            "Window 1 (from document 1):\n",
            "  Original tokens: [2, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> This is a much longer sentence that will be'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Shape after feed-forward: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.6359478831291199, 0.9919414520263672, 0.4989064931869507, 0.6064485311508179, 0.9750649333000183]\n",
            "      Positional:[0.6359478831291199, 1.9919414520263672, 0.4989064931869507, 1.6064485311508179, 0.9750649333000183]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.7947388291358948, -0.6079118251800537, -0.2088201642036438, -0.040452923625707626, 0.5872057676315308]\n",
            "      Feed-Forward: [0.08439116925001144, 0.2273155301809311, -0.004009127616882324, 0.14556235074996948, -0.04961974173784256]\n",
            "    Token 1:\n",
            "      Initial:   [0.004542946815490723, 0.41001880168914795, 0.0458981990814209, 0.33253902196884155, 0.6517975926399231]\n",
            "      Positional:[0.8460139036178589, 0.9503211379051208, 0.3568817973136902, 1.2829543352127075, 0.7516310214996338]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.4135802984237671, 0.13283202052116394, 0.03438878059387207, 0.15070922672748566, 0.6727937459945679]\n",
            "      Feed-Forward: [-0.08731020241975784, 0.21438707411289215, 0.09867904335260391, 0.15940429270267487, -0.12677699327468872]\n",
            "    Token 2:\n",
            "      Initial:   [0.25208085775375366, 0.11456817388534546, 0.9003341794013977, 0.41853517293930054, 0.05829566717147827]\n",
            "      Positional:[1.161378264427185, -0.30157867074012756, 1.4914612770080566, 1.2251136302947998, 0.2569649815559387]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.18002291023731232, 0.26408472657203674, 0.047632258385419846, 0.22812001407146454, 0.6200374364852905]\n",
            "      Feed-Forward: [0.08429785817861557, 0.26815804839134216, 0.05389470234513283, 0.13200771808624268, -0.1456768810749054]\n",
            "    Token 3:\n",
            "      Initial:   [0.4619702696800232, 0.25280481576919556, 0.32849156856536865, 0.1096387505531311, 0.8901828527450562]\n",
            "      Positional:[0.6030902862548828, -0.7371876835823059, 1.1411404609680176, 0.6923924088478088, 1.1857030391693115]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.3946669101715088, 0.1358938068151474, -0.08150777965784073, 0.2555299997329712, 0.7708964943885803]\n",
            "      Feed-Forward: [0.07958284765481949, 0.2920098602771759, 0.04878059774637222, 0.18656083941459656, -0.1314241886138916]\n",
            "    Token 4:\n",
            "      Initial:   [0.5239563584327698, 0.11974334716796875, 0.26555144786834717, 0.938884973526001, 0.5052425265312195]\n",
            "      Positional:[-0.23284614086151123, -0.533900260925293, 1.2191321849822998, 1.2400224208831787, 0.8946608304977417]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.3757171332836151, 0.0038707361090928316, -0.10043063014745712, 0.16246499121189117, 0.6786367893218994]\n",
            "      Feed-Forward: [0.06875775754451752, 0.25569823384284973, 0.037610817700624466, 0.15458334982395172, -0.13645626604557037]\n",
            "    Token 5:\n",
            "      Initial:   [0.8093817830085754, 0.10163873434066772, 0.32407933473587036, 0.866020679473877, 0.6483898758888245]\n",
            "      Positional:[-0.14954251050949097, 0.3853009343147278, 1.3240258693695068, 0.8556783199310303, 1.1278153657913208]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.3543052673339844, 0.1427040845155716, -0.06009800359606743, 0.29671671986579895, 0.737775444984436]\n",
            "      Feed-Forward: [0.05659681186079979, 0.1626596301794052, -0.037158817052841187, 0.18912214040756226, -0.03029685840010643]\n",
            "    Token 6:\n",
            "      Initial:   [0.7823862433433533, 0.254031777381897, 0.005369961261749268, 0.5927556753158569, 0.7629470229148865]\n",
            "      Positional:[0.5029707551002502, 1.2142020463943481, 0.9525181651115417, 0.2719592750072479, 1.327589511871338]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4210466742515564, 0.05444774404168129, -0.09358207881450653, 0.26671797037124634, 0.7212975025177002]\n",
            "      Feed-Forward: [0.09442702680826187, 0.27199995517730713, 0.0626833587884903, 0.19157105684280396, -0.11764684319496155]\n",
            "    Token 7:\n",
            "      Initial:   [0.01924741268157959, 0.8139157295227051, 0.675154983997345, 0.13386660814285278, 0.7421404123306274]\n",
            "      Positional:[0.6762340068817139, 1.5678179264068604, 1.475576639175415, -0.465570867061615, 1.3863580226898193]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4537617564201355, 0.057432621717453, -0.0978248193860054, 0.27965134382247925, 0.7687429785728455]\n",
            "      Feed-Forward: [0.06738574802875519, 0.2775084972381592, 0.047347426414489746, 0.18312670290470123, -0.11371300369501114]\n",
            "    Token 8:\n",
            "      Initial:   [0.06049448251724243, 0.5933913588523865, 0.14427685737609863, 0.6539331078529358, 0.5882169604301453]\n",
            "      Positional:[1.049852728843689, 0.44789132475852966, 0.7185946702957153, -0.16469931602478027, 1.3055729866027832]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4984799325466156, 0.013171100057661533, -0.1419624239206314, 0.26439812779426575, 0.7228074073791504]\n",
            "      Feed-Forward: [0.04168172925710678, 0.10443110018968582, 0.020798111334443092, 0.25883960723876953, 0.07601788640022278]\n",
            "    Token 9:\n",
            "      Initial:   [0.8149324059486389, 0.8447468876838684, 0.04272198677062988, 0.5030533075332642, 0.4047732353210449]\n",
            "      Positional:[1.2270509004592896, -0.06638336181640625, 0.3339812159538269, -0.45359086990356445, 1.1881000995635986]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.30794793367385864, 0.15681718289852142, -0.06488948315382004, 0.26380085945129395, 0.6681775450706482]\n",
            "      Feed-Forward: [-0.07655423879623413, 0.21332837641239166, 0.10227889567613602, 0.09141126275062561, -0.15651048719882965]\n",
            "\n",
            "Window 2 (from document 1):\n",
            "  Original tokens: [2, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Decoded: '<SOS> will be split into multiple windows. Observe the term'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Shape after feed-forward: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.20525509119033813, 0.5216648578643799, 0.08346337080001831, 0.35331326723098755, 0.8429332375526428]\n",
            "      Positional:[0.20525509119033813, 1.5216648578643799, 0.08346337080001831, 1.3533132076263428, 0.8429332375526428]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.34262973070144653, 0.23409520089626312, 0.11619265377521515, 0.2208753079175949, 0.1576533317565918]\n",
            "      Feed-Forward: [0.1535845249891281, 0.23503969609737396, 0.0359233021736145, 0.294308602809906, -0.0768669918179512]\n",
            "    Token 1:\n",
            "      Initial:   [0.8093734383583069, 0.4719254970550537, 0.6596767902374268, 0.29222166538238525, 0.9055961966514587]\n",
            "      Positional:[1.6508443355560303, 1.0122277736663818, 0.970660388469696, 1.2426369190216064, 1.0054296255111694]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.4892405569553375, -0.07134568691253662, -0.05715471878647804, 0.16797570884227753, 0.6996737718582153]\n",
            "      Feed-Forward: [0.16665178537368774, 0.29518386721611023, -0.0160696879029274, 0.17275221645832062, -0.18790873885154724]\n",
            "    Token 2:\n",
            "      Initial:   [0.8998173475265503, 0.24625533819198608, 0.828414261341095, 0.560326874256134, 0.5384562015533447]\n",
            "      Positional:[1.809114694595337, -0.16989150643348694, 1.419541358947754, 1.3669052124023438, 0.7371255159378052]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.4826525151729584, -0.022217048332095146, -0.15350937843322754, 0.19158928096294403, 0.8971268534660339]\n",
            "      Feed-Forward: [0.09216514229774475, 0.33030205965042114, 0.0316021591424942, 0.1501549929380417, -0.1610659807920456]\n",
            "    Token 3:\n",
            "      Initial:   [0.06975919008255005, 0.5404964685440063, 0.7917697429656982, 0.5960680246353149, 0.566434919834137]\n",
            "      Positional:[0.21087919175624847, -0.4494960308074951, 1.6044186353683472, 1.1788216829299927, 0.8619551062583923]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.45302802324295044, -0.008015372790396214, -0.11080608516931534, 0.18644064664840698, 0.8536342978477478]\n",
            "      Feed-Forward: [0.05686473101377487, 0.21788737177848816, 0.09066788852214813, 0.2639305591583252, -0.022648829966783524]\n",
            "    Token 4:\n",
            "      Initial:   [0.23101294040679932, 0.16123050451278687, 0.3157983422279358, 0.6784682273864746, 0.07892072200775146]\n",
            "      Positional:[-0.5257895588874817, -0.49241310358047485, 1.2693791389465332, 0.9796056747436523, 0.46833905577659607]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.44314149022102356, 0.012268435209989548, -0.07914654165506363, 0.2467912882566452, 0.6741561889648438]\n",
            "      Feed-Forward: [0.059012748301029205, 0.26398202776908875, 0.04782538115978241, 0.19241130352020264, -0.10756146162748337]\n",
            "    Token 5:\n",
            "      Initial:   [0.40931808948516846, 0.5367186069488525, 0.44500988721847534, 0.7021442651748657, 0.8322750329971313]\n",
            "      Positional:[-0.549606204032898, 0.8203808069229126, 1.4449564218521118, 0.691801905632019, 1.3117005825042725]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.44804084300994873, -0.011382580734789371, -0.06093776598572731, 0.2735636830329895, 0.6026684045791626]\n",
            "      Feed-Forward: [0.056526049971580505, 0.2494652271270752, 0.04818242788314819, 0.18805237114429474, -0.10364499688148499]\n",
            "    Token 6:\n",
            "      Initial:   [0.4741339087486267, 0.14845764636993408, 0.4495701193809509, 0.5710428953170776, 0.47965359687805176]\n",
            "      Positional:[0.19471842050552368, 1.1086279153823853, 1.3967182636260986, 0.25024649500846863, 1.0442960262298584]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.04513288289308548, 0.2668267786502838, 0.08658196032047272, 0.28327107429504395, 0.42972737550735474]\n",
            "      Feed-Forward: [0.06708869338035583, 0.18710491061210632, 0.05682341009378433, 0.15189248323440552, -0.1376107931137085]\n",
            "    Token 7:\n",
            "      Initial:   [0.6296166181564331, 0.452853798866272, 0.8430114388465881, 0.2085251808166504, 0.6791903972625732]\n",
            "      Positional:[1.2866032123565674, 1.2067561149597168, 1.6434330940246582, -0.3909122943878174, 1.3234080076217651]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.49457475543022156, -0.0396600179374218, -0.1094399020075798, 0.29630088806152344, 0.7514663338661194]\n",
            "      Feed-Forward: [0.04547939449548721, 0.27660849690437317, 0.047394365072250366, 0.1703958809375763, -0.11461268365383148]\n",
            "    Token 8:\n",
            "      Initial:   [0.3650050759315491, 0.0908435583114624, 0.6901710629463196, 0.853779673576355, 0.539588212966919]\n",
            "      Positional:[1.3543633222579956, -0.05465647578239441, 1.264488935470581, 0.035147249698638916, 1.256944179534912]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.5470186471939087, -0.11577131599187851, -0.16678296029567719, 0.2833719849586487, 0.7637554407119751]\n",
            "      Feed-Forward: [0.04258997365832329, 0.27798083424568176, 0.046209581196308136, 0.15115787088871002, -0.11642857640981674]\n",
            "    Token 9:\n",
            "      Initial:   [0.6829202771186829, 0.04994887113571167, 0.20464551448822021, 0.5167828798294067, 0.6897211670875549]\n",
            "      Positional:[1.0950387716293335, -0.861181378364563, 0.49590474367141724, -0.4398612976074219, 1.4730479717254639]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4171288013458252, -0.006975642405450344, -0.13114503026008606, 0.24320881068706512, 0.6027928590774536]\n",
            "      Feed-Forward: [0.0684601366519928, 0.25782310962677, 0.06095203384757042, 0.14336206018924713, -0.13147768378257751]\n",
            "\n",
            "Window 3 (from document 1):\n",
            "  Original tokens: [2, 20, 21, 22, 3, 0, 0, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Decoded: '<SOS> the term overlapping? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Shape after feed-forward: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.24992585182189941, 0.7478739023208618, 0.00799030065536499, 0.9042335152626038, 0.5402940511703491]\n",
            "      Positional:[0.24992585182189941, 1.7478739023208618, 0.00799030065536499, 1.904233455657959, 0.5402940511703491]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [-0.5676283836364746, -0.4690694212913513, -0.23205167055130005, -0.0292686615139246, 0.47379446029663086]\n",
            "      Feed-Forward: [0.10472049564123154, 0.12553328275680542, -0.013566110283136368, 0.12953850626945496, -0.05739782750606537]\n",
            "    Token 1:\n",
            "      Initial:   [0.22819238901138306, 0.16303443908691406, 0.8103036284446716, 0.2651660442352295, 0.6609750390052795]\n",
            "      Positional:[1.0696632862091064, 0.703336775302887, 1.121287226676941, 1.2155814170837402, 0.7608084678649902]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.3819083869457245, 0.07100137323141098, 0.0786714255809784, 0.19252783060073853, 0.5678400993347168]\n",
            "      Feed-Forward: [0.11712592840194702, 0.24096223711967468, 0.017759695649147034, 0.25424623489379883, -0.08506062626838684]\n",
            "    Token 2:\n",
            "      Initial:   [0.40790629386901855, 0.2947550415992737, 0.4013308882713318, 0.7430171370506287, 0.48850834369659424]\n",
            "      Positional:[1.3172037601470947, -0.12139180302619934, 0.9924579858779907, 1.549595594406128, 0.6871776580810547]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.5271307826042175, -0.17690593004226685, -0.11361709237098694, 0.10355546325445175, 0.7833746075630188]\n",
            "      Feed-Forward: [0.07053685933351517, 0.26154831051826477, 0.018657686188817024, 0.16018140316009521, -0.11112922430038452]\n",
            "    Token 3:\n",
            "      Initial:   [0.6413989067077637, 0.6738442778587341, 0.6613420844078064, 0.5518633723258972, 0.9253681898117065]\n",
            "      Positional:[0.7825189232826233, -0.31614822149276733, 1.4739909172058105, 1.1346170902252197, 1.220888376235962]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.2439175397157669, 0.149299755692482, -0.0010255069937556982, 0.1800723522901535, 0.6182388663291931]\n",
            "      Feed-Forward: [0.06217847764492035, 0.19141468405723572, 0.08189482241868973, 0.21624866127967834, -0.07075832784175873]\n",
            "    Token 4:\n",
            "      Initial:   [0.28137218952178955, 0.6315562725067139, 0.7832725644111633, 0.03273719549179077, 0.5331819653511047]\n",
            "      Positional:[-0.47543030977249146, -0.02208733558654785, 1.7368533611297607, 0.3338746726512909, 0.922600269317627]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.46551838517189026, -0.08394690603017807, -0.08128168433904648, 0.19449135661125183, 0.7791151404380798]\n",
            "      Feed-Forward: [0.07788433134555817, 0.24816973507404327, 0.004299229010939598, 0.14917542040348053, -0.16156375408172607]\n",
            "\n",
            "Window 4 (from document 2):\n",
            "  Original tokens: [2, 23, 11, 24, 25, 26, 3, 0, 0, 0]\n",
            "  Attention mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Decoded: '<SOS> Another sentence of medium length. <EOS> <PAD> <PAD> <PAD>'\n",
            "  Shape of pseudo embeddings: torch.Size([1, 10, 16])\n",
            "  Shape after positional encoding: torch.Size([1, 10, 16])\n",
            "  Shape after masked self-attention: torch.Size([1, 10, 16])\n",
            "  Shape after feed-forward: torch.Size([1, 10, 16])\n",
            "  Transformer effect on tokens:\n",
            "    Token 0:\n",
            "      Initial:   [0.4206295609474182, 0.10261595249176025, 0.6299805641174316, 0.1394609808921814, 0.9936105012893677]\n",
            "      Positional:[0.4206295609474182, 1.1026159524917603, 0.6299805641174316, 1.1394610404968262, 0.9936105012893677]\n",
            "      Attention Mask: [0.0, -inf, -inf, -inf, -inf]\n",
            "      Attention: [0.27215397357940674, 0.38980725407600403, 0.20350271463394165, 0.1299135833978653, 0.08580341190099716]\n",
            "      Feed-Forward: [0.10969668626785278, 0.14216290414333344, 0.05971229448914528, 0.1491212546825409, -0.1826557219028473]\n",
            "    Token 1:\n",
            "      Initial:   [0.7419456839561462, 0.4869093894958496, 0.0194857120513916, 0.2144399881362915, 0.2686115503311157]\n",
            "      Positional:[1.5834167003631592, 1.0272116661071777, 0.3304693102836609, 1.1648552417755127, 0.3684449791908264]\n",
            "      Attention Mask: [0.0, 0.0, -inf, -inf, -inf]\n",
            "      Attention: [-0.5509953498840332, -0.2806611955165863, -0.13032394647598267, 0.04372486099600792, 0.5775344967842102]\n",
            "      Feed-Forward: [0.09168443083763123, 0.2011178433895111, -0.025189682841300964, 0.13558629155158997, -0.07144923508167267]\n",
            "    Token 2:\n",
            "      Initial:   [0.7478297352790833, 0.3032248020172119, 0.36690109968185425, 0.024027764797210693, 0.9142425060272217]\n",
            "      Positional:[1.6571271419525146, -0.11292204260826111, 0.9580281972885132, 0.8306061625480652, 1.1129118204116821]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, -inf, -inf]\n",
            "      Attention: [-0.5164880752563477, 0.03420485556125641, -0.12055393308401108, 0.1851067990064621, 0.7701945900917053]\n",
            "      Feed-Forward: [0.10391048341989517, 0.30666810274124146, 0.06131849065423012, 0.21074366569519043, -0.11110107600688934]\n",
            "    Token 3:\n",
            "      Initial:   [0.11832767724990845, 0.2576485872268677, 0.039157330989837646, 0.5006737112998962, 0.5721340775489807]\n",
            "      Positional:[0.25944769382476807, -0.7323439121246338, 0.8518062233924866, 1.0834274291992188, 0.8676542639732361]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, -inf]\n",
            "      Attention: [-0.49413803219795227, 0.09829466044902802, -0.10922243446111679, 0.22278067469596863, 0.7249518632888794]\n",
            "      Feed-Forward: [0.0730220377445221, 0.3107382357120514, 0.04604791849851608, 0.17113934457302094, -0.14650669693946838]\n",
            "    Token 4:\n",
            "      Initial:   [0.7489223480224609, 0.279208779335022, 0.027316689491271973, 0.06242650747299194, 0.34092187881469727]\n",
            "      Positional:[-0.007880151271820068, -0.37443482875823975, 0.9808974266052246, 0.36356398463249207, 0.7303402423858643]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.28454655408859253, 0.18564161658287048, -0.042509108781814575, 0.2642478346824646, 0.515045702457428]\n",
            "      Feed-Forward: [0.056420184671878815, 0.2523735761642456, 0.059353165328502655, 0.1517820656299591, -0.15555843710899353]\n",
            "    Token 5:\n",
            "      Initial:   [0.6029056310653687, 0.6991045475006104, 0.5029131174087524, 0.09671282768249512, 0.1919437050819397]\n",
            "      Positional:[-0.35601866245269775, 0.9827667474746704, 1.5028595924377441, 0.08637049049139023, 0.671369194984436]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4136500954627991, 0.09450415521860123, -0.06218463182449341, 0.2812601923942566, 0.6479023098945618]\n",
            "      Feed-Forward: [-0.09730853885412216, 0.2281179130077362, 0.10393067449331284, 0.11241815984249115, -0.14887145161628723]\n",
            "    Token 6:\n",
            "      Initial:   [0.154535174369812, 0.2867479920387268, 0.39955729246139526, 0.3825226426124573, 0.026348888874053955]\n",
            "      Positional:[-0.12488031387329102, 1.2469182014465332, 1.346705436706543, 0.06172624230384827, 0.5909913182258606]\n",
            "      Attention Mask: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "      Attention: [-0.4248798191547394, 0.023722711950540543, -0.05799097195267677, 0.28466302156448364, 0.6257750391960144]\n",
            "      Feed-Forward: [0.04405980557203293, 0.16323137283325195, -0.021493341773748398, 0.16651275753974915, -0.032971009612083435]\n",
            "\n",
            "--- End of Expanded Test ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Decoder Layer\n",
        "\n",
        "Implementation of a Transformer Decoder Layer with Masked Multi-Head Attention and Feed Forward Network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HM696sBjAtmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Decoder Only Architecture](https://drive.google.com/uc?id=1ksROxQxf3b7dlBUoIQggzyLeBaPO-AQn)\n"
      ],
      "metadata": {
        "id": "G0tNpzNhzTXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, nhead: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.masked_attention = MaskedAttention(d_model, nhead, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Masked Multi-Head Attention\n",
        "        normed_x = self.norm1(x)\n",
        "        attn_output, _ = self.masked_attention(normed_x) # _ because we returned also the mask in the previous demonstration\n",
        "        x = x + self.dropout1(attn_output)\n",
        "\n",
        "        # Feed Forward\n",
        "        normed_x = self.norm2(x)\n",
        "        ff_output = self.feed_forward(normed_x)\n",
        "        x = x + self.dropout2(ff_output)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "P02MAkENBZrS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Decoder-only Transformer\n",
        "\n",
        "The components of a Decoder-Only Transformer include an embedding layer for token representation, positional encoding for sequential information, stacked decoder layers for hierarchical processing, layer normalization for stability, and an output projection layer for generating tokens."
      ],
      "metadata": {
        "id": "VJULRnp4BZJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderOnlyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model: int, nhead: int, num_layers: int,\n",
        "                 d_ff: int, max_seq_length: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        # Decoder layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, nhead, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm\n",
        "        self.final_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x shape: (batch_size, seq_len)\n",
        "\n",
        "        # Embed the input\n",
        "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        # Apply decoder layers\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Apply final layer norm\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # Project to vocabulary size\n",
        "        output = self.output_projection(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, start_tokens: torch.Tensor, max_length: int,\n",
        "                 temperature: float = 1.0) -> torch.Tensor:\n",
        "        self.eval()\n",
        "        current_seq = start_tokens\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length - start_tokens.size(1)):\n",
        "                # Ensure we're not exceeding the maximum sequence length\n",
        "                if current_seq.size(1) > self.max_seq_length:\n",
        "                    current_seq = current_seq[:, -self.max_seq_length:]\n",
        "\n",
        "                # Get model predictions\n",
        "                logits = self(current_seq)\n",
        "                next_token_logits = logits[:, -1, :] / temperature\n",
        "\n",
        "                # Sample next token\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # Append next token to sequence\n",
        "                current_seq = torch.cat([current_seq, next_token], dim=1)\n",
        "\n",
        "                # Check if we've generated an EOS token\n",
        "                if next_token.item() == self.vocab_size - 1:  # Assuming EOS is the last token\n",
        "                    break\n",
        "\n",
        "        return current_seq"
      ],
      "metadata": {
        "id": "hs7mWseS3hWV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Displaying the Decoder-only Transformer Architecture"
      ],
      "metadata": {
        "id": "YyhgXe9X7ytF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "# Initialize the model with some example parameters\n",
        "vocab_size = 10000\n",
        "d_model = 512\n",
        "nhead = 2\n",
        "num_layers = 1\n",
        "d_ff = 2048\n",
        "max_seq_length = 1024\n",
        "dropout = 0.1\n",
        "\n",
        "# Define your model\n",
        "model = DecoderOnlyTransformer(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "summary(model, input_size=(1, max_seq_length), dtypes=[torch.int64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49nYvRll78Ug",
        "outputId": "cdea85c1-e437-4a59-84d9-4fadba8b9296"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DecoderOnlyTransformer                        [1, 1024, 10000]          --\n",
              "├─Embedding: 1-1                              [1, 1024, 512]            5,120,000\n",
              "├─PositionalEncoding: 1-2                     [1, 1024, 512]            --\n",
              "├─ModuleList: 1-3                             --                        --\n",
              "│    └─DecoderLayer: 2-1                      [1, 1024, 512]            --\n",
              "│    │    └─LayerNorm: 3-1                    [1, 1024, 512]            1,024\n",
              "│    │    └─MaskedAttention: 3-2              [1, 1024, 512]            1,050,624\n",
              "│    │    └─Dropout: 3-3                      [1, 1024, 512]            --\n",
              "│    │    └─LayerNorm: 3-4                    [1, 1024, 512]            1,024\n",
              "│    │    └─FeedForward: 3-5                  [1, 1024, 512]            2,099,712\n",
              "│    │    └─Dropout: 3-6                      [1, 1024, 512]            --\n",
              "├─LayerNorm: 1-4                              [1, 1024, 512]            1,024\n",
              "├─Linear: 1-5                                 [1, 1024, 10000]          5,130,000\n",
              "===============================================================================================\n",
              "Total params: 13,403,408\n",
              "Trainable params: 13,403,408\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 12.35\n",
              "===============================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 119.67\n",
              "Params size (MB): 49.41\n",
              "Estimated Total Size (MB): 169.09\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Training the Decoder-only Transformer"
      ],
      "metadata": {
        "id": "qJMRxOoSB0Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tiny_shakespeare dataset\n",
        "dataset = load_dataset(\"tiny_shakespeare\", split=\"train\")\n",
        "# Load the tiny_shakespeare dataset\n",
        "# dataset = load_dataset(\"lyimo/shakespear\", split=\"train\")\n",
        "\n",
        "# Extract the text from the dataset\n",
        "texts = dataset[\"text\"]\n",
        "\n",
        "# Hyperparameters\n",
        "d_model = 256\n",
        "nhead = 2\n",
        "num_layers = 2\n",
        "d_ff = 256\n",
        "max_seq_length = 128\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.2\n",
        "\n",
        "# Tokenize and prepare data\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenizer.fit(texts)\n",
        "vocab_size = len(tokenizer.word_to_idx)\n",
        "\n",
        "dataset = TextDataset(texts, tokenizer, max_seq_length)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create model and move to device\n",
        "model = DecoderOnlyTransformer(vocab_size, d_model, nhead, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
        "\n",
        "# Create optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.word_to_idx[\"<PAD>\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_seq, _, _ = batch  # Unpack batch\n",
        "        input_seq = input_seq.squeeze(1).to(device)  # Move input to device and remove extra dimension\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_seq)\n",
        "\n",
        "\n",
        "        # Reshape output tensor\n",
        "        output = output[:, :-1, :].contiguous().view(-1, output.size(-1))  # Shift predictions to the left\n",
        "\n",
        "        # Shift targets to the right (original targets)\n",
        "        target_seq = input_seq[:, 1:].contiguous().view(-1)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output, target_seq)\n",
        "\n",
        "        # Debugging prints\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "          # Debugging prints\n",
        "          print(f\"Epoch: {epoch+1}, Batch: {batch_idx+1}\")\n",
        "          print(f\"Input sequence shape: {input_seq.shape}\")\n",
        "          print(f\"Input sequence: {input_seq.unsqueeze(1)}\")\n",
        "          print(f\"Output shape before reshape: {output.shape}\")\n",
        "          print(f\"Output shape after reshape: {output.shape}\")\n",
        "          print(f\"Target sequence shape: {target_seq.shape}\")\n",
        "\n",
        "    # Print epoch loss\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "gSUt8j7yBrcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd460906c5434436bb0ad4b122cb8616",
            "37a8f46704f14945bef2635440aa0bc9",
            "ce5253855acb4be4b0026ca55c1aaf23",
            "5b18da8645e14bc9bf817d19d9ac4bf7",
            "8c8a82d674674682b00aba4cd2e87dba",
            "844e303a4d7a4cfb9934bcab6746c945",
            "84c0bb59ed724811a5ef0473a40d867c",
            "d070ad3703a6435b9188cd7a17e9f1b9",
            "128acced85c148fd89c6530bfbf49ae1",
            "ad45f16aa83d49a3bdf0a67aa9ad0f2c",
            "6970f7710c074c9baed65efed2c6a2e3",
            "2816d1668fd042aca827a5685f815b59",
            "cc3d8de5049e48928fb68f5f18ef916c",
            "d966ec1f281a4f5aa5c140e3054eade4",
            "ed23753e83234294b11b9e8d84272580",
            "3b1c60ce0a0a4369a1fe277fbbff77f3",
            "410881f61a7941ee98e0fea1bed948be",
            "7676a6a0a1b84595a13887308cb55ee6",
            "ad1eea7a6fbc472bb5ecd071d50f172e",
            "2a483b76dede460784011ad5bc056fc2",
            "053d38cfbef2404485346b5cda96f523",
            "92944b62080e4770aa332bd2703a2f1d",
            "42c0d4c00f0345b79f0a7c4b293fd6b4",
            "204df83e2d60442281b00e07ad6725c3",
            "34619982bbde403cb4603ab126433b64",
            "f3bd58ecf11b41b48c260ea630e2a94a",
            "19511f6ed8bc4d9294ef28f3d20f46ca",
            "71bf45b35e76439b94063e47de734d01",
            "eb8e20d8825945029a38848fb92b0bc6",
            "56c90df872f4449ea9cfb78b2ed59c10",
            "bb86d1cfa7274329b718eec570d135d5",
            "70325a36fbc342ff9c54359eed0147fd",
            "f6f96202911143b1bf27eea07077ac44",
            "779594a3ce134ad186ea5fe72abf7aae",
            "d57bec07df304798810a71d8efed2afe",
            "d00f8829eda2428ba2b97553d34f7e85",
            "e2f6b5d1e88542d888abd70ae75047f1",
            "87863c8478f74a469eabd86f859feb7b",
            "3d9af869d0164bfea5160adafdac963b",
            "65f2b49d83ab4e2287044377945f42d4",
            "baf60e6b38ac4f87b38083d431f89df4",
            "8c7aac4d3a08459ea4081a552f5c6e95",
            "bbf2166e9786415b93b432cc440fe62c",
            "0b6706206abb4abeacf4d741dc5b4ca6",
            "5a0f3fe566a54d3a8f19bf797ff4345b",
            "a21df6419419451da7696d4945a9bcda",
            "b11878e97c984ca88790d5b031d82e65",
            "b8bea541198344b2af7bba9e34ad7ec2",
            "2e998e1fb7274e3589de073a1aa883d2",
            "9e1773bb38f14c4c9eb9702cbdf2321a",
            "71e9e801c3c4409b8d8ccbe1d53dc0ff",
            "4e57f719ec2c4ebe9c870a6cb61eac11",
            "8f2e8c74722c49b69bd091d7df8f6bba",
            "be4dc868fe6d46cb9038b9c7830eb1da",
            "557c543998dc49f587103be30ef618f5",
            "7d29503173f04d8998f9d3f91ba86a6f",
            "7bbe5aee32254f40a79ba6688a1d989a",
            "dd71a5de19ee40d9867aa4a5e719064a",
            "2fd83fc3e84749a7a053c4ba247fbf11",
            "d262a7075b8744be9012728db17bc75e",
            "1975fd2c6daf4b20a4da0dfa2ccfcbaa",
            "4e218252bc0343f4ac39e12e04c6f2e5",
            "01feab2fa8fa4d14a226bfae192401c9",
            "43abfe39db0a4fee8976cd60e3688dde",
            "d1b165bdfb7d4e8a85c491658251ab94",
            "7e4219bb0ad24fa3959264e546970dc6"
          ]
        },
        "outputId": "a8d455c0-13b9-436d-dea4-34fd05150e9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd460906c5434436bb0ad4b122cb8616"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2816d1668fd042aca827a5685f815b59"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for tiny_shakespeare contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tiny_shakespeare.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/435k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42c0d4c00f0345b79f0a7c4b293fd6b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "779594a3ce134ad186ea5fe72abf7aae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a0f3fe566a54d3a8f19bf797ff4345b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d29503173f04d8998f9d3f91ba86a6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23845\n",
            "Loss: 10.230379104614258\n",
            "Epoch: 1, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,   120,   604,  ...,    53,  5272,    44]],\n",
            "\n",
            "        [[    2,  6008,   621,  ...,    53, 12935,   102]],\n",
            "\n",
            "        [[    2,   221,   235,  ...,  1464,    68, 15352]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,   124,   142,  ...,   122, 18124,    28]],\n",
            "\n",
            "        [[    2,  6613,   529,  ...,    21,    46,  5532]],\n",
            "\n",
            "        [[    2,  2028,  8209,  ...,   235,  4709,  8219]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 10.25078010559082\n",
            "Loss: 10.250794410705566\n",
            "Loss: 10.237319946289062\n",
            "Loss: 10.231711387634277\n",
            "Loss: 10.222508430480957\n",
            "Loss: 10.237987518310547\n",
            "Loss: 10.212271690368652\n",
            "Loss: 10.215311050415039\n",
            "Loss: 10.223275184631348\n",
            "Loss: 10.2117280960083\n",
            "Loss: 10.201935768127441\n",
            "Loss: 10.206974029541016\n",
            "Loss: 10.209392547607422\n",
            "Loss: 10.203399658203125\n",
            "Loss: 10.198244094848633\n",
            "Loss: 10.201169967651367\n",
            "Loss: 10.198321342468262\n",
            "Loss: 10.182782173156738\n",
            "Loss: 10.174945831298828\n",
            "Loss: 10.191006660461426\n",
            "Loss: 10.188871383666992\n",
            "Loss: 10.185406684875488\n",
            "Loss: 10.170395851135254\n",
            "Loss: 10.160771369934082\n",
            "Loss: 10.16920280456543\n",
            "Loss: 10.166292190551758\n",
            "Loss: 10.15951919555664\n",
            "Loss: 10.167238235473633\n",
            "Loss: 10.154082298278809\n",
            "Loss: 10.150381088256836\n",
            "Loss: 10.151144027709961\n",
            "Loss: 10.134245872497559\n",
            "Loss: 10.14136028289795\n",
            "Loss: 10.13032054901123\n",
            "Loss: 10.137727737426758\n",
            "Loss: 10.125901222229004\n",
            "Loss: 10.180899620056152\n",
            "Epoch 1/10, Loss: 10.1886\n",
            "Loss: 10.097314834594727\n",
            "Epoch: 2, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,  7468,   122,  ...,  7308,  2622,  6697]],\n",
            "\n",
            "        [[    2,  1089,  1788,  ...,    61,  8360,  1296]],\n",
            "\n",
            "        [[    2,  3658,   147,  ..., 18260, 11350, 21321]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  7210, 14304,  ...,  1182,   635, 14327]],\n",
            "\n",
            "        [[    2,     7,   239,  ...,   102,  6909,   607]],\n",
            "\n",
            "        [[    2,   588,   501,  ...,    16,   809,   473]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 10.106201171875\n",
            "Loss: 10.094398498535156\n",
            "Loss: 10.097771644592285\n",
            "Loss: 10.090648651123047\n",
            "Loss: 10.09721565246582\n",
            "Loss: 10.073644638061523\n",
            "Loss: 10.074525833129883\n",
            "Loss: 10.071805953979492\n",
            "Loss: 10.075961112976074\n",
            "Loss: 10.055310249328613\n",
            "Loss: 10.074524879455566\n",
            "Loss: 10.056894302368164\n",
            "Loss: 10.0547513961792\n",
            "Loss: 10.05819034576416\n",
            "Loss: 10.058969497680664\n",
            "Loss: 10.047910690307617\n",
            "Loss: 10.040486335754395\n",
            "Loss: 10.026496887207031\n",
            "Loss: 10.020610809326172\n",
            "Loss: 10.022855758666992\n",
            "Loss: 10.019011497497559\n",
            "Loss: 10.01663875579834\n",
            "Loss: 10.007757186889648\n",
            "Loss: 10.003336906433105\n",
            "Loss: 9.99105167388916\n",
            "Loss: 9.971713066101074\n",
            "Loss: 9.982781410217285\n",
            "Loss: 9.973034858703613\n",
            "Loss: 9.953639030456543\n",
            "Loss: 9.955436706542969\n",
            "Loss: 9.942289352416992\n",
            "Loss: 9.946653366088867\n",
            "Loss: 9.931136131286621\n",
            "Loss: 9.898436546325684\n",
            "Loss: 9.910173416137695\n",
            "Loss: 9.906705856323242\n",
            "Loss: 9.933046340942383\n",
            "Epoch 2/10, Loss: 10.0195\n",
            "Loss: 9.874841690063477\n",
            "Epoch: 3, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2, 13213,   666,  ...,    12,    21,   235]],\n",
            "\n",
            "        [[    2,  2481,   621,  ...,    29,  1072,   897]],\n",
            "\n",
            "        [[    2,   122,   300,  ...,   108,  5573,   389]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2, 16808, 16809,  ...,   264, 16821,   619]],\n",
            "\n",
            "        [[    2,    46,  1236,  ...,    44, 12644, 20975]],\n",
            "\n",
            "        [[    2,    46,  6464,  ...,    56,    23,  6483]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 9.848584175109863\n",
            "Loss: 9.835999488830566\n",
            "Loss: 9.807732582092285\n",
            "Loss: 9.79296588897705\n",
            "Loss: 9.778053283691406\n",
            "Loss: 9.773492813110352\n",
            "Loss: 9.751548767089844\n",
            "Loss: 9.731037139892578\n",
            "Loss: 9.728681564331055\n",
            "Loss: 9.675215721130371\n",
            "Loss: 9.669300079345703\n",
            "Loss: 9.63872241973877\n",
            "Loss: 9.599637031555176\n",
            "Loss: 9.572981834411621\n",
            "Loss: 9.55469036102295\n",
            "Loss: 9.51968002319336\n",
            "Loss: 9.489015579223633\n",
            "Loss: 9.457773208618164\n",
            "Loss: 9.421387672424316\n",
            "Loss: 9.36349105834961\n",
            "Loss: 9.361696243286133\n",
            "Loss: 9.331441879272461\n",
            "Loss: 9.306883811950684\n",
            "Loss: 9.261338233947754\n",
            "Loss: 9.212761878967285\n",
            "Loss: 9.185009956359863\n",
            "Loss: 9.142363548278809\n",
            "Loss: 9.093256950378418\n",
            "Loss: 9.070703506469727\n",
            "Loss: 9.019469261169434\n",
            "Loss: 8.97665023803711\n",
            "Loss: 8.954721450805664\n",
            "Loss: 8.925722122192383\n",
            "Loss: 8.878528594970703\n",
            "Loss: 8.857193946838379\n",
            "Loss: 8.793516159057617\n",
            "Loss: 8.750067710876465\n",
            "Epoch 3/10, Loss: 9.3949\n",
            "Loss: 8.685157775878906\n",
            "Epoch: 4, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,  8059, 11911,  ...,   389,   314,    35]],\n",
            "\n",
            "        [[    2,  9706,  9707,  ..., 10391,   322,  2590]],\n",
            "\n",
            "        [[    2,   270,  3330,  ...,  1184,   897,    23]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  6692,   264,  ...,  1010,  1681,    17]],\n",
            "\n",
            "        [[    2, 14406,   389,  ..., 21323, 10186,    21]],\n",
            "\n",
            "        [[    2,   102,  1971,  ...,   685,   114,  3744]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 8.662312507629395\n",
            "Loss: 8.621347427368164\n",
            "Loss: 8.59289836883545\n",
            "Loss: 8.57835578918457\n",
            "Loss: 8.549400329589844\n",
            "Loss: 8.524690628051758\n",
            "Loss: 8.478023529052734\n",
            "Loss: 8.432391166687012\n",
            "Loss: 8.366323471069336\n",
            "Loss: 8.361557006835938\n",
            "Loss: 8.37524700164795\n",
            "Loss: 8.325918197631836\n",
            "Loss: 8.302658081054688\n",
            "Loss: 8.231345176696777\n",
            "Loss: 8.233638763427734\n",
            "Loss: 8.166057586669922\n",
            "Loss: 8.184075355529785\n",
            "Loss: 8.155657768249512\n",
            "Loss: 8.171038627624512\n",
            "Loss: 8.100980758666992\n",
            "Loss: 8.073660850524902\n",
            "Loss: 8.051233291625977\n",
            "Loss: 8.078546524047852\n",
            "Loss: 8.002686500549316\n",
            "Loss: 8.002171516418457\n",
            "Loss: 7.940013885498047\n",
            "Loss: 7.918228626251221\n",
            "Loss: 7.958131313323975\n",
            "Loss: 7.940041542053223\n",
            "Loss: 7.896629810333252\n",
            "Loss: 7.903168201446533\n",
            "Loss: 7.882355213165283\n",
            "Loss: 7.8577446937561035\n",
            "Loss: 7.893885612487793\n",
            "Loss: 7.849113941192627\n",
            "Loss: 7.809178829193115\n",
            "Loss: 7.846525192260742\n",
            "Epoch 4/10, Loss: 8.1843\n",
            "Loss: 7.782304763793945\n",
            "Epoch: 5, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,   142,    28,  ...,  1121,   192,   477]],\n",
            "\n",
            "        [[    2,    60,  2713,  ...,   376,  1089,   621]],\n",
            "\n",
            "        [[    2,   122,  1913,  ...,    17,  1948,   195]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,   122,   272,  ...,  1057,  5846,   635]],\n",
            "\n",
            "        [[    2,   539,   147,  ..., 21627,   147,  1422]],\n",
            "\n",
            "        [[    2,   172,  3481,  ...,  9991,  9992,   102]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.7807416915893555\n",
            "Loss: 7.787658214569092\n",
            "Loss: 7.7555155754089355\n",
            "Loss: 7.739869594573975\n",
            "Loss: 7.713539123535156\n",
            "Loss: 7.724016189575195\n",
            "Loss: 7.6917548179626465\n",
            "Loss: 7.734047889709473\n",
            "Loss: 7.675717830657959\n",
            "Loss: 7.658647537231445\n",
            "Loss: 7.683938503265381\n",
            "Loss: 7.704419136047363\n",
            "Loss: 7.676436424255371\n",
            "Loss: 7.715551376342773\n",
            "Loss: 7.620578289031982\n",
            "Loss: 7.601096153259277\n",
            "Loss: 7.64110803604126\n",
            "Loss: 7.581847667694092\n",
            "Loss: 7.6507568359375\n",
            "Loss: 7.683936595916748\n",
            "Loss: 7.590342998504639\n",
            "Loss: 7.54597282409668\n",
            "Loss: 7.608133316040039\n",
            "Loss: 7.633347034454346\n",
            "Loss: 7.580348014831543\n",
            "Loss: 7.574353218078613\n",
            "Loss: 7.62380313873291\n",
            "Loss: 7.57118034362793\n",
            "Loss: 7.556114673614502\n",
            "Loss: 7.635909080505371\n",
            "Loss: 7.64924955368042\n",
            "Loss: 7.585613250732422\n",
            "Loss: 7.559690952301025\n",
            "Loss: 7.602240085601807\n",
            "Loss: 7.603063106536865\n",
            "Loss: 7.5596442222595215\n",
            "Loss: 7.651030540466309\n",
            "Epoch 5/10, Loss: 7.6509\n",
            "Loss: 7.501795768737793\n",
            "Epoch: 6, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,  7058,    21,  ...,   284,  1306,    32]],\n",
            "\n",
            "        [[    2,    44,  7315,  ...,  1432,   122,   548]],\n",
            "\n",
            "        [[    2,  2432, 13976,  ...,  7201, 17607, 17608]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  1306,    32,  ...,    53,  1507,  1508]],\n",
            "\n",
            "        [[    2,    35,   443,  ...,   477,  1600, 22113]],\n",
            "\n",
            "        [[    2,  8704,  8705,  ...,   389,  8739,  8740]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.593413352966309\n",
            "Loss: 7.503868103027344\n",
            "Loss: 7.542642116546631\n",
            "Loss: 7.579221248626709\n",
            "Loss: 7.624009609222412\n",
            "Loss: 7.503668308258057\n",
            "Loss: 7.569045066833496\n",
            "Loss: 7.553654193878174\n",
            "Loss: 7.529605388641357\n",
            "Loss: 7.5462117195129395\n",
            "Loss: 7.540484428405762\n",
            "Loss: 7.536342620849609\n",
            "Loss: 7.581934452056885\n",
            "Loss: 7.548853874206543\n",
            "Loss: 7.573678970336914\n",
            "Loss: 7.512368679046631\n",
            "Loss: 7.548606872558594\n",
            "Loss: 7.523775577545166\n",
            "Loss: 7.5512189865112305\n",
            "Loss: 7.586370944976807\n",
            "Loss: 7.535110950469971\n",
            "Loss: 7.504080295562744\n",
            "Loss: 7.4931559562683105\n",
            "Loss: 7.557384490966797\n",
            "Loss: 7.499959468841553\n",
            "Loss: 7.520880699157715\n",
            "Loss: 7.501616477966309\n",
            "Loss: 7.495445728302002\n",
            "Loss: 7.519435882568359\n",
            "Loss: 7.508519172668457\n",
            "Loss: 7.500104904174805\n",
            "Loss: 7.57852029800415\n",
            "Loss: 7.539252758026123\n",
            "Loss: 7.493220329284668\n",
            "Loss: 7.486518383026123\n",
            "Loss: 7.540672779083252\n",
            "Loss: 7.660104274749756\n",
            "Epoch 6/10, Loss: 7.5391\n",
            "Loss: 7.528928279876709\n",
            "Epoch: 7, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,   635,  9985,  ..., 16503,  2590,   122]],\n",
            "\n",
            "        [[    2,  5234,  5235,  ...,  5257,  1095,    21]],\n",
            "\n",
            "        [[    2,  5815, 12013,  ...,   431,    35,  1604]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  7091,   635,  ...,  3661,  4681, 13579]],\n",
            "\n",
            "        [[    2,    23,   225,  ...,  5703,   102,  5704]],\n",
            "\n",
            "        [[    2,   114,  4989,  ...,  7095,   122,   123]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.533655166625977\n",
            "Loss: 7.524077415466309\n",
            "Loss: 7.503216743469238\n",
            "Loss: 7.493635177612305\n",
            "Loss: 7.522703170776367\n",
            "Loss: 7.487565040588379\n",
            "Loss: 7.4621453285217285\n",
            "Loss: 7.489168643951416\n",
            "Loss: 7.488234519958496\n",
            "Loss: 7.51878547668457\n",
            "Loss: 7.518345355987549\n",
            "Loss: 7.480541706085205\n",
            "Loss: 7.55442476272583\n",
            "Loss: 7.491486549377441\n",
            "Loss: 7.473033428192139\n",
            "Loss: 7.466471195220947\n",
            "Loss: 7.4962897300720215\n",
            "Loss: 7.512115955352783\n",
            "Loss: 7.499382972717285\n",
            "Loss: 7.517820835113525\n",
            "Loss: 7.471314907073975\n",
            "Loss: 7.535086631774902\n",
            "Loss: 7.420446395874023\n",
            "Loss: 7.479794979095459\n",
            "Loss: 7.522801876068115\n",
            "Loss: 7.513473987579346\n",
            "Loss: 7.517235279083252\n",
            "Loss: 7.4748640060424805\n",
            "Loss: 7.497279644012451\n",
            "Loss: 7.563783168792725\n",
            "Loss: 7.498847484588623\n",
            "Loss: 7.569616794586182\n",
            "Loss: 7.482692241668701\n",
            "Loss: 7.5508575439453125\n",
            "Loss: 7.510917663574219\n",
            "Loss: 7.476150989532471\n",
            "Loss: 7.521656036376953\n",
            "Epoch 7/10, Loss: 7.5044\n",
            "Loss: 7.4726386070251465\n",
            "Epoch: 8, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,  6229, 21315,  ...,    44,  3406,   165]],\n",
            "\n",
            "        [[    2,  3307,  4380,  ...,   540,  4399,  1057]],\n",
            "\n",
            "        [[    2,   124,    35,  ...,   424,  8620, 13017]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  1829,   122,  ...,  3555, 10560,    87]],\n",
            "\n",
            "        [[    2,   941,  1565,  ...,   365,   765,  1345]],\n",
            "\n",
            "        [[    2,   876,  1333,  ...,  9706,  9707,   379]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.506866931915283\n",
            "Loss: 7.453453063964844\n",
            "Loss: 7.471186637878418\n",
            "Loss: 7.449900150299072\n",
            "Loss: 7.4643049240112305\n",
            "Loss: 7.520570278167725\n",
            "Loss: 7.468027114868164\n",
            "Loss: 7.479312896728516\n",
            "Loss: 7.498661041259766\n",
            "Loss: 7.457115173339844\n",
            "Loss: 7.470601558685303\n",
            "Loss: 7.491530418395996\n",
            "Loss: 7.440182209014893\n",
            "Loss: 7.491878509521484\n",
            "Loss: 7.469839096069336\n",
            "Loss: 7.543754577636719\n",
            "Loss: 7.501109600067139\n",
            "Loss: 7.474504470825195\n",
            "Loss: 7.547615051269531\n",
            "Loss: 7.500452041625977\n",
            "Loss: 7.47062873840332\n",
            "Loss: 7.439105033874512\n",
            "Loss: 7.58120584487915\n",
            "Loss: 7.43419075012207\n",
            "Loss: 7.500507831573486\n",
            "Loss: 7.443591594696045\n",
            "Loss: 7.464893341064453\n",
            "Loss: 7.5022807121276855\n",
            "Loss: 7.469661235809326\n",
            "Loss: 7.471019744873047\n",
            "Loss: 7.536535263061523\n",
            "Loss: 7.474668025970459\n",
            "Loss: 7.504889965057373\n",
            "Loss: 7.469017505645752\n",
            "Loss: 7.423361778259277\n",
            "Loss: 7.477046966552734\n",
            "Loss: 7.233652114868164\n",
            "Epoch 8/10, Loss: 7.4755\n",
            "Loss: 7.471869468688965\n",
            "Epoch: 9, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,  1581,   115,  ...,  1632,    45,  1327]],\n",
            "\n",
            "        [[    2,   122,  1702,  ...,   966,   523,  6613]],\n",
            "\n",
            "        [[    2,  3451,   260,  ...,  3943,  1450,     7]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  2378, 14152,  ...,    35,  1334,   328]],\n",
            "\n",
            "        [[    2,   543,   240,  ...,    35,  5328,   102]],\n",
            "\n",
            "        [[    2,  1074,   117,  ...,  5189,   885,    49]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.401721477508545\n",
            "Loss: 7.424461841583252\n",
            "Loss: 7.447767734527588\n",
            "Loss: 7.4568657875061035\n",
            "Loss: 7.451162338256836\n",
            "Loss: 7.386911869049072\n",
            "Loss: 7.4847025871276855\n",
            "Loss: 7.445871829986572\n",
            "Loss: 7.431516647338867\n",
            "Loss: 7.56690788269043\n",
            "Loss: 7.488789081573486\n",
            "Loss: 7.460616111755371\n",
            "Loss: 7.449629783630371\n",
            "Loss: 7.445673942565918\n",
            "Loss: 7.500185966491699\n",
            "Loss: 7.504370212554932\n",
            "Loss: 7.4213128089904785\n",
            "Loss: 7.450514793395996\n",
            "Loss: 7.458888053894043\n",
            "Loss: 7.443780899047852\n",
            "Loss: 7.411646842956543\n",
            "Loss: 7.483493804931641\n",
            "Loss: 7.459497928619385\n",
            "Loss: 7.391307353973389\n",
            "Loss: 7.465610027313232\n",
            "Loss: 7.4335618019104\n",
            "Loss: 7.4752302169799805\n",
            "Loss: 7.438698768615723\n",
            "Loss: 7.4416890144348145\n",
            "Loss: 7.448891639709473\n",
            "Loss: 7.543017864227295\n",
            "Loss: 7.419703483581543\n",
            "Loss: 7.475030899047852\n",
            "Loss: 7.401985168457031\n",
            "Loss: 7.500189304351807\n",
            "Loss: 7.482531547546387\n",
            "Loss: 7.372767448425293\n",
            "Epoch 9/10, Loss: 7.4536\n",
            "Loss: 7.371369361877441\n",
            "Epoch: 10, Batch: 1\n",
            "Input sequence shape: torch.Size([64, 128])\n",
            "Input sequence: tensor([[[    2,   248,    17,  ...,   595,  3400,   122]],\n",
            "\n",
            "        [[    2,  5619,   173,  ...,   122,   123, 21415]],\n",
            "\n",
            "        [[    2,   122,  1257,  ..., 10990,  1224,   135]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,  1333,  6722,  ...,   285,  9436,   287]],\n",
            "\n",
            "        [[    2,   821,    12,  ...,  9102,    44,  4932]],\n",
            "\n",
            "        [[    2,    44,  2709,  ...,   590,   153,  4203]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([8128, 23845])\n",
            "Output shape after reshape: torch.Size([8128, 23845])\n",
            "Target sequence shape: torch.Size([8128])\n",
            "Loss: 7.429234027862549\n",
            "Loss: 7.389941215515137\n",
            "Loss: 7.439608573913574\n",
            "Loss: 7.443648338317871\n",
            "Loss: 7.436363220214844\n",
            "Loss: 7.481662273406982\n",
            "Loss: 7.451634407043457\n",
            "Loss: 7.456754684448242\n",
            "Loss: 7.4638261795043945\n",
            "Loss: 7.427252292633057\n",
            "Loss: 7.400466442108154\n",
            "Loss: 7.438788890838623\n",
            "Loss: 7.4176764488220215\n",
            "Loss: 7.446531295776367\n",
            "Loss: 7.403642654418945\n",
            "Loss: 7.395731449127197\n",
            "Loss: 7.4017181396484375\n",
            "Loss: 7.4043779373168945\n",
            "Loss: 7.4406256675720215\n",
            "Loss: 7.390570640563965\n",
            "Loss: 7.42020320892334\n",
            "Loss: 7.412413120269775\n",
            "Loss: 7.407607555389404\n",
            "Loss: 7.412168502807617\n",
            "Loss: 7.458731651306152\n",
            "Loss: 7.39983606338501\n",
            "Loss: 7.396461009979248\n",
            "Loss: 7.456642150878906\n",
            "Loss: 7.3969831466674805\n",
            "Loss: 7.469219207763672\n",
            "Loss: 7.427085876464844\n",
            "Loss: 7.422060489654541\n",
            "Loss: 7.396480083465576\n",
            "Loss: 7.429867744445801\n",
            "Loss: 7.42078971862793\n",
            "Loss: 7.428882598876953\n",
            "Loss: 7.058164596557617\n",
            "Epoch 10/10, Loss: 7.4143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Decoder-only Transformer"
      ],
      "metadata": {
        "id": "XEkV3lWgCsHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"Better three hours too soon than\", \" I believe I can \", \"My words fly up, my\", \"Brevity is \", \"Love looks not with the eyes, but\", \"To be or \"]\n",
        "\n",
        "for quote in texts:\n",
        "  start_tokens = torch.tensor(tokenizer.encode(quote)).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "  generated_tokens = model.generate(start_tokens, max_length=20, temperature=.9)\n",
        "  generated_text = tokenizer.decode(generated_tokens.squeeze().tolist())\n",
        "\n",
        "  print(generated_text)"
      ],
      "metadata": {
        "id": "ioC249m3-X2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bb7c89-878b-478e-b3c1-fb411ffd01ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better three hours too soon than no blame but a in Edward, By'r like young on bound their in fifteen\n",
            "I believe I can QUEEN disgrace, Bridget you, on Hastings, have you and this he small: of First Elizabeth It\n",
            "My words fly up, my prophesy Indeed, I. thus. Such wrap Menenius. amain, ever, pleader, Third fool, manner sugar, gin.\n",
            "<UNK> is thou thou you Warwick. not And forces captain gentle-sleeping Olympian cheek? For good Citizen: scarfs Jupiter, 'lordship:' wisely.\n",
            "Love looks not with the eyes, but are, well-warranted By to had nod; Marry, indeed. and SICINIUS: nice are such\n",
            "To be or begin. SCROOP: Cobham, youth: say. applause cheaper brazen duke? on Sneak he's he, went answering baseness material.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder-only with MoE instead of FFN\n",
        "\n",
        "In the Sparse Mixture of Experts (MoE) architecture, the self-attention mechanism within each transformer block stays the same.\n",
        "\n",
        "However, a key modification is made to the structure **of each block**: the standard **feed-forward neural network** is replaced with **multiple sparsely activated feed-forward networks, known as experts.**\n",
        "\n",
        "\"Sparse activation\" means that each token in the sequence is routed to only a small number of these experts—usually one or two—out of the entire pool.\n",
        "\n",
        "\n",
        "\n",
        "**✨ Additional Resources:**\n",
        "\n",
        "*   makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch [Link-huggingface](https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LYtAnvTb83kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Expert Layer"
      ],
      "metadata": {
        "id": "uDOiZz6LKT69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "    \"\"\" An MLP with a single hidden layer and ReLU activation, serving as an expert in a Mixture of Experts. \"\"\"\n",
        "    def __init__(self, n_embd: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "S9PuG3xQKZcp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Gating in MoE Architectures\n",
        "\n",
        "Types of gating in Mixture of Experts (MoE) systems include Top-k gating, Noisy Top-k gating (as implemented here), and other variants like Hierarchical gating or Soft gating.\n",
        "\n",
        "Gating is essential in MoE systems because it determines which experts to use for each input, allowing the model to specialize different experts for different types of inputs or tasks.\n",
        "\n",
        "Specifically, Noisy Top-k gating adds controlled randomness to the expert selection process, which can help balance expert utilization and potentially improve model performance by introducing exploration in the routing mechanism."
      ],
      "metadata": {
        "id": "KhIocpeCKevX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k_moe):\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        # Store the top_k_moe parameter which specifies the number of top experts to select\n",
        "        self.top_k_moe = top_k_moe\n",
        "        # Linear layer to compute logits for routing\n",
        "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
        "        # Linear layer to compute noise logits for added noise\n",
        "        self.noise_linear = nn.Linear(n_embed, num_experts)\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # Compute the logits for routing to experts\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "        # Compute the noise logits\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "        # Generate noise with standard deviation determined by softplus of noise logits\n",
        "        noise = torch.randn_like(logits) * F.softplus(noise_logits)\n",
        "        # Add noise to the original logits to get noisy logits\n",
        "        noisy_logits = logits + noise\n",
        "        # Select the top k logits and their indices from the noisy logits\n",
        "        top_k_moe_logits, indices = noisy_logits.topk(self.top_k_moe, dim=-1)\n",
        "        # Create a tensor full of -inf values\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
        "        # Scatter the top k logits into the zeros tensor to create a sparse logits tensor\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_moe_logits)\n",
        "        # Apply softmax to the sparse logits to get the final router output\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        # Return the router output and the indices of the selected experts\n",
        "        return router_output, indices"
      ],
      "metadata": {
        "id": "N1z8IuwGKjV3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📚 Sparse MoE Layer"
      ],
      "metadata": {
        "id": "OXoO2q9IKlmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k_moe):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        # Initialize the NoisyTopkRouter to determine which experts to activate\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k_moe)\n",
        "        # Create a list of expert networks, each being a feed-forward network\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        # Store the number of top experts to activate\n",
        "        self.top_k_moe = top_k_moe\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the gating output and indices from the router\n",
        "        gating_output, indices = self.router(x)\n",
        "        # Initialize the final output tensor with zeros, having the same shape as x\n",
        "        final_output = torch.zeros_like(x)\n",
        "        # Flatten the input tensor to simplify processing\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        # Flatten the gating output tensor to align with the flattened input\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        # Iterate over each expert\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            # Create a mask to identify where the current expert is used\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            # Flatten the expert mask to match the flattened input\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():  # Check if there are any positions using the current expert\n",
        "                # Extract the inputs for the current expert based on the mask\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                # Get the output from the current expert\n",
        "                expert_output = expert(expert_input)\n",
        "                # Get the gating scores for the current expert\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                # Compute the weighted output based on the gating scores\n",
        "                weighted_output = expert_output * gating_scores\n",
        "                # Add the weighted output to the final output tensor\n",
        "                final_output[expert_mask] += weighted_output.view_as(final_output[expert_mask])\n",
        "\n",
        "        # Return the final output tensor which combines the results from all activated experts\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "N6kQTACyKvhF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Decoder with Sparse MoE\n",
        "\n",
        "![Decoder Only Architecture](https://drive.google.com/uc?id=1ksROxQxf3b7dlBUoIQggzyLeBaPO-AQn)\n",
        "\n"
      ],
      "metadata": {
        "id": "pru3rAF3Kwg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayerMoE(nn.Module):\n",
        "    def __init__(self, d_model, nhead, d_ff, num_experts, top_k_moe, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.sparse_moe = SparseMoE(d_model, num_experts, top_k_moe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x2 = self.norm1(x)\n",
        "        attn_output, _ = self.self_attn(x2, x2, x2, attn_mask=self.generate_square_subsequent_mask(x.size(1)).to(x.device))\n",
        "        x = x + self.dropout1(attn_output)\n",
        "        x2 = self.norm2(x)\n",
        "        moe_output = self.sparse_moe(x2)\n",
        "        x = x + self.dropout2(moe_output)\n",
        "        return x\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "metadata": {
        "id": "t38S7EsDK3_r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Showcase how Sparse MoE handles its inputs\n",
        "\n",
        "-  Experiment: Change the number of experts in the SparseMoE_example model.\n",
        "  -  Observation: Observe how increasing or decreasing the number of experts affects the routing, gating outputs, and final output.\n",
        "\n",
        "- Experiment: Adjust the top_k_moe parameter to select more or fewer top experts.\n",
        "  - Observation: See how the number of experts activated for each token changes and how it impacts the final output.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGu0o0A00f3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SparseMoE_example(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k_moe):\n",
        "        super(SparseMoE_example, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k_moe)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k_moe = top_k_moe\n",
        "\n",
        "    def forward(self, x):\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                expert_output = expert(expert_input)\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "                final_output[expert_mask] += weighted_output.view_as(final_output[expert_mask])\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def forward_debug_example(self, x):\n",
        "        # Forward pass with debug prints\n",
        "        gating_output, indices = self.router(x)\n",
        "        print(\"Gating Output Shape:\", gating_output.shape)\n",
        "        print(\"Gating Output:\", gating_output)\n",
        "        print(\"Expert Indices Shape:\", indices.shape)\n",
        "        print(\"Expert Indices:\", indices)\n",
        "\n",
        "        print(\"Input Shape:\", x.shape)\n",
        "        print(\"Input:\", x)\n",
        "\n",
        "        final_output = torch.zeros_like(x)\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            print(\"\\n\" + \"-\"*50)\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                print(f\"Expert {i} Input Shape:\", expert_input.shape)\n",
        "                print(f\"Expert {i} Input:\", expert_input)\n",
        "\n",
        "                expert_output = expert(expert_input)\n",
        "                print(f\"Expert {i} Output Shape:\", expert_output.shape)\n",
        "                print(f\"Expert {i} Output:\", expert_output)\n",
        "\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                print(f\"Gating Scores for Expert {i}:\")\n",
        "                print(gating_scores.squeeze())\n",
        "\n",
        "                print(f\"Weighted Output for Expert {i}:\")\n",
        "                weighted_output = expert_output * gating_scores\n",
        "                print(weighted_output)\n",
        "\n",
        "                final_output[expert_mask] += weighted_output.view_as(final_output[expert_mask])\n",
        "                print(f\"Expert {i} final_output Shape:\", final_output[expert_mask].shape)\n",
        "                print(f\"Expert {i} final_output:\", final_output[expert_mask])\n",
        "\n",
        "        print(\"Final MoE Output Shape:\", final_output.shape)\n",
        "        print(\"Final MoE Output:\", final_output)\n",
        "        print(\"-\"*50)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "# Example usage and debugging prints\n",
        "def test_sparse_moe():\n",
        "    # Parameters\n",
        "    batch_size = 2   #\n",
        "    seq_length = 1   # number of tokens, if 1 then it is easier to see which experts are activated and how each embedding is calculated\n",
        "    n_embed = 5\n",
        "    num_experts = 6  # Increased number of experts\n",
        "    top_k_moe = 2   # If you modify, more or less experts will be activated for each input token\n",
        "\n",
        "    # Random input tensor (simulating token embeddings)\n",
        "    random_input = torch.randn(batch_size, seq_length, n_embed)\n",
        "\n",
        "    # Initialize SparseMoE\n",
        "    sparse_moe = SparseMoE_example(n_embed, num_experts, top_k_moe)\n",
        "\n",
        "    # Forward pass with debugging example\n",
        "    final_output = sparse_moe.forward_debug_example(random_input)\n",
        "\n",
        "    print(\"\\nRandom Input Tensor:\")\n",
        "    print(random_input)\n",
        "    print(\"\\nFinal Output Tensor (after MoE processing):\")\n",
        "    print(final_output)\n",
        "\n",
        "# Run the test function\n",
        "test_sparse_moe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DBAPMat0oJh",
        "outputId": "42287afd-f5a8-492c-8dce-51140461f101"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gating Output Shape: torch.Size([2, 1, 6])\n",
            "Gating Output: tensor([[[0.6733, 0.0000, 0.0000, 0.0000, 0.3267, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000, 0.3676, 0.0000, 0.6324]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "Expert Indices Shape: torch.Size([2, 1, 2])\n",
            "Expert Indices: tensor([[[0, 4]],\n",
            "\n",
            "        [[5, 3]]])\n",
            "Input Shape: torch.Size([2, 1, 5])\n",
            "Input: tensor([[[ 0.3745,  0.9364,  1.1533,  1.2270,  0.7363]],\n",
            "\n",
            "        [[-0.7316,  0.3322, -0.4338,  0.0275,  1.8612]]])\n",
            "\n",
            "--------------------------------------------------\n",
            "Expert 0 Input Shape: torch.Size([1, 5])\n",
            "Expert 0 Input: tensor([[0.3745, 0.9364, 1.1533, 1.2270, 0.7363]])\n",
            "Expert 0 Output Shape: torch.Size([1, 5])\n",
            "Expert 0 Output: tensor([[-0.1023, -0.5338,  0.2251,  0.2022, -0.5254]], grad_fn=<MulBackward0>)\n",
            "Gating Scores for Expert 0:\n",
            "tensor(0.6733, grad_fn=<SqueezeBackward0>)\n",
            "Weighted Output for Expert 0:\n",
            "tensor([[-0.0688, -0.3594,  0.1515,  0.1361, -0.3538]], grad_fn=<MulBackward0>)\n",
            "Expert 0 final_output Shape: torch.Size([1, 5])\n",
            "Expert 0 final_output: tensor([[-0.0688, -0.3594,  0.1515,  0.1361, -0.3538]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Expert 3 Input Shape: torch.Size([1, 5])\n",
            "Expert 3 Input: tensor([[-0.7316,  0.3322, -0.4338,  0.0275,  1.8612]])\n",
            "Expert 3 Output Shape: torch.Size([1, 5])\n",
            "Expert 3 Output: tensor([[ 0.1982,  0.2853,  0.1190, -0.5082, -0.4453]], grad_fn=<MulBackward0>)\n",
            "Gating Scores for Expert 3:\n",
            "tensor(0.3676, grad_fn=<SqueezeBackward0>)\n",
            "Weighted Output for Expert 3:\n",
            "tensor([[ 0.0729,  0.1049,  0.0437, -0.1868, -0.1637]], grad_fn=<MulBackward0>)\n",
            "Expert 3 final_output Shape: torch.Size([1, 5])\n",
            "Expert 3 final_output: tensor([[ 0.0729,  0.1049,  0.0437, -0.1868, -0.1637]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "\n",
            "--------------------------------------------------\n",
            "Expert 4 Input Shape: torch.Size([1, 5])\n",
            "Expert 4 Input: tensor([[0.3745, 0.9364, 1.1533, 1.2270, 0.7363]])\n",
            "Expert 4 Output Shape: torch.Size([1, 5])\n",
            "Expert 4 Output: tensor([[-0.5178,  0.3847,  0.1816,  0.0000,  0.6921]], grad_fn=<MulBackward0>)\n",
            "Gating Scores for Expert 4:\n",
            "tensor(0.3267, grad_fn=<SqueezeBackward0>)\n",
            "Weighted Output for Expert 4:\n",
            "tensor([[-0.1692,  0.1257,  0.0593,  0.0000,  0.2261]], grad_fn=<MulBackward0>)\n",
            "Expert 4 final_output Shape: torch.Size([1, 5])\n",
            "Expert 4 final_output: tensor([[-0.2380, -0.2338,  0.2109,  0.1361, -0.1277]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "\n",
            "--------------------------------------------------\n",
            "Expert 5 Input Shape: torch.Size([1, 5])\n",
            "Expert 5 Input: tensor([[-0.7316,  0.3322, -0.4338,  0.0275,  1.8612]])\n",
            "Expert 5 Output Shape: torch.Size([1, 5])\n",
            "Expert 5 Output: tensor([[ 0.6693, -0.2024,  0.4026,  0.0410,  0.2013]], grad_fn=<MulBackward0>)\n",
            "Gating Scores for Expert 5:\n",
            "tensor(0.6324, grad_fn=<SqueezeBackward0>)\n",
            "Weighted Output for Expert 5:\n",
            "tensor([[ 0.4233, -0.1280,  0.2546,  0.0259,  0.1273]], grad_fn=<MulBackward0>)\n",
            "Expert 5 final_output Shape: torch.Size([1, 5])\n",
            "Expert 5 final_output: tensor([[ 0.4961, -0.0231,  0.2983, -0.1609, -0.0364]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "Final MoE Output Shape: torch.Size([2, 1, 5])\n",
            "Final MoE Output: tensor([[[-0.2380, -0.2338,  0.2109,  0.1361, -0.1277]],\n",
            "\n",
            "        [[ 0.4961, -0.0231,  0.2983, -0.1609, -0.0364]]],\n",
            "       grad_fn=<IndexPutBackward0>)\n",
            "--------------------------------------------------\n",
            "\n",
            "Random Input Tensor:\n",
            "tensor([[[ 0.3745,  0.9364,  1.1533,  1.2270,  0.7363]],\n",
            "\n",
            "        [[-0.7316,  0.3322, -0.4338,  0.0275,  1.8612]]])\n",
            "\n",
            "Final Output Tensor (after MoE processing):\n",
            "tensor([[[-0.2380, -0.2338,  0.2109,  0.1361, -0.1277]],\n",
            "\n",
            "        [[ 0.4961, -0.0231,  0.2983, -0.1609, -0.0364]]],\n",
            "       grad_fn=<IndexPutBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Decoder-only Transformer with MoE"
      ],
      "metadata": {
        "id": "5BfeO9sAK5YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderOnlyTransformerMoE(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers, d_ff, max_seq_length, dropout, num_experts, top_k_moe):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length)\n",
        "        self.layers = nn.ModuleList([DecoderLayerMoE(d_model, nhead, d_ff, num_experts, top_k_moe, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.output = nn.Linear(d_model, vocab_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k_moe = top_k_moe\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        return self.output(x)\n",
        "\n",
        "    def generate(self, start_tokens: torch.Tensor, max_length: int, temperature: float = 1.0) -> torch.Tensor:\n",
        "        self.eval()\n",
        "        current_seq = start_tokens\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            # Generate tokens until max_length is reached or end token is generated\n",
        "            for _ in range(max_length - start_tokens.size(1)):\n",
        "                # Ensure the sequence length does not exceed max_seq_length\n",
        "                if current_seq.size(1) > self.max_seq_length:\n",
        "                    current_seq = current_seq[:, -self.max_seq_length:]\n",
        "\n",
        "                # Get logits from the model\n",
        "                logits = self(current_seq)\n",
        "\n",
        "                # Extract logits for the next token and scale by temperature\n",
        "                next_token_logits = logits[:, -1, :] / temperature\n",
        "\n",
        "                # Compute probabilities using softmax\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "\n",
        "                # Sample the next token from the probability distribution\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # Append the next token to the current sequence\n",
        "                current_seq = torch.cat([current_seq, next_token], dim=1)\n",
        "\n",
        "                # Stop if the end token is generated (vocab_size - 1 assumed to be the end token)\n",
        "                if next_token.item() == self.vocab_size - 1:\n",
        "                    break\n",
        "\n",
        "        # Return the generated sequence\n",
        "        return current_seq"
      ],
      "metadata": {
        "id": "KvbjHbTCLEuO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Displaying the Decoder-only Transformer with MoE Architecture"
      ],
      "metadata": {
        "id": "gXwM_wnqLL4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model with some example parameters\n",
        "vocab_size = 10000\n",
        "d_model = 512\n",
        "nhead = 2\n",
        "num_layers = 1\n",
        "d_ff = 2048\n",
        "max_seq_length = 1024\n",
        "dropout = 0.1\n",
        "num_experts = 4\n",
        "top_k_moe = 2\n",
        "\n",
        "# Define your model\n",
        "model = DecoderOnlyTransformer(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout,\n",
        ")\n",
        "\n",
        "# Define your model\n",
        "model_moe = DecoderOnlyTransformerMoE(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout,\n",
        "    num_experts=num_experts,\n",
        "    top_k_moe=top_k_moe\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "print(50*\"-\")\n",
        "print(summary(model, input_size=(1, max_seq_length), dtypes=[torch.int64]))\n",
        "print(50*\"-\")\n",
        "print(summary(model_moe, input_size=(1, max_seq_length), dtypes=[torch.int64]))"
      ],
      "metadata": {
        "id": "HPDbqV4ULPmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a93c9a3-ac94-4818-ea78-9eebd24d9933"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "DecoderOnlyTransformer                        [1, 1024, 10000]          --\n",
            "├─Embedding: 1-1                              [1, 1024, 512]            5,120,000\n",
            "├─PositionalEncoding: 1-2                     [1, 1024, 512]            --\n",
            "├─ModuleList: 1-3                             --                        --\n",
            "│    └─DecoderLayer: 2-1                      [1, 1024, 512]            --\n",
            "│    │    └─LayerNorm: 3-1                    [1, 1024, 512]            1,024\n",
            "│    │    └─MaskedAttention: 3-2              [1, 1024, 512]            1,050,624\n",
            "│    │    └─Dropout: 3-3                      [1, 1024, 512]            --\n",
            "│    │    └─LayerNorm: 3-4                    [1, 1024, 512]            1,024\n",
            "│    │    └─FeedForward: 3-5                  [1, 1024, 512]            2,099,712\n",
            "│    │    └─Dropout: 3-6                      [1, 1024, 512]            --\n",
            "├─LayerNorm: 1-4                              [1, 1024, 512]            1,024\n",
            "├─Linear: 1-5                                 [1, 1024, 10000]          5,130,000\n",
            "===============================================================================================\n",
            "Total params: 13,403,408\n",
            "Trainable params: 13,403,408\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 12.35\n",
            "===============================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 119.67\n",
            "Params size (MB): 49.41\n",
            "Estimated Total Size (MB): 169.09\n",
            "===============================================================================================\n",
            "--------------------------------------------------\n",
            "====================================================================================================\n",
            "Layer (type:depth-idx)                             Output Shape              Param #\n",
            "====================================================================================================\n",
            "DecoderOnlyTransformerMoE                          [1, 1024, 10000]          --\n",
            "├─Embedding: 1-1                                   [1, 1024, 512]            5,120,000\n",
            "├─PositionalEncoding: 1-2                          [1, 1024, 512]            --\n",
            "├─ModuleList: 1-3                                  --                        --\n",
            "│    └─DecoderLayerMoE: 2-1                        [1, 1024, 512]            --\n",
            "│    │    └─LayerNorm: 3-1                         [1, 1024, 512]            1,024\n",
            "│    │    └─MultiheadAttention: 3-2                [1, 1024, 512]            1,050,624\n",
            "│    │    └─Dropout: 3-3                           [1, 1024, 512]            --\n",
            "│    │    └─LayerNorm: 3-4                         [1, 1024, 512]            1,024\n",
            "│    │    └─SparseMoE: 3-5                         [1, 1024, 512]            8,402,952\n",
            "│    │    └─Dropout: 3-6                           [1, 1024, 512]            --\n",
            "├─LayerNorm: 1-4                                   [1, 1024, 512]            1,024\n",
            "├─Linear: 1-5                                      [1, 1024, 10000]          5,130,000\n",
            "====================================================================================================\n",
            "Total params: 19,706,648\n",
            "Trainable params: 19,706,648\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 4.31\n",
            "====================================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 140.71\n",
            "Params size (MB): 74.62\n",
            "Estimated Total Size (MB): 215.34\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_summary(model, input_size):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    dummy_input = torch.zeros(input_size, dtype=torch.int64).to(device)\n",
        "\n",
        "    def register_hook(module):\n",
        "        def hook(module, input, output):\n",
        "            class_name = module.__class__.__name__\n",
        "            module_idx = len(summary)\n",
        "            m_key = f\"{module_idx:03d} {class_name}\"\n",
        "            summary[m_key] = {}\n",
        "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
        "            if isinstance(output, torch.Tensor):\n",
        "                summary[m_key][\"output_shape\"] = list(output.size())\n",
        "            elif isinstance(output, (tuple, list)) and len(output) > 0 and isinstance(output[0], torch.Tensor):\n",
        "                summary[m_key][\"output_shape\"] = [list(out.size()) for out in output]\n",
        "            else:\n",
        "                summary[m_key][\"output_shape\"] = \"multiple outputs\"\n",
        "            params = sum(p.numel() for p in module.parameters())\n",
        "            summary[m_key][\"num_params\"] = params\n",
        "\n",
        "        if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList):\n",
        "            hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    summary = {}\n",
        "    hooks = []\n",
        "    model.apply(register_hook)\n",
        "    model(dummy_input)\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    print(\"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Input Shape\", \"Param #\"))\n",
        "    print(\"================================================================\")\n",
        "    total_params = 0\n",
        "    total_output = 0\n",
        "    for layer in summary:\n",
        "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
        "            layer,\n",
        "            str(summary[layer][\"input_shape\"]),\n",
        "            \"{0:,}\".format(summary[layer][\"num_params\"]),\n",
        "        )\n",
        "        total_params += summary[layer][\"num_params\"]\n",
        "        if isinstance(summary[layer][\"output_shape\"], list) and all(isinstance(i, int) for i in summary[layer][\"output_shape\"]):\n",
        "            total_output += np.prod(summary[layer][\"output_shape\"])\n",
        "        print(line_new)\n",
        "    print(\"================================================================\")\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "\n",
        "vocab_size = 10000\n",
        "d_model = 512\n",
        "nhead = 8\n",
        "num_layers = 1\n",
        "d_ff = 2048\n",
        "max_seq_length = 1024\n",
        "dropout = 0.1\n",
        "num_experts = 2\n",
        "top_k_moe = 1\n",
        "\n",
        "# Ensure you have the correct definitions for these classes\n",
        "# from your_model_definitions import DecoderOnlyTransformer, DecoderOnlyTransformerMoE\n",
        "\n",
        "model = DecoderOnlyTransformer(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout,\n",
        ")\n",
        "\n",
        "model_moe = DecoderOnlyTransformerMoE(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout,\n",
        "    num_experts=num_experts,\n",
        "    top_k_moe=top_k_moe\n",
        ")\n",
        "\n",
        "print(\"Summary for DecoderOnlyTransformer\")\n",
        "print_model_summary(model, (1, max_seq_length))\n",
        "\n",
        "print(\"\\nSummary for DecoderOnlyTransformerMoE\")\n",
        "print_model_summary(model_moe, (1, max_seq_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGHFvdZwpdqT",
        "outputId": "52f11162-7ef5-4e1e-cb22-bfe9fea433e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for DecoderOnlyTransformer\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)                Input Shape         Param #\n",
            "================================================================\n",
            "       000 Embedding                  [1, 1024]       5,120,000\n",
            "001 PositionalEncoding             [1, 1024, 512]               0\n",
            "       002 LayerNorm             [1, 1024, 512]           1,024\n",
            "003 MultiheadAttention             [1, 1024, 512]       1,050,624\n",
            " 004 MaskedAttention             [1, 1024, 512]       1,050,624\n",
            "         005 Dropout             [1, 1024, 512]               0\n",
            "       006 LayerNorm             [1, 1024, 512]           1,024\n",
            "          007 Linear             [1, 1024, 512]       1,050,624\n",
            "            008 ReLU            [1, 1024, 2048]               0\n",
            "         009 Dropout            [1, 1024, 2048]               0\n",
            "          010 Linear            [1, 1024, 2048]       1,049,088\n",
            "     011 FeedForward             [1, 1024, 512]       2,099,712\n",
            "         012 Dropout             [1, 1024, 512]               0\n",
            "    013 DecoderLayer             [1, 1024, 512]       3,152,384\n",
            "       014 LayerNorm             [1, 1024, 512]           1,024\n",
            "          015 Linear             [1, 1024, 512]       5,130,000\n",
            "016 DecoderOnlyTransformer                  [1, 1024]      13,403,408\n",
            "================================================================\n",
            "Total params: 33,109,536\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Summary for DecoderOnlyTransformerMoE\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)                Input Shape         Param #\n",
            "================================================================\n",
            "       000 Embedding                  [1, 1024]       5,120,000\n",
            "001 PositionalEncoding             [1, 1024, 512]               0\n",
            "       002 LayerNorm             [1, 1024, 512]           1,024\n",
            "003 MultiheadAttention             [1, 1024, 512]       1,050,624\n",
            "         004 Dropout             [1, 1024, 512]               0\n",
            "       005 LayerNorm             [1, 1024, 512]           1,024\n",
            "          006 Linear             [1, 1024, 512]           1,026\n",
            "          007 Linear             [1, 1024, 512]           1,026\n",
            " 008 NoisyTopkRouter             [1, 1024, 512]           2,052\n",
            "          009 Linear                 [222, 512]       1,050,624\n",
            "            010 ReLU                [222, 2048]               0\n",
            "          011 Linear                [222, 2048]       1,049,088\n",
            "         012 Dropout                 [222, 512]               0\n",
            "          013 Expert                 [222, 512]       2,099,712\n",
            "          014 Linear                 [802, 512]       1,050,624\n",
            "            015 ReLU                [802, 2048]               0\n",
            "          016 Linear                [802, 2048]       1,049,088\n",
            "         017 Dropout                 [802, 512]               0\n",
            "          018 Expert                 [802, 512]       2,099,712\n",
            "       019 SparseMoE             [1, 1024, 512]       4,201,476\n",
            "         020 Dropout             [1, 1024, 512]               0\n",
            " 021 DecoderLayerMoE             [1, 1024, 512]       5,254,148\n",
            "       022 LayerNorm             [1, 1024, 512]           1,024\n",
            "          023 Linear             [1, 1024, 512]       5,130,000\n",
            "024 DecoderOnlyTransformerMoE                  [1, 1024]      15,505,172\n",
            "================================================================\n",
            "Total params: 44,667,444\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Training the Decoder-only Transformer with MoE"
      ],
      "metadata": {
        "id": "lV4CGY2ZLo1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tiny_shakespeare dataset\n",
        "dataset = load_dataset(\"tiny_shakespeare\", split=\"train\")\n",
        "\n",
        "# Extract the text from the dataset\n",
        "texts = dataset[\"text\"]\n",
        "\n",
        "# Hyperparameters\n",
        "d_model = 128\n",
        "nhead = 2\n",
        "num_layers = 2\n",
        "d_ff = 256\n",
        "max_seq_length = 64\n",
        "batch_size = 32\n",
        "num_epochs = 1\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.2\n",
        "num_experts=4\n",
        "top_k_moe=2\n",
        "\n",
        "# Tokenize and prepare data\n",
        "tokenizer = SimpleTokenizer()\n",
        "tokenizer.fit(texts)\n",
        "vocab_size = len(tokenizer.word_to_idx)\n",
        "\n",
        "dataset = TextDataset(texts, tokenizer, max_seq_length)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create model and move to device\n",
        "model_moe = DecoderOnlyTransformerMoE(vocab_size, d_model, nhead, num_layers, d_ff, max_seq_length, dropout, num_experts, top_k_moe).to(device)\n",
        "\n",
        "# Create optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model_moe.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.word_to_idx[\"<PAD>\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model_moe.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_seq, _, _ = batch  # Unpack batch\n",
        "        input_seq = input_seq.squeeze(1).to(device)  # Move input to device and remove extra dimension\n",
        "\n",
        "        # Forward pass\n",
        "        output = model_moe(input_seq)\n",
        "\n",
        "\n",
        "        # Reshape output tensor\n",
        "        output = output[:, :-1, :].contiguous().view(-1, output.size(-1))  # Shift predictions to the left\n",
        "\n",
        "        # Shift targets to the right (original targets)\n",
        "        target_seq = input_seq[:, 1:].contiguous().view(-1)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output, target_seq)\n",
        "\n",
        "        # Debugging prints\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "          # Debugging prints\n",
        "          print(f\"Epoch: {epoch+1}, Batch: {batch_idx+1}\")\n",
        "          print(f\"Input sequence shape: {input_seq.shape}\")\n",
        "          print(f\"Input sequence: {input_seq.unsqueeze(1)}\")\n",
        "          print(f\"Output shape before reshape: {output.shape}\")\n",
        "          print(f\"Output shape after reshape: {output.shape}\")\n",
        "          print(f\"Target sequence shape: {target_seq.shape}\")\n",
        "\n",
        "    # Print epoch loss\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b587c362-046d-4416-9f93-93ad729c64c1",
        "id": "-HgiNedeLo1s"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23845\n",
            "Loss: 10.261877059936523\n",
            "Epoch: 1, Batch: 1\n",
            "Input sequence shape: torch.Size([32, 64])\n",
            "Input sequence: tensor([[[    2,  1721,   102,  ...,    35,  5782,    61]],\n",
            "\n",
            "        [[    2,    32,  4437,  ...,  4432,   102,  5270]],\n",
            "\n",
            "        [[    2, 10984,  1131,  ..., 14708,   122,   424]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[    2,   122,    46,  ..., 13476, 10791,   675]],\n",
            "\n",
            "        [[    2,  7823,  1873,  ..., 17657,   547,   144]],\n",
            "\n",
            "        [[    2,   235,  8362,  ...,  7171,   501,    35]]], device='cuda:0')\n",
            "Output shape before reshape: torch.Size([2016, 23845])\n",
            "Output shape after reshape: torch.Size([2016, 23845])\n",
            "Target sequence shape: torch.Size([2016])\n",
            "Loss: 10.270655632019043\n",
            "Loss: 10.238564491271973\n",
            "Loss: 10.24071979522705\n",
            "Loss: 10.202763557434082\n",
            "Loss: 10.206976890563965\n",
            "Loss: 10.17464542388916\n",
            "Loss: 10.15494441986084\n",
            "Loss: 10.17193603515625\n",
            "Loss: 10.165684700012207\n",
            "Loss: 10.136601448059082\n",
            "Loss: 10.122502326965332\n",
            "Loss: 10.115411758422852\n",
            "Loss: 10.085820198059082\n",
            "Loss: 10.069578170776367\n",
            "Loss: 10.052993774414062\n",
            "Loss: 10.043012619018555\n",
            "Loss: 10.05695915222168\n",
            "Loss: 10.026860237121582\n",
            "Loss: 10.028369903564453\n",
            "Loss: 9.992074012756348\n",
            "Loss: 9.9564790725708\n",
            "Loss: 9.952384948730469\n",
            "Loss: 9.952913284301758\n",
            "Loss: 9.95435905456543\n",
            "Loss: 9.956711769104004\n",
            "Loss: 9.929399490356445\n",
            "Loss: 9.913811683654785\n",
            "Loss: 9.896450996398926\n",
            "Loss: 9.868489265441895\n",
            "Loss: 9.871831893920898\n",
            "Loss: 9.811405181884766\n",
            "Loss: 9.830259323120117\n",
            "Loss: 9.79561996459961\n",
            "Loss: 9.810707092285156\n",
            "Loss: 9.813199996948242\n",
            "Loss: 9.781349182128906\n",
            "Loss: 9.75342082977295\n",
            "Loss: 9.733785629272461\n",
            "Loss: 9.752305030822754\n",
            "Loss: 9.753829956054688\n",
            "Loss: 9.697866439819336\n",
            "Loss: 9.7161865234375\n",
            "Loss: 9.714071273803711\n",
            "Loss: 9.666318893432617\n",
            "Loss: 9.655028343200684\n",
            "Loss: 9.646909713745117\n",
            "Loss: 9.634628295898438\n",
            "Loss: 9.58342456817627\n",
            "Loss: 9.593189239501953\n",
            "Loss: 9.564047813415527\n",
            "Loss: 9.529120445251465\n",
            "Loss: 9.557951927185059\n",
            "Loss: 9.531270027160645\n",
            "Loss: 9.51551342010498\n",
            "Loss: 9.50854778289795\n",
            "Loss: 9.491681098937988\n",
            "Loss: 9.484231948852539\n",
            "Loss: 9.475778579711914\n",
            "Loss: 9.472840309143066\n",
            "Loss: 9.460468292236328\n",
            "Loss: 9.42160415649414\n",
            "Loss: 9.440877914428711\n",
            "Loss: 9.401121139526367\n",
            "Loss: 9.38758373260498\n",
            "Loss: 9.364280700683594\n",
            "Loss: 9.32050609588623\n",
            "Loss: 9.35550308227539\n",
            "Loss: 9.381734848022461\n",
            "Loss: 9.347031593322754\n",
            "Loss: 9.29560661315918\n",
            "Loss: 9.294384002685547\n",
            "Loss: 9.285661697387695\n",
            "Loss: 9.263826370239258\n",
            "Loss: 9.239236831665039\n",
            "Loss: 9.19846248626709\n",
            "Loss: 9.214310646057129\n",
            "Loss: 9.213274955749512\n",
            "Loss: 9.215174674987793\n",
            "Loss: 9.199583053588867\n",
            "Loss: 9.241162300109863\n",
            "Loss: 9.152181625366211\n",
            "Loss: 9.156396865844727\n",
            "Loss: 9.105830192565918\n",
            "Loss: 9.116084098815918\n",
            "Loss: 9.053656578063965\n",
            "Loss: 9.111189842224121\n",
            "Loss: 9.082128524780273\n",
            "Loss: 9.082101821899414\n",
            "Loss: 9.051356315612793\n",
            "Loss: 9.040481567382812\n",
            "Loss: 9.025175094604492\n",
            "Loss: 9.02444839477539\n",
            "Loss: 9.030155181884766\n",
            "Loss: 9.02701187133789\n",
            "Loss: 8.975347518920898\n",
            "Loss: 8.981635093688965\n",
            "Loss: 8.997403144836426\n",
            "Loss: 8.95772647857666\n",
            "Loss: 8.94183349609375\n",
            "Loss: 8.956815719604492\n",
            "Loss: 8.927041053771973\n",
            "Loss: 8.930902481079102\n",
            "Loss: 8.879251480102539\n",
            "Loss: 8.962319374084473\n",
            "Loss: 8.898520469665527\n",
            "Loss: 8.831963539123535\n",
            "Loss: 8.891141891479492\n",
            "Loss: 8.897143363952637\n",
            "Loss: 8.806450843811035\n",
            "Loss: 8.828251838684082\n",
            "Loss: 8.80097770690918\n",
            "Loss: 8.860340118408203\n",
            "Loss: 8.817506790161133\n",
            "Loss: 8.809650421142578\n",
            "Loss: 8.83255672454834\n",
            "Loss: 8.744661331176758\n",
            "Loss: 8.748297691345215\n",
            "Loss: 8.784956932067871\n",
            "Loss: 8.758316993713379\n",
            "Loss: 8.716435432434082\n",
            "Loss: 8.782402992248535\n",
            "Loss: 8.716562271118164\n",
            "Loss: 8.699993133544922\n",
            "Loss: 8.760871887207031\n",
            "Loss: 8.655431747436523\n",
            "Loss: 8.669703483581543\n",
            "Loss: 8.706405639648438\n",
            "Loss: 8.696317672729492\n",
            "Loss: 8.634496688842773\n",
            "Loss: 8.638912200927734\n",
            "Loss: 8.696534156799316\n",
            "Loss: 8.615690231323242\n",
            "Loss: 8.607266426086426\n",
            "Loss: 8.645770072937012\n",
            "Loss: 8.625794410705566\n",
            "Loss: 8.611044883728027\n",
            "Loss: 8.553797721862793\n",
            "Loss: 8.611600875854492\n",
            "Loss: 8.584207534790039\n",
            "Loss: 8.510202407836914\n",
            "Loss: 8.576748847961426\n",
            "Loss: 8.527833938598633\n",
            "Loss: 8.511467933654785\n",
            "Loss: 8.484092712402344\n",
            "Loss: 8.490011215209961\n",
            "Loss: 8.55168628692627\n",
            "Loss: 8.520374298095703\n",
            "Loss: 8.467972755432129\n",
            "Loss: 8.47928524017334\n",
            "Loss: 8.452774047851562\n",
            "Loss: 8.471489906311035\n",
            "Loss: 8.412786483764648\n",
            "Loss: 8.437175750732422\n",
            "Loss: 8.419309616088867\n",
            "Loss: 8.435898780822754\n",
            "Loss: 8.367344856262207\n",
            "Loss: 8.38836669921875\n",
            "Loss: 8.414973258972168\n",
            "Loss: 8.390509605407715\n",
            "Loss: 8.391694068908691\n",
            "Loss: 8.403855323791504\n",
            "Loss: 8.389885902404785\n",
            "Loss: 8.440041542053223\n",
            "Loss: 8.394015312194824\n",
            "Loss: 8.365283966064453\n",
            "Loss: 8.389524459838867\n",
            "Loss: 8.406003952026367\n",
            "Loss: 8.275915145874023\n",
            "Loss: 8.340595245361328\n",
            "Loss: 8.32407283782959\n",
            "Loss: 8.246935844421387\n",
            "Loss: 8.265621185302734\n",
            "Loss: 8.229063987731934\n",
            "Loss: 8.377801895141602\n",
            "Loss: 8.248552322387695\n",
            "Loss: 8.184814453125\n",
            "Loss: 8.323019981384277\n",
            "Loss: 8.21218204498291\n",
            "Loss: 8.257763862609863\n",
            "Loss: 8.251923561096191\n",
            "Loss: 8.242172241210938\n",
            "Loss: 8.277796745300293\n",
            "Loss: 8.163625717163086\n",
            "Loss: 8.182385444641113\n",
            "Loss: 8.20995044708252\n",
            "Loss: 8.211647033691406\n",
            "Loss: 8.248343467712402\n",
            "Loss: 8.124208450317383\n",
            "Loss: 8.1240873336792\n",
            "Loss: 8.143362998962402\n",
            "Loss: 8.166481971740723\n",
            "Loss: 8.145767211914062\n",
            "Loss: 8.107877731323242\n",
            "Loss: 8.15596866607666\n",
            "Loss: 8.08277702331543\n",
            "Loss: 8.080209732055664\n",
            "Loss: 8.131842613220215\n",
            "Loss: 8.024539947509766\n",
            "Loss: 8.10939884185791\n",
            "Loss: 8.14107894897461\n",
            "Loss: 8.141654014587402\n",
            "Loss: 8.077802658081055\n",
            "Loss: 8.072579383850098\n",
            "Loss: 8.077841758728027\n",
            "Loss: 8.135823249816895\n",
            "Loss: 8.014826774597168\n",
            "Loss: 8.118943214416504\n",
            "Loss: 8.082263946533203\n",
            "Loss: 8.028653144836426\n",
            "Loss: 7.999658584594727\n",
            "Loss: 8.020353317260742\n",
            "Loss: 8.134669303894043\n",
            "Loss: 7.945064544677734\n",
            "Loss: 7.987025260925293\n",
            "Loss: 7.901312828063965\n",
            "Loss: 8.02263069152832\n",
            "Loss: 8.030200958251953\n",
            "Loss: 8.03069019317627\n",
            "Loss: 7.9717254638671875\n",
            "Loss: 7.956814289093018\n",
            "Loss: 7.9214186668396\n",
            "Loss: 8.06312370300293\n",
            "Loss: 7.927814483642578\n",
            "Loss: 7.999311447143555\n",
            "Loss: 7.979533672332764\n",
            "Loss: 7.975318431854248\n",
            "Loss: 7.924520492553711\n",
            "Loss: 7.965388298034668\n",
            "Loss: 7.888427257537842\n",
            "Loss: 7.87239933013916\n",
            "Loss: 7.993356227874756\n",
            "Loss: 7.967030048370361\n",
            "Loss: 7.988238334655762\n",
            "Loss: 7.896203994750977\n",
            "Loss: 7.864570140838623\n",
            "Loss: 7.952320098876953\n",
            "Loss: 7.879108428955078\n",
            "Loss: 7.981339454650879\n",
            "Loss: 7.964471340179443\n",
            "Loss: 7.827474117279053\n",
            "Loss: 7.868134498596191\n",
            "Loss: 7.876636505126953\n",
            "Loss: 7.844648361206055\n",
            "Loss: 7.9308390617370605\n",
            "Loss: 7.878994941711426\n",
            "Loss: 7.853414535522461\n",
            "Loss: 7.822618007659912\n",
            "Loss: 7.966264247894287\n",
            "Loss: 7.929267406463623\n",
            "Loss: 7.80389404296875\n",
            "Loss: 7.79873514175415\n",
            "Loss: 7.797382831573486\n",
            "Loss: 7.904282093048096\n",
            "Loss: 7.89309549331665\n",
            "Loss: 7.833519458770752\n",
            "Loss: 7.826247215270996\n",
            "Loss: 7.8321533203125\n",
            "Loss: 7.817224979400635\n",
            "Loss: 7.76162052154541\n",
            "Loss: 7.821134567260742\n",
            "Loss: 7.8250041007995605\n",
            "Loss: 7.84175968170166\n",
            "Loss: 7.752161026000977\n",
            "Loss: 7.827123641967773\n",
            "Loss: 7.759766578674316\n",
            "Loss: 7.822987079620361\n",
            "Loss: 7.829774379730225\n",
            "Loss: 7.77882194519043\n",
            "Loss: 7.874495983123779\n",
            "Loss: 7.824977397918701\n",
            "Loss: 7.750943183898926\n",
            "Loss: 7.8188676834106445\n",
            "Loss: 7.914344787597656\n",
            "Loss: 7.772390365600586\n",
            "Loss: 7.744022369384766\n",
            "Loss: 7.785485744476318\n",
            "Loss: 7.82028341293335\n",
            "Loss: 7.771312713623047\n",
            "Loss: 7.80911111831665\n",
            "Loss: 7.719114780426025\n",
            "Loss: 7.765755653381348\n",
            "Loss: 7.768681049346924\n",
            "Loss: 7.827415943145752\n",
            "Loss: 7.778834342956543\n",
            "Loss: 7.807414531707764\n",
            "Loss: 7.71794319152832\n",
            "Loss: 7.720571517944336\n",
            "Loss: 7.689694404602051\n",
            "Loss: 7.7330851554870605\n",
            "Loss: 7.713138103485107\n",
            "Loss: 7.761752605438232\n",
            "Loss: 7.669188022613525\n",
            "Loss: 7.711510181427002\n",
            "Loss: 7.640820503234863\n",
            "Loss: 7.681550025939941\n",
            "Loss: 7.715522289276123\n",
            "Loss: 7.787132263183594\n",
            "Loss: 7.737898826599121\n",
            "Loss: 7.77963399887085\n",
            "Loss: 7.716394901275635\n",
            "Loss: 7.753742694854736\n",
            "Loss: 7.735354900360107\n",
            "Loss: 7.752674102783203\n",
            "Loss: 7.753233432769775\n",
            "Loss: 7.643437385559082\n",
            "Loss: 7.643442630767822\n",
            "Loss: 7.661619186401367\n",
            "Loss: 7.68166971206665\n",
            "Loss: 7.710940361022949\n",
            "Loss: 7.581505298614502\n",
            "Loss: 7.706419944763184\n",
            "Loss: 7.579286575317383\n",
            "Loss: 7.683081150054932\n",
            "Loss: 7.634695053100586\n",
            "Loss: 7.623138904571533\n",
            "Loss: 7.664268970489502\n",
            "Loss: 7.67573356628418\n",
            "Loss: 7.7588276863098145\n",
            "Loss: 7.690434455871582\n",
            "Loss: 7.685659408569336\n",
            "Loss: 7.712226867675781\n",
            "Loss: 7.66090726852417\n",
            "Loss: 7.6862874031066895\n",
            "Loss: 7.7112298011779785\n",
            "Loss: 7.731638431549072\n",
            "Loss: 7.647180080413818\n",
            "Loss: 7.677906036376953\n",
            "Loss: 7.740442276000977\n",
            "Loss: 7.634504318237305\n",
            "Loss: 7.721520900726318\n",
            "Loss: 7.690523624420166\n",
            "Loss: 7.704960346221924\n",
            "Loss: 7.706173896789551\n",
            "Loss: 7.658942222595215\n",
            "Loss: 7.727836608886719\n",
            "Loss: 7.626070976257324\n",
            "Loss: 7.666816234588623\n",
            "Loss: 7.6558966636657715\n",
            "Loss: 7.680575847625732\n",
            "Loss: 7.645217418670654\n",
            "Loss: 7.726956844329834\n",
            "Loss: 7.646601676940918\n",
            "Loss: 7.679998874664307\n",
            "Loss: 7.653641223907471\n",
            "Loss: 7.660104274749756\n",
            "Loss: 7.647887229919434\n",
            "Loss: 7.793659687042236\n",
            "Loss: 7.6530256271362305\n",
            "Loss: 7.644881248474121\n",
            "Loss: 7.609131336212158\n",
            "Loss: 7.582143306732178\n",
            "Loss: 7.64130973815918\n",
            "Loss: 7.740518093109131\n",
            "Loss: 7.591014862060547\n",
            "Loss: 7.710648059844971\n",
            "Loss: 7.581625938415527\n",
            "Loss: 7.63201379776001\n",
            "Loss: 7.675281047821045\n",
            "Loss: 7.6690802574157715\n",
            "Loss: 7.658535003662109\n",
            "Loss: 7.5872111320495605\n",
            "Loss: 7.659914493560791\n",
            "Loss: 7.66679048538208\n",
            "Loss: 7.662105560302734\n",
            "Loss: 7.5798659324646\n",
            "Loss: 7.67555570602417\n",
            "Loss: 7.71649169921875\n",
            "Loss: 7.671566486358643\n",
            "Loss: 7.704537868499756\n",
            "Loss: 7.66271448135376\n",
            "Loss: 7.58782958984375\n",
            "Loss: 7.595783710479736\n",
            "Loss: 7.59683084487915\n",
            "Loss: 7.657954692840576\n",
            "Loss: 7.601309299468994\n",
            "Loss: 7.614686489105225\n",
            "Loss: 7.68699312210083\n",
            "Loss: 7.666370868682861\n",
            "Loss: 7.660968780517578\n",
            "Loss: 7.622446060180664\n",
            "Loss: 7.632563591003418\n",
            "Loss: 7.580970287322998\n",
            "Loss: 7.638571739196777\n",
            "Loss: 7.714606761932373\n",
            "Loss: 7.510675430297852\n",
            "Loss: 7.710067272186279\n",
            "Loss: 7.642498970031738\n",
            "Loss: 7.63908052444458\n",
            "Loss: 7.59196138381958\n",
            "Loss: 7.547094345092773\n",
            "Loss: 7.654129505157471\n",
            "Loss: 7.66440486907959\n",
            "Loss: 7.597672462463379\n",
            "Loss: 7.67864990234375\n",
            "Loss: 7.585055828094482\n",
            "Loss: 7.488221645355225\n",
            "Loss: 7.605073928833008\n",
            "Loss: 7.515326499938965\n",
            "Loss: 7.686676025390625\n",
            "Loss: 7.642583847045898\n",
            "Loss: 7.6076555252075195\n",
            "Loss: 7.5884175300598145\n",
            "Loss: 7.766192436218262\n",
            "Loss: 7.619784832000732\n",
            "Loss: 7.646614074707031\n",
            "Loss: 7.625593662261963\n",
            "Loss: 7.668914318084717\n",
            "Loss: 7.618960857391357\n",
            "Loss: 7.616124153137207\n",
            "Loss: 7.621223449707031\n",
            "Loss: 7.588453769683838\n",
            "Loss: 7.638576030731201\n",
            "Loss: 7.632201194763184\n",
            "Loss: 7.552405834197998\n",
            "Loss: 7.5738205909729\n",
            "Loss: 7.556293487548828\n",
            "Loss: 7.730719089508057\n",
            "Loss: 7.631274700164795\n",
            "Loss: 7.62583065032959\n",
            "Loss: 7.546695232391357\n",
            "Loss: 7.566863536834717\n",
            "Loss: 7.569889545440674\n",
            "Loss: 7.65093994140625\n",
            "Loss: 7.583180904388428\n",
            "Loss: 7.621924877166748\n",
            "Loss: 7.571688652038574\n",
            "Loss: 7.465110778808594\n",
            "Loss: 7.610771179199219\n",
            "Loss: 7.610950469970703\n",
            "Loss: 7.588746070861816\n",
            "Loss: 7.650008678436279\n",
            "Loss: 7.656631946563721\n",
            "Loss: 7.529860019683838\n",
            "Loss: 7.482013702392578\n",
            "Loss: 7.654877662658691\n",
            "Loss: 7.508872985839844\n",
            "Loss: 7.61838960647583\n",
            "Loss: 7.617926597595215\n",
            "Epoch 1/1, Loss: 8.3345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Testing the Decoder-only Transformer with MoE"
      ],
      "metadata": {
        "id": "Ll7zTpyWLo1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"Better three hours too soon than\", \" I believe I can \", \"My words fly up, my\", \"Brevity is \", \"Love looks not with the eyes, but\", \"To be or \"]\n",
        "\n",
        "for quote in texts:\n",
        "  start_tokens = torch.tensor(tokenizer.encode(quote)).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "  generated_tokens = model_moe.generate(start_tokens, max_length=20, temperature=.9)\n",
        "  generated_text = tokenizer.decode(generated_tokens.squeeze().tolist())\n",
        "\n",
        "  print(generated_text)"
      ],
      "metadata": {
        "id": "yDzYIElYLo1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d04d447-e389-4464-ed9e-62c03b61b819"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better three hours too soon than you humour he A to deep it Teaching Gaunt, me the use QUEEN their\n",
            "I believe I can begin great for the I Marcius, these And Of too Lancaster; than And the from of\n",
            "My words fly up, my from O, here? in wed prorogue whom do sirrah, Now, my a the would we\n",
            "<UNK> is to of should they covenant their The and to you, by of then fall a function, I is\n",
            "Love looks not with the eyes, but creeping A first him I I King have agony. and be not pardoning\n",
            "To be or verier his makes Aufidius I and royal is of, hotly you along one without knowledge, In But\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7m4vkkwN5NS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}