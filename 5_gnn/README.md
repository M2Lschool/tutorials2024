# [[M2L2024](https://www.m2lschool.org/home)] Tutorial 5: Graph Neural Networks

**Authors:** Masha Samsikova and Wilfried Bounsi

--- 

Welcome to the final tutorial of the summer school! Congratulations on getting this far :-)

Today we will look at Graph Neural Networks (GNNs)! GNNs are a powerful and widespread class of Neural Network models specifically designed to operate over graph structures. In Part I, we will look at how to build the most common types of GNNs. Next, in Part II, we will look at an interesting application of GNNs -- using them to estimate missing data in a dataset. Finally, in Part III, we will look at more advanced topics such as how to scale GNNs to massive graphs and on a mathematical phenomenon known as over-squashing -- information being "squashed" due to exponential amounts of information being observed by a single node. 

### Outline

* Part I: Introduction to Graph Neural Nets
    * Graph Convolution Network (GCN) Implementation.
    * Graph Attention Network (GAT) Implementation.
    * Efficient GAT and GCN implementations with Sparse Matrix operations.
    * Node classification on the Cora dataset: training, evaluation & analysis.
* Part II: Missing Data Estimation
    *  Use GNNs to estimate missing training data
* Part III: Advanced Topics
    * Scaling GNNs to massive graphs
    * Over-squashing

### Notebooks

#### Part I:
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/5_gnn/part_I/introduction_to_gnns.ipynb)


#### Part II:
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/5_gnn/part_II/Missing_data_estimation.ipynb)


#### Part III: 
Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/M2Lschool/tutorials2024/blob/main/5_gnn/part_III/gnns_advanced_topics.ipynb)

---
