{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHa51EeXfL9E"
      },
      "source": [
        "In this part of our tutorial, we will explore how GNNs can be used to estimate missing tabular data on the [extended Iris dataset](https://www.kaggle.com/datasets/samybaladram/iris-dataset-extended/data). The approach we will be implementing is called GRAPE and can be found [this paper](https://proceedings.neurips.cc/paper/2020/file/dc36f18a9a0a776671d4879cae69b551-Paper.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Ot6qEL8hEV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Required setup\n",
        "!pip3 install torch_geometric\n",
        "\n",
        "# Downloads and unpacks the dataset\n",
        "!kaggle datasets download -d samybaladram/iris-dataset-extended\n",
        "!unzip iris-dataset-extended.zip\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.datasets as datasets\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4DTf1gagbWk"
      },
      "source": [
        "First, let's look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zW6oDiJgF53"
      },
      "outputs": [],
      "source": [
        "iris_df = pd.read_csv('iris_extended.csv')\n",
        "iris_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFcEjPTEknRf"
      },
      "source": [
        "We have a bunch of categorical variables, let's encode them using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yybdzUshkZW8"
      },
      "outputs": [],
      "source": [
        "iris_df = pd.get_dummies(iris_df, drop_first=True)\n",
        "iris_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cG7hNrtxipIk"
      },
      "outputs": [],
      "source": [
        "# @title Consider normalizing the dataset\n",
        "\n",
        "NORMALIZE = False  # @param {'type': 'boolean'}\n",
        "\n",
        "iris_df = iris_df.to_numpy()\n",
        "if NORMALIZE:\n",
        "  iris_df = preprocessing.MinMaxScaler().fit_transform(iris_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU_r29O2lm52"
      },
      "source": [
        "Now let's encode the data into a graph according to the following rules:\n",
        "Nodes - dataset entries and features, edges - feature values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0dMlNbGlkT_"
      },
      "outputs": [],
      "source": [
        "def encode_data(data: pd.DataFrame, train_mask: np.ndarray) -> np.ndarray:\n",
        "  \"\"\"Encodes tabular data into a graph.\"\"\"\n",
        "  # Number of dataset entries.\n",
        "  num_entries = data.shape[0]\n",
        "\n",
        "  # Number of features in the dataset.\n",
        "  num_features = data.shape[1]\n",
        "\n",
        "  # Computes the number of edges in the graph.\n",
        "  num_edges = num_entries * num_features\n",
        "\n",
        "  # Creates train and test indices according to the `train_mask`.\n",
        "  train_indices = np.arange(num_edges)[train_mask]\n",
        "  test_indices = np.arange(num_edges)[~train_mask]\n",
        "\n",
        "  # Finds the index of the first feature node.\n",
        "  # First `num_entries` nodes correspons to the entries of the dataset.\n",
        "  least_feature_node_id = num_entries\n",
        "\n",
        "  # Specifies nodes features. Here, we are using them to specify the\n",
        "  # one-hot-encoded type of a node.\n",
        "  entry_nodes = np.concatenate(\n",
        "      [np.ones((num_entries, 1)), np.zeros((num_entries, num_features))], axis=1\n",
        "  )\n",
        "  feature_nodes = np.concatenate(\n",
        "      [np.zeros((num_features, 1)), np.identity(num_features)], axis=1\n",
        "  )\n",
        "  nodes_features = np.concatenate([entry_nodes, feature_nodes]).astype(\n",
        "      np.float32\n",
        "  )\n",
        "\n",
        "  # Defines graph connectivity and has the final shape of [2, `num_edges`].\n",
        "  edge_index = []\n",
        "  # Edge feature matrix with shape [`num_edges`, `num_features`].\n",
        "  edge_attr = []\n",
        "  # Retrieves edge indices (indices of nodes that are connected by that edge).\n",
        "  # Builds a directed graph, where all nodes start in an entry node and end in\n",
        "  # a feature node.\n",
        "  for entry_index, features_per_entry in enumerate(data):\n",
        "    for feature_index, feature_value in enumerate(features_per_entry):\n",
        "      edge_index.append([entry_index, least_feature_node_id + feature_index])\n",
        "      edge_attr.append(feature_value)\n",
        "\n",
        "  edge_index = np.array(edge_index, dtype=np.int64).T\n",
        "  edge_attr = np.array(edge_attr, dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "  # Splits edges and attributes into train and tests subsets.\n",
        "  edge_index_train = edge_index[:, train_indices]\n",
        "  edge_index_test = edge_index[:, test_indices]\n",
        "  edge_attr_train = edge_attr[train_indices]\n",
        "  edge_attr_test = edge_attr[test_indices]\n",
        "  return Data(\n",
        "      x=nodes_features,\n",
        "      edge_index_train=edge_index_train,\n",
        "      edge_index_test=edge_index_test,\n",
        "      edge_attr_train=edge_attr_train,\n",
        "      edge_attr_test=edge_attr_test,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxXBjrh_kUns"
      },
      "outputs": [],
      "source": [
        "TRAIN_RATIO = 0.7  # @param {'type': 'number'}\n",
        "train_mask = (\n",
        "    np.random.RandomState(0)\n",
        "    .binomial(1, TRAIN_RATIO, iris_df.shape[0] * iris_df.shape[1])\n",
        "    .astype(bool)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muqluvpsU6_d"
      },
      "outputs": [],
      "source": [
        "# @title Let's visualize the resulting train/test split\n",
        "\n",
        "plt.imshow(train_mask.reshape(iris_df.shape[0], iris_df.shape[1])[:40])\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9L1pF673Rra"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      *,\n",
        "      node_input_dim: int,\n",
        "      edge_input_dim: int,\n",
        "      node_hidden_dim: int,\n",
        "      edge_hidden_dim: int,\n",
        "  ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.node_conv = torch_geometric.nn.SAGEConv(\n",
        "        node_input_dim, node_hidden_dim\n",
        "    )\n",
        "    self.edge_update_mlps = nn.Sequential(\n",
        "        nn.Linear(2 * node_hidden_dim + edge_input_dim, edge_hidden_dim),\n",
        "        torch.nn.ReLU(),\n",
        "        nn.Linear(edge_hidden_dim, edge_input_dim),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(\n",
        "      self, x: torch.Tensor, edge_attr: torch.Tensor, edge_index: torch.Tensor\n",
        "  ):\n",
        "    x = self.node_conv(x, edge_index)\n",
        "    x_from = x[edge_index[0]]\n",
        "    x_to = x[edge_index[1]]\n",
        "    edge_attr = self.edge_update_mlps(\n",
        "        torch.cat([x_from, x_to, edge_attr], dim=-1)\n",
        "    )\n",
        "    return x, edge_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crw9gH_K4Gy9"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 200  # @param {'type': 'number'}\n",
        "LEARNING_RATE = 0.001  # @param {'type': 'number'}\n",
        "WEIGHT_DECAY = 0.0000001  # @param {'type': 'number'}\n",
        "\n",
        "\n",
        "def train(gnn: torch.nn.Module, graph: Data) -> tuple[list[float], list[float]]:\n",
        "  train_loss, val_loss = [], []\n",
        "  # Puts all of the tensors to the device in use.\n",
        "  x = torch.from_numpy(graph.x).to(device)\n",
        "  edge_attr = torch.from_numpy(graph.edge_attr_train).to(device)\n",
        "  edge_attr_test = torch.from_numpy(graph.edge_attr_test).to(device)\n",
        "  edge_index_train = torch.from_numpy(graph.edge_index_train).to(device)\n",
        "  edge_index_test = torch.from_numpy(graph.edge_index_test).to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(\n",
        "      gnn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "  )\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    gnn.train()\n",
        "    optimizer.zero_grad()\n",
        "    out, out_edge = gnn(x, edge_attr, edge_index_train)\n",
        "    loss = F.mse_loss(edge_attr, out_edge)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    out.detach().to('cpu')\n",
        "    out_edge.detach().to('cpu')\n",
        "    del out\n",
        "    del out_edge\n",
        "    train_loss.append(loss.item())\n",
        "    with torch.no_grad():\n",
        "      out, out_edge_test = gnn(x, edge_attr_test, edge_index_test)\n",
        "      loss = F.mse_loss(edge_attr_test, out_edge_test)\n",
        "      out.detach().to('cpu')\n",
        "      out_edge_test.detach().to('cpu')\n",
        "      val_loss.append(loss.item())\n",
        "  return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dUHOXsg1xlI"
      },
      "outputs": [],
      "source": [
        "graph = encode_data(iris_df, train_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSrA9x8WQT5W"
      },
      "outputs": [],
      "source": [
        "# @title Instantiate the GNN\n",
        "\n",
        "NODE_HIDDEN_DIM = 128  # @param {'type': 'number'}\n",
        "EDGE_HIDDEN_DIM = 128  # @param {'type': 'number'}\n",
        "\n",
        "\n",
        "gnn = Net(\n",
        "    node_input_dim=graph.x.shape[1],\n",
        "    edge_input_dim=graph.edge_attr_train.shape[1],\n",
        "    node_hidden_dim=NODE_HIDDEN_DIM,\n",
        "    edge_hidden_dim=EDGE_HIDDEN_DIM,\n",
        ")\n",
        "gnn = gnn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzgtpPMfQAJ2"
      },
      "outputs": [],
      "source": [
        "train_loss, val_loss = train(gnn, graph)\n",
        "\n",
        "plt.plot((x := list(range(NUM_EPOCHS))), train_loss, label='train loss')\n",
        "plt.plot(x, val_loss, label='val loss')\n",
        "plt.legend()\n",
        "plt.title('Training progress')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}